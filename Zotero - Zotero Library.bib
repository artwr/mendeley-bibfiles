Automatically generated by Mendeley Desktop 1.11
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@inproceedings{Hun1996,
author = {Hun, Jun},
booktitle = {ESRI User Conference},
title = {{BEIDMS and ARCVIEW An Integrated Solution for Managing Environmental Data}},
url = {http://proceedings.esri.com/library/userconf/proc96/to200/pap166/p166.htm},
year = {1996}
}
@article{Bohlke1995,
abstract = {The history and fate of groundwater nitrate (NO3−) contamination were compared in 2 small adjacent agricultural watersheds in the Atlantic coastal plain by combined use of chronologic (CCl2F2, 3H), chemical (dissolved solids, gases), and isotopic ($\delta$15N,$\delta$13C, $\delta$34S) analyses of recharging groundwaters, discharging groundwaters, and surface waters. The results demonstrate the interactive effects of changing agricultural practices, groundwater residence times, and local geologic features on the transfer of NO3− through local flow systems. Recharge dates of groundwaters taken in 1990–1992 from the surficial aquifer in the Chesterville Branch and Morgan Creek watersheds near Locust Grove, Maryland, ranged from pre-1940 to the late 1980’s. When corrected for localized denitrification by use of dissolved gas concentrations, the dated waters provide a 40-year record of the recharge rate of NO3−, which increased in both watersheds by a factor of 3–6, most rapidly in the 1970's. The increase in groundwater NO3− over time was approximately proportional to the documented increase in regional N fertilizer use, and could be accounted for by oxidation and leaching of about 20–35\% of the fertilizer N. Groundwaters discharging upward beneath streams in both watersheds had measured recharge dates from pre-1940 to 1975, while chemical data for second-order reaches of the streams indicated average groundwater residence times in the order of 20+ years. At the time of the study, NO3− discharge rates were less than NO3− recharge rates for at least two reasons: (1) discharge of relatively old waters with low initial NO3− concentrations, and (2) local denitrification. In the Chesterville Branch watershed, groundwaters remained oxic throughout much of the surficial aquifer and discharged relatively unaltered to the stream, which had a relatively high NO3− concentration (9–10 mg/L as N). In the Morgan Creek watershed, groundwaters were largely reduced and denitrified before discharging to the stream, which had a relatively low NO3− concentration (2–3 mg/L as N). Chemical and isotopic data indicate that quantitative denitrification occurred within buried calcareous glauconitic marine sediments that are present at relatively shallow depths beneath the Morgan Creek watershed. NO3− removal by forests, wetlands, and shallow organic-rich soils in near-stream environments was largely avoided by groundwaters that followed relatively deep flow paths before converging and discharging rapidly upward to the streams.},
author = {B\"{o}hlke, J. K. and Denver, J. M.},
doi = {10.1029/95WR01584},
issn = {1944-7973},
journal = {Water Resources Research},
language = {en},
number = {9},
pages = {2319--2339},
title = {{Combined Use of Groundwater Dating, Chemical, and Isotopic Analyses to Resolve the History and Fate of Nitrate Contamination in Two Agricultural Watersheds, Atlantic Coastal Plain, Maryland}},
url = {http://onlinelibrary.wiley.com/doi/10.1029/95WR01584/abstract http://onlinelibrary.wiley.com/doi/10.1029/95WR01584/abstract;jsessionid=76716EB0C5198E3003306ABC9A6C3B43.d02t03?deniedAccessCustomisedMessage=\&userIsAuthenticated=false http://onlinelibrary.wiley.com/store/10.1029/95WR01584/asset/wrcr6895.pdf?v=1\&t=hhjwymbf\&s=1827c70680d2f94316cc76a704d4e49fafb261b3},
volume = {31},
year = {1995}
}
@incollection{Lettieri2011,
abstract = {This chapter provides a brief introductory guide to the challenge of managing plastic solid waste (PSW) to its use as a material and an energy resource. PSW recycling processes can be classified in four major categories, re-extrusion (primary), mechanical (secondary), chemical (tertiary), and energy recovery (quaternary). Each method provides a unique set of advantages that makes it particularly beneficial for specific locations, applications or requirements. Increasing recovery of waste and diverting waste away from landfill play a key role in tackling the environmental impacts of increasing waste volumes. PSW not only represents a significant proportion of the total waste produced but also has the highest potential for energy recovery, having the highest calorific value when compared with other waste fractions. This chapter also presents a review of the current situation in the United Kingdom (UK), European Union (EU), and worldwide in relation to solid waste arising and strategies to address waste management. It also introduces the different routes for PSW management, namely, re-extrusion, mechanical recycling, and energy recovery. Petrochemical recovery via thermochemical treatment is also discussed and in particular some of the thermal treatment options available, namely, gasification, hydrogenation, and pyrolysis, are presented. Finally, it discusses a case study based on pyrolysis.},
address = {Boston},
author = {Lettieri, Paola and Al-Salem, Sultan M.},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/JE5IWQXI/Lettieri and Al-Salem - 2011 - Chapter 17 - Thermochemical Treatment of Plastic S.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {233--242},
publisher = {Academic Press},
title = {{Chapter 17 - Thermochemical Treatment of Plastic Solid Waste}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100178 http://www.sciencedirect.com/science/article/pii/B9780123814753100178/pdfft?md5=7fe068c3e8154a618e6de8da02a3abbb\&pid=3-s2.0-B9780123814753100178-main.pdf},
year = {2011}
}
@article{Yamamoto2012,
abstract = {A field survey was carried out soon after the Fukushima Dai-ichi Nuclear Power Plant accident. Gamma-ray emitting radionuclides and plutonium isotopes in a series of soil samples collected from the heavily contaminated areas outside the 20-km exclusion zone, as well as from Okuma Town adjacent to the plant, were measured. Volatile radionuclides such as 131I, 134Cs, and 137Cs contributed largely to the released radioactivity. Higher depositions of these nuclides were observed in areas to the northwestern- including Okuma Town and Iitate Village, which is at a distance of 25-45 km from the plant. The results obtained were consistent with the levels and distributions estimated later by the Japan-USA joint-survey (Asahi Shimbun Company, 2011). Trace amounts of plutonium isotopes originating from the accident were detected mainly in soil samples from Iitate Village and in limited soil samples from Okuma Town. The detected levels of 239,240Pu contamination due to the accident were considered to be less than a millionth those of the 137Cs contamination. © 2012 by The Geochemical Society of Japan.},
annote = {Cited By (since 1996):13},
author = {Yamamoto, M. and Takada, T. and Nagao, S. and Koike, T. and Shimada, K. and Hoshi, M. and Zhumadilov, K. and Shima, T. and Fukuoka, M. and Imanaka, T. and Endo, S. and Sakaguchi, A. and Kimura, S.},
issn = {0016-7002},
journal = {Geochemical Journal},
keywords = {Early field survey,Fukushima Dai-ichi Nuclear Power Plant accident,Gamma-emitting radionuclides,Plutonium,Soil contamination},
language = {English},
mendeley-tags = {Early field survey,Fukushima Dai-ichi Nuclear Power Plant accident,Gamma-emitting radionuclides,Plutonium,Soil contamination},
number = {4},
pages = {341--353},
title = {{An early survey of the radioactive contamination of soil due to the Fukushima Dai-ichi Nuclear Power Plant accident, with emphasis on plutonium analysis}},
volume = {46},
year = {2012}
}
@article{Beven2008,
author = {Beven, Keith J. and Smith, Paul J. and Freer, Jim E.},
doi = {10.1016/j.jhydrol.2008.02.007},
issn = {00221694},
journal = {Journal of Hydrology},
month = jun,
number = {1-4},
pages = {15--32},
title = {{So just why would a modeller choose to be incoherent?}},
url = {http://www.scopus.com/record/display.url?eid=2-s2.0-43449131518\&origin=inward\&txGid=994B5FED5512D88323EE79331AFAF951.WXhD7YyTQ6A7Pvk9AlA:2},
volume = {354},
year = {2008}
}
@article{Zahraeifard2014,
abstract = {This paper presents a novel triple-layer model, called VART DO-3L, for simulation of spatial variations in dissolved oxygen (DO) in fine-grained streams, characterized by a fluid mud (fluff or flocculent) layer (an advection-dominated storage zone) as the interface between overlying stream water and relatively consolidated stream bed-sediment (a diffusion-dominated storage zone). A global sensitivity analysis is conducted to investigate the sensitivity of VART DO-3L model input parameters. Results of the sensitivity analysis indicate that the most sensitive parameter is the relative size of the advection-dominated storage zones (As/A), followed by a lumped reaction term (R) for the flocculent layer, biological reaction rate ($\mu$o) in diffusive layer, and BOD concentration (L) in water column. In order to address uncertainty in model input parameters, Monte Carlo simulations are performed to sample parameter values and to produce various parameter combinations or cases. The VART DO-3L model is applied to the Lower Amite River in Louisiana, USA to simulate vertical and longitudinal variations in DO under the cases. In terms of longitudinal variation, the DO level decreases from 7. 9 mg/L at the Denham Springs station to about 2.89 mg/L at the Port Vincent station. In terms of vertical variation, the DO level drops rapidly from the overlying water column to the advection-dominated storage zone and further to the diffusive layer. The DO level (CF) in the advective layer (flocculent layer) can reach as high as 40\% of DO concentration (C) in the water column. The VART DO-3L model may be applied to similar rivers for simulation of spatial variations in DO level. This article is protected by copyright. All rights reserved.},
author = {Zahraeifard, Vahid and Deng, Zhiqiang and Malone, Ronald},
doi = {10.1002/hyp.10144},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/AIBC7SB5/Zahraeifard et al. - 2014 - Modeling spatial variations in dissolved oxygen in.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/MZE2EIMF/abstract.html:html},
issn = {1099-1085},
journal = {Hydrological Processes},
keywords = {Folder - geostats,dissolved oxygen,longitudinal variation,sediment oxygen demand,triple-layer model,vertical variation},
language = {en},
mendeley-tags = {Folder - geostats,dissolved oxygen,longitudinal variation,sediment oxygen demand,triple-layer model,vertical variation},
pages = {n/a--n/a},
title = {{Modeling spatial variations in dissolved oxygen in fine-grained streams under uncertainty}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/hyp.10144/abstract http://onlinelibrary.wiley.com/store/10.1002/hyp.10144/asset/hyp10144.pdf?v=1\&t=hqe5qyjf\&s=5780d8e1b41ff3ebbe50483723a57a09242ec247},
year = {2014}
}
@article{Tokunaga2012,
author = {Tokunaga, Tetsu K. and Wan, Jiamin and Denham, Miles E.},
doi = {10.2136/vzj2011.0131},
issn = {1539-1663},
journal = {Vadose Zone Journal},
language = {en},
month = aug,
number = {3},
publisher = {Soil Science Society of America},
title = {{Estimates of Vadose Zone Drainage from a Capped Seepage Basin, F-Area, Savannah River Site}},
url = {http://vzj.geoscienceworld.org/content/11/3/vzj2011.0131.full},
volume = {11},
year = {2012}
}
@article{Hippert2010,
abstract = {Artificial neural networks have frequently been proposed for electricity load forecasting because of their capabilities for the nonlinear modelling of large multivariate data sets. Modelling with neural networks is not an easy task though; two of the main challenges are defining the appropriate level of model complexity, and choosing the input variables. This paper evaluates techniques for automatic neural network modelling within a Bayesian framework, as applied to six samples containing daily load and weather data for four different countries. We analyse input selection as carried out by the Bayesian ‘automatic relevance determination’, and the usefulness of the Bayesian ‘evidence’ for the selection of the best structure (in terms of number of neurones), as compared to methods based on cross-validation.},
author = {Hippert, Henrique S. and Taylor, James W.},
doi = {10.1016/j.neunet.2009.11.016},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/ZGDST89H/Hippert and Taylor - 2010 - An evaluation of Bayesian techniques for controlli.pdf:pdf},
issn = {0893-6080},
journal = {Neural Networks},
keywords = {Bayesian model selection,Bayesian neural networks,Input selection,Load forecasting},
mendeley-tags = {Bayesian model selection,Bayesian neural networks,Input selection,Load forecasting},
month = apr,
number = {3},
pages = {386--395},
title = {{An evaluation of Bayesian techniques for controlling model complexity and selecting inputs in a neural network for short-term load forecasting}},
url = {http://www.sciencedirect.com/science/article/pii/S0893608009003189 http://www.sciencedirect.com/science/article/pii/S0893608009003189/pdfft?md5=39722ccce125e931bbee102fdf26dd06\&pid=1-s2.0-S0893608009003189-main.pdf},
volume = {23},
year = {2010}
}
@incollection{Pichtel2014ch3,
author = {Pichtel, John},
booktitle = {Waste Management Practices: Municipal, Hazardous, and Industrial, Second Edition},
chapter = {3},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/A5KKQBXU/2014 - Regulatory Development.pdf:pdf},
isbn = {978-1-4665-8518-8},
month = jan,
pages = {47--60},
publisher = {CRC Press},
title = {{Regulatory Development}},
url = {http://www.crcnetbase.com/doi/abs/10.1201/b16576-5 http://www.crcnetbase.com/doi/pdf/10.1201/b16576-5},
year = {2014}
}
@article{Paces2012,
author = {Paces, James B and Elliott, Peggy E and Fenelon, Joseph M and Laczniak, Randell J and Moreo, Michael T},
journal = {Sci. Invest. Rep.(US Geol. Surv.)},
number = {2012},
pages = {108},
title = {{Transient Effects on Groundwater Chemical Compositions from Pumping of Supply Wells at the Nevada National Security Site, Nye County, Nevada, 1951–2008}},
url = {http://pubs.usgs.gov/sir/2012/5023/},
volume = {5023},
year = {2012}
}
@article{Srinivasan2008a,
abstract = {Multi-species reactive transport equations coupled through sorption and sequential first-order reactions are commonly used to model sites contaminated with radioactive wastes, chlorinated solvents and nitrogenous species. Although researchers have been attempting to solve various forms of these reactive transport equations for over 50 years, a general closed-form analytical solution to this problem is not available in the published literature. In Part I of this two-part article, we derive a closed-form analytical solution to this problem for spatially-varying initial conditions. The proposed solution procedure employs a combination of Laplace and linear transform methods to uncouple and solve the system of partial differential equations. Two distinct solutions are derived for Dirichlet and Cauchy boundary conditions each with Bateman-type source terms. We organize and present the final solutions in a common format that represents the solutions to both boundary conditions. In addition, we provide the mathematical concepts for deriving the solution within a generic framework that can be used for solving similar transport problems.},
author = {Srinivasan, V. and Clement, T.P.},
doi = {10.1016/j.advwatres.2007.08.002},
issn = {0309-1708},
journal = {Advances in Water Resources},
keywords = {Analytical solution,Contaminant transport,First-order decay,Radioactive decay,Reactive transport,Sequential reactions},
mendeley-tags = {Analytical solution,Contaminant transport,First-order decay,Radioactive decay,Reactive transport,Sequential reactions},
month = feb,
number = {2},
pages = {203--218},
shorttitle = {Analytical solutions for sequentially coupled one-},
title = {{Analytical solutions for sequentially coupled one-dimensional reactive transport problems – Part I: Mathematical derivations}},
url = {http://www.sciencedirect.com/science/article/pii/S0309170807001297 http://pdn.sciencedirect.com/science?\_ob=MiamiImageURL\&\_cid=271718\&\_user=4420\&\_pii=S0309170807001297\&\_check=y\&\_origin=article\&\_zone=toolbar\&\_coverDate=2008--29\&view=c\&originContentFamily=serial\&wchp=dGLbVlS-zSkzk\&md5=31d93aa812243f7109d7ba7c3ea630a8\&pid=1-s2.0-S0309170807001297-main.pdf http://pdn.sciencedirect.com/science?\_ob=MiamiImageURL\&\_cid=271718\&\_user=4420\&\_pii=S0309170807001297\&\_check=y\&\_origin=article\&\_zone=toolbar\&\_cove},
volume = {31},
year = {2008}
}
@article{Simpson1960a,
author = {Simpson, J. D. and Greening, J. R.},
doi = {10.1038/186467c0},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/DP6DHTEX/Simpson and Greening - 1960 - Preparation of Tritiated Water Samples by Distilla.pdf:pdf},
journal = {Nature},
language = {en},
month = may,
number = {4723},
pages = {467--468},
title = {{Preparation of Tritiated Water Samples by Distillation}},
url = {http://www.nature.com/nature/journal/v186/n4723/abs/186467c0.html http://www.nature.com/nature/journal/v186/n4723/pdf/186467c0.pdf},
volume = {186},
year = {1960}
}
@article{Yamamoto2014,
abstract = {Dust samples from the sides of roads (black substances) have been collected together with litter and soil samples at more than 100 sites contaminated heavily in the 20-km exclusion zones around Fukushima Dai-ichi Nuclear Power Plant (FDNPP) (Minamisoma City, and Namie, Futaba and Okuma Towns), in Iitate Village located from 25 to 45 km northwest of the plant and in southern areas from the plant. Isotopes of Pu, Am and Cm have been measured in the samples to evaluate their total releases into the environment from the FDNPP and to get the isotopic compositions among these nuclides. For black substances and litter samples, in addition to Pu isotopes, 241Am, 242Cm and 243,244Cm were determined for most of samples examined, while for soil samples, only Pu isotopes were determined. The results provided a coherent data set on 239,240Pu inventories and isotopic composition among these transuranic nuclides. When these activity ratios were compared with those for fuel core inventories in the FDNPP accident estimated by a group at JAEA, except 239,240Pu/137Cs activity ratios, fairly good agreements were found, indicating that transuranic nuclides, probably in the forms of fine particles, were released into the environment without their large fractionations. The obtained data may lead to more accurate information about the on-site situation (e.g., burn-up, conditions of fuel during the release phase, etc.), which would be difficult to get otherwise, and more detailed information on the dispersion and deposition processes of transuranic nuclides and the behavior of these nuclides in the environment.},
author = {Yamamoto, M. and Sakaguchi, A. and Ochiai, S. and Takada, T. and Hamataka, K. and Murakami, T. and Nagao, S.},
doi = {10.1016/j.jenvrad.2014.01.013},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/GQXQ8IFS/Yamamoto et al. - 2014 - Isotopic Pu, Am and Cm signatures in environmental.pdf:pdf},
issn = {0265-931X},
journal = {Journal of Environmental Radioactivity},
keywords = {Am,Black substances,Cm,FDNPP accident,Pu,Radioactive Cs},
mendeley-tags = {Am,Black substances,Cm,FDNPP accident,Pu,Radioactive Cs},
month = jun,
pages = {31--46},
title = {{Isotopic Pu, Am and Cm signatures in environmental samples contaminated by the Fukushima Dai-ichi Nuclear Power Plant accident}},
url = {http://www.sciencedirect.com/science/article/pii/S0265931X14000162 http://www.sciencedirect.com/science/article/pii/S0265931X14000162/pdfft?md5=7923c3574be4255a931f7ac50552f73d\&pid=1-s2.0-S0265931X14000162-main.pdf},
volume = {132},
year = {2014}
}
@book{Gilbert2004,
author = {Gilbert, Steven},
isbn = {978-0-415-31168-7, 978-0-203-46173-0},
language = {en},
month = feb,
publisher = {CRC Press},
shorttitle = {A Small Dose of Toxicology},
title = {{A Small Dose of Toxicology: The Health Effects of Common Chemicals}},
url = {http://www.crcnetbase.com/isbn/9780203461730},
year = {2004}
}
@article{Zucchini2000,
abstract = {This paper is an introduction to model selection intended for nonspecialists who have knowledge of the statistical concepts covered in a typical first (occasionally second) statistics course. The intention is to explain the ideas that generate frequentist methodology for model selection, for example the Akaike information criterion, bootstrap criteria, and cross-validation criteria. Bayesian methods, including the Bayesian information criterion, are also mentioned in the context of the framework outlined in the paper. The ideas are illustrated using an example in which observations are available for the entire population of interest. This enables us to examine and to measure effects that are usually invisible, because in practical applications only a sample from the population is observed. The problem of selection bias, a hazard of which one needs to be aware in the context of model selection, is also discussed. Copyright 2000 Academic Press.},
author = {Zucchini, W},
doi = {10.1006/jmps.1999.1276},
issn = {0022-2496},
journal = {Journal of mathematical psychology},
month = mar,
number = {1},
pages = {41--61},
pmid = {10733857},
title = {{An Introduction to Model Selection.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10733857},
volume = {44},
year = {2000}
}
@incollection{ScottKlasky2009,
annote = {doi:10.1201/9781420069815-c5},
author = {{Scott Klasky} and {Hasan Abbasi} and {Viraj Bhat} and {Ciprian Docan} and {Steve Hodson} and {Chen Jin} and {Jay Lofstead} and {Manish Parashar} and {Karsten Schwan} and {Matthew Wolf}},
booktitle = {Scien},
isbn = {978-1-4200-6980-8},
month = dec,
publisher = {Chapman and Hall/CRC},
series = {Chapman \& Hall/CRC Computational Science},
title = {{High Throughput Data Movement}},
url = {http://dx.doi.org/10.1201/9781420069815-c5},
year = {2009}
}
@article{Schotanus,
abstract = {Transport and degradation of de-icing chemical (containing propylene glycol, PG) in the vadose zone were studied with a lysimeter experiment and a model, in which transient water flow, kinetic degradation of PG and soil chemistry were combined. The lysimeter experiment indicated that aerobic as well as anaerobic degradation occurs in the vadose zone. Therefore, the model included both types of degradation, which was made possible by assuming advection-controlled (mobile) and diffusion-controlled (immobile) zones. In the mobile zone, oxygen can be transported by diffusion in the gas phase. The immobile zone is always water-saturated, and oxygen only diffuses slowly in the water phase. Therefore, the model is designed in a way that the redox potential can decrease when PG is degraded, and thus, anaerobic degradation can occur. In our model, manganese oxide (MnO2, which is present in the soil) and NO 3 − −3\_\{3\}\^{}\{-\} (applied to enhance biodegradation) can be used as electron acceptors for anaerobic degradation. The application of NO 3 − −3\_\{3\}\^{}\{-\} does not result in a lower leaching of PG nor in a slower depletion of MnO2. The thickness of the snowcover influences the leached fraction of PG, as with a high infiltration rate, transport is fast, there is less time for degradation and thus more PG will leach. The model showed that, in this soil, the effect of the water flow dominates over the effect of the degradation parameters on the leaching at a 1-m depth.},
author = {Schotanus, D. and Meeussen, J. C. L. and Lissner, H. and van der Ploeg, M. J. and Wehrer, M. and Totsche, K. U. and van der Zee, S. E. A. T. M.},
doi = {10.1007/s11356-013-2033-y},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/JHEXAN8R/Schotanus et al. - Transport and degradation of propylene glycol in t.html:html;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/MUSAWZG7/Schotanus et al. - Transport and degradation of propylene glycol in t.pdf:pdf},
issn = {0944-1344, 1614-7499},
journal = {Environmental Science and Pollution Research},
keywords = {Atmospheric Protection/Air Quality Control/Air Pol,Contaminant transport,De-icing chemical,Degradation,Ecotoxicology,Environment- general,Environmental Chemistry,Environmental Health,Modeling,Vadose Zone,Waste Water Technology / Water Pollution Control /},
language = {en},
mendeley-tags = {Atmospheric Protection/Air Quality Control/Air Pol,Contaminant transport,De-icing chemical,Degradation,Ecotoxicology,Environment- general,Environmental Chemistry,Environmental Health,Modeling,Vadose Zone,Waste Water Technology / Water Pollution Control /},
pages = {1--13},
shorttitle = {Transport and degradation of propylene glycol in t},
title = {{Transport and degradation of propylene glycol in the vadose zone: model development and sensitivity analysis}},
url = {http://link.springer.com/article/10.1007/s11356-013-2033-y http://link.springer.com/content/pdf/10.1007\%2Fs11356-013-2033-y.pdf}
}
@misc{Bloschl2005a,
author = {Bl\"{o}schl, G\"{u}nter},
booktitle = {Encyclopedia of Hydrological Sciences},
doi = {10.1002/0470848944.hsa008},
keywords = {aggregation,disaggregation,flood frequency,fractals,global circulation models,groundwater,media generation,rainfall,sampling,scale,soil moisture,stochastic rainfall models,topographic index,variogram},
publisher = {Wiley Online Library},
title = {{Statistical upscaling and downscaling in hydrology}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/0470848944.hsa008/full},
year = {2005}
}
@article{Casella1992,
abstract = {Computer-intensive algorithms, such as the Gibbs sampler, have become increasingly popular statistical tools, both in applied and theoretical work. The properties of such algorithms, however, may sometimes not be obvious. Here we give a simple explanation of how and why the Gibbs sampler works. We analytically establish its properties in a simple case and provide insight for more complicated cases. There are also a number of examples.},
author = {Casella, George and George, Edward I.},
doi = {10.2307/2685208},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/S2ZTUQIA/Casella and George - 1992 - Explaining the Gibbs Sampler.pdf:pdf},
issn = {00031305},
journal = {The American Statistician},
month = aug,
number = {3},
pages = {167},
title = {{Explaining the Gibbs Sampler}},
url = {http://www.jstor.org/stable/2685208 http://www.jstor.org/stable/pdfplus/2685208.pdf?acceptTC=true http://www.jstor.org/stable/2685208?origin=crossref},
volume = {46},
year = {1992}
}
@article{Reggiani1998,
author = {Reggiani, Paolo and Sivapalan, Murugesu and {Majid Hassanizadeh}, S.},
journal = {Advances in Water Resources},
number = {4},
pages = {367--398},
shorttitle = {A unifying framework for watershed thermodynamics},
title = {{A unifying framework for watershed thermodynamics: balance equations for mass, momentum, energy and entropy, and the second law of thermodynamics}},
url = {http://www.sciencedirect.com/science/article/pii/S0309170898000128 http://www.geo.uu.nl/hydrogeology/majid/pdf/reggiani\_etal\_awr98.pdf},
volume = {22},
year = {1998}
}
@incollection{Letcher2011i,
address = {Boston},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/MIJ66DH4/Letcher and Vallero - 2011 - Introduction.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {75},
publisher = {Academic Press},
title = {{Introduction}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100427 http://www.sciencedirect.com/science/article/pii/B9780123814753100427/pdfft?md5=1253e20cf8ae352be1a70c5d34fe65c9\&pid=3-s2.0-B9780123814753100427-main.pdf},
year = {2011}
}
@article{Duffus2007,
author = {Duffus, John H. and Nordberg, Monica and Templeton, Douglas M.},
doi = {10.1351/pac200779071153},
issn = {1365-3075, 0033-4545},
journal = {Pure and Applied Chemistry},
month = jan,
number = {7},
pages = {1153--1344},
title = {{Glossary of terms used in toxicology, 2nd edition (IUPAC Recommendations 2007)}},
url = {http://www.iupac.org/publications/pac/79/7/1153/},
volume = {79},
year = {2007}
}
@incollection{Otterpohl2011,
abstract = {The management of biowaste has undergone significant changes during the last decade as environmental concerns and the need for sustainable use of resources continue to penetrate the public conscience. In this chapter, a systematic short description of commonly implemented sanitation systems is presented. It emphasizes that all reuse-oriented wastewater systems; whether low- or high-tech, have different strengths in contributing to sustainable biowaste management, depending on the specific context, and argues that the key issue as far as the reuse of wastewater is concerned is to collect and treat toilet flow streams (blackwater or dry faecal matter and urine) and wastewater (greywater) separately. The chapter shows how this approach has grown rapidly over the past years, with a clear message that future innovations will need increased focus on managing the solid fraction.
Biowaste management deals with solid waste management, focusing on reusing rather than disposing. There are three main lines of approaching the problem—high-tech systems based mainly on vacuum technology, membrane bioreactors, and biogas plants; urine diverting flush systems; and, finally, the very promising modern dry sanitation systems that can be very cost efficient and furthermore produce black soil and water that can be reused [terra preta sanitation (TPS)]. This chapter provides an overview to some of the different solutions. Integration of the anaerobic dry toilet and vermicomposting thus promises to be an ideal approach for managing wastes; even wastes generated by urban households. The product, terra preta, can address the problems of soil degradation and food insecurity, common in many areas across the world. TPS could become important in the design of highly efficient ecofriendly houses and housing areas with the added value of improved urban agriculture, which can be combined with local greywater reuse. Thus, TPS can close regional cycles and improve hygienic conditions and soil fertility in a sustainable manner with the creation of local added value. There are still questions to be answered such as the issue of macronutrients and also micronutrients.},
address = {Boston},
author = {Otterpohl, Ralf and Buzie, Christopher},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/7P9FNQX3/Otterpohl and Buzie - 2011 - Chapter 9 - Wastewater Reuse-Oriented Wastewater .pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {127--136},
publisher = {Academic Press},
shorttitle = {Chapter 9 - Wastewater},
title = {{Chapter 9 - Wastewater: Reuse-Oriented Wastewater Systems—Low- and High-Tech Approaches for Urban Areas}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100099 http://www.sciencedirect.com/science/article/pii/B9780123814753100099/pdfft?md5=e9c9d6cb53ed8d09af00f672adc8ab1d\&pid=3-s2.0-B9780123814753100099-main.pdf},
year = {2011}
}
@article{Pimm1979,
abstract = {Most species persist at fairly constant levels despite perturbations from a variety of abiotic and biotic factors that may affect their numbers. To model this persistence, most studies impose the constraint that species densities, when slightly perturbed from equilibrium, will return to that equilibrium. This is the condition of local stability. This paper examines a different condition involving a more severe perturbation. I define a system to be species deletion stable if, when a species is removed from a system, all the remaining species remain at a stable equilibrium involving only positive densities. Species in the real world might be deleted through emigration, disease, or the effects of a predator - including man. The condition of species deletion stability seems closer to the concept of 'stability' used by MacArthur. He argued that increased model complexity should lead to greater resistance to perturbation but this idea has generally not been supported by studies on local stability. This paper shows that increasing model complexity does not result in increased species deletion stability. Indeed, species deletion stability varies widely with slight changes in model structure and the characteristics of the species deleted. Species deletion stable models do not differ in any recognizable structural properties from models that are sensitive to species deletion. I conclude that natural ecosystems have not been significantly modified in their structures to maximize their resistance to species deletion. This is in contrast to the condition of local stability. Locally stable models, differ in many structural properties from those that are unstable. Analyses of the structure of real food webs shows that these possess the structures that lead to local stability. /// Большинство видов существует при довольно постоянном уровне численности, несмотря на изменения различных абиотических и биотических факторов, ко торые могут влиять на их численность. При моделировании этого в большин-стве исследований предлолагалась напряженность, с кторой виды, после не-больших нарушений равновесия, снова к нему воавращались. Это - условие локальной стабильности. В данной статье исследованы разные условия, ко-торые приводят к наиболее сильным нарушениям. Я предлолагаю, что система, устойчивая к удалению вида, сохраняет остальные виды в постоянном рав-новесии, включающем только положиетльную численность. Виды в реальных условиях могут исчезать в результате миграций, болезней либо пресса хищ-ников, включая и человека. Условие стабильности при удалении вида приб-лижается к концепции стабильности Макартура. Он утверждает, что увеличе-ние сложности модели полжно привести к большей устойчивости к различным пертрубациям, но данная идея в целом не подтверждается изучением локаль-ной стабильности. Данная статья показывает, что увеличение сложности модели не приводит к повьшению стабильности при удалении видов. Действительно, стабильность при удалении видов широко колеблется при незначительных изменениях в структуре модели и оксобенностей исчезакщих видов. Модели, устойчивые к удалению видов не отличаются по каким-то четким признакам от модлей, чувствительных к удалению видов. Я делаю вывод, что естественные экосис-темы существенно не изменяют свою структуру для максимализации собствен-ной устойчивости к удалению видов. Это противоречит условию локальной стабильности. Стабильные модели отличаются по многим структурным особен-ностям от нестабильных. Анализы структуры реальных пищеных сетей показы-вают, что они обладают структурой, которая приводит к наличию локальной стабильности.},
author = {Pimm, Stuart L.},
doi = {10.2307/3544322},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/UI9MPQCK/Pimm - 1979 - Complexity and Stability Another Look at MacArthu.pdf:pdf},
issn = {0030-1299},
journal = {Oikos},
month = jan,
number = {3},
pages = {351--357},
shorttitle = {Complexity and Stability},
title = {{Complexity and Stability: Another Look at MacArthur's Original Hypothesis}},
url = {http://www.jstor.org/stable/3544322 http://www.jstor.org/stable/pdfplus/3544322.pdf?acceptTC=true},
volume = {33},
year = {1979}
}
@article{Price1958,
author = {Price, A. H.},
doi = {10.1038/181262a0},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/HCZ6TTRC/Price - 1958 - Vapour Pressure of Tritiated Water.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
month = jan,
number = {4604},
pages = {262--262},
title = {{Vapour Pressure of Tritiated Water}},
url = {http://apps.webofknowledge.com/InboundService.do?UT=A1958ZP87500033\&IsProductCode=Yes\&mode=FullRecord\&product=WOS\&SID=1C7zSNARcF1feI9opJa\&smartRedirect=yes\&SrcApp=Nature\&DestFail=http\%3A\%2F\%2Fwww.webofknowledge.com\%3FDestApp\%3DCEL\%26DestParams\%3D\%253Faction\%253Dretrieve\%2526mode\%253DFullRecord\%2526product\%253DCEL\%2526UT\%253DA1958ZP87500033\%2526customersID\%253DNature\%26e\%3DLCuaBGIgIDreMLG2Ay4VRA26HlV1Ea.8WtcwAQpOm2rBuLnftxkv9Kkq5dVzjfAa\%26SrcApp\%3DNature\%26SrcAuth\%3DNature\&action=retrieve\&Init=Ye},
volume = {181},
year = {1958}
}
@article{Hassan2011a,
abstract = {This article seeks to explore the spatial variability of groundwater arsenic (As) concentrations in Southwestern Bangladesh. Facts about spatial pattern of As are important to understand the complex processes of As concentrations and its spatial predictions in the unsampled areas of the study site. The relevant As data for this study were collected from Southwest Bangladesh and were analyzed with Flow Injection Hydride Generation Atomic Absorption Spectrometry (FI-HG-AAS). A geostatistical analysis with Indicator Kriging (IK) was employed to investigate the regionalized variation of As concentration. The IK prediction map shows a highly uneven spatial pattern of arsenic concentrations. The safe zones are mainly concentrated in the north, central and south part of the study area in a scattered manner, while the contamination zones are found to be concentrated in the west and northeast parts of the study area. The southwest part of the study area is contaminated with a highly irregular pattern. A Generalized Linear Model (GLM) was also used to investigate the relationship between As concentrations and aquifer depths. A negligible negative correlation between aquifer depth and arsenic concentrations was found in the study area. The fitted value with 95 \% confidence interval shows a decreasing tendency of arsenic concentrations with the increase of aquifer depth. The adjusted mean smoothed lowess curve with a bandwidth of 0.8 shows an increasing trend of arsenic concentration up to a depth of 75 m, with some erratic fluctuations and regional variations at the depth between 30 m and 60 m. The borehole lithology was considered to analyze and map the pattern of As variability with aquifer depths. The study has performed an investigation of spatial pattern and variation of As concentrations.},
author = {Hassan, M Manzurul and Atkins, Peter J},
doi = {10.1080/10934529.2011.598771},
issn = {1532-4117},
journal = {Journal of environmental science and health. Part A, Toxic/hazardous substances \& environmental engineering},
keywords = {Arsenic,Bangladesh,Environmental Monitoring,Groundwater,Models- Chemical,Risk Assessment,Statistics- Nonparametric,Water Pollutants- Chemical},
language = {eng},
mendeley-tags = {Arsenic,Bangladesh,Environmental Monitoring,Groundwater,Models- Chemical,Risk Assessment,Statistics- Nonparametric,Water Pollutants- Chemical},
number = {11},
pages = {1185--1196},
title = {{Application of geostatistics with Indicator Kriging for analyzing spatial variability of groundwater arsenic concentrations in Southwest Bangladesh}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21879851 http://www.tandfonline.com/doi/abs/10.1080/10934529.2011.598771?url\_ver=Z39.88-2003\&rfr\_id=ori:rid:crossref.org\&rfr\_dat=cr\_pub=pubmed\#.UZXNbcGk-So http://www.tandfonline.com/doi/pdf/10.1080/10934529.2011.598771},
volume = {46},
year = {2011}
}
@article{Burnell2014,
abstract = {Stochastic analyses were performed to examine sequential first-order monomolecular reactions at the microscopic scale and both Fickian and non-Fickian plume reactive transport at the macroscopic scale. An analytical solution was derived for the chemical master equation (CME) for a closed system of irreversible first-order monomolecular reactions. Taking a Lagrangian reference frame of particles migrating from a source, analyses show that the relative concentration of each species in the deterministic analytical solution for 1-D steady-state plug flow with first-order sequential degradation is mathematically equivalent to the mean of a multinomial distribution of plume particles moving at constant velocity with sequential transformations described by transition probabilities of a discrete state, continuous-time Markov chain. In order to examine the coupling of reaction and transport terms in subdiffusive-reactive transport equations, a closed-form multi-species analytical solution also was derived for steady-state advection, dispersion, and sequential first-order reaction. Using a 1-D continuous time random walk (CTRW) embedded in Markov chains, computationally efficient Monte Carlo simulations of particle movement were performed to more fully examine effects of subdiffusive- reactive transport with an application to steady-state, sequentially degrading multi-species plumes at a site in Palm, Bay, FL. The simulation results indicated that non-Fickian steady-state plumes can resemble Fickian plumes because linear reactions truncate the waiting time between particle jumps, which removes lower velocity particles from the broad spectrum of velocities in highly heterogeneous media. Results show that fitting of Fickian models to plume concentration data can lead to inaccurate estimates of rate constants because of the wide distribution of travel times in highly heterogeneous media.},
author = {Burnell, Daniel K. and Mercer, James W. and Faust, Charles R.},
doi = {10.1002/2013WR013814},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/M6552RKM/abstract.html:html;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/5MVIGSVB/Burnell et al. - 2014 - Stochastic modeling analysis of sequential first-o.pdf:pdf},
issn = {1944-7973},
journal = {Water Resources Research},
keywords = {CTRW,First-order reaction,non-Fickian transport,sequential degradation,steady-state plume,stochastic process},
language = {en},
mendeley-tags = {CTRW,First-order reaction,non-Fickian transport,sequential degradation,steady-state plume,stochastic process},
pages = {n/a--n/a},
title = {{Stochastic modeling analysis of sequential first-order degradation reactions and non-Fickian transport in steady-state plumes}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/2013WR013814/abstract http://onlinelibrary.wiley.com/store/10.1002/2013WR013814/asset/wrcr20713.pdf?v=1\&t=hq7gcory\&s=6b400dc8c82cc1c52ce0489391df766cf6bf11b9},
year = {2014}
}
@article{Yeboah2014,
abstract = {The migration of radionuclides from a borehole repository located about 20 km from the Akwapim fault line which lies in an area of high seismicity was analyzed for some selected radionuclides. In the event of a seismic activity, fractures and faults could be rejuvenated or initiated resulting in container failure leading to the release of radionuclides. A numerical model was solved using a two-dimensional finite element code (Comsol Multiphysics) by taking into account the effect of heterogeneities. Results showed that, the fractured medium created preferential pathways indicating that, fault zones generated potential paths for released radionuclides from a radioactive waste repository. The results obtained showed that variations in hydraulic conductivity as a result of the heterogeneity considered within the domain significantly affected the direction of flow.},
author = {Yeboah, Serwaa and Akiti, Thomas T. and Fletcher, John J.},
doi = {10.1186/2193-1801-3-155},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/M2CM8Z2V/Yeboah et al. - 2014 - Numerical modeling of radionuclide migration throu.pdf:pdf},
issn = {2193-1801},
journal = {SpringerPlus},
language = {en},
month = mar,
number = {1},
pages = {155},
title = {{Numerical modeling of radionuclide migration through a borehole disposal site}},
url = {http://www.springerplus.com/content/3/1/155/abstract http://www.springerplus.com/content/pdf/2193-1801-3-155.pdf},
volume = {3},
year = {2014}
}
@book{Boltzmann1896,
abstract = {1. Theil. Theorie des Gase mit einatomigen Molek\"{u}len, deren dimensionen gegen die Mittlere wegl\"{a}nge verschwinden. -- 2. Theil. Theorie van der Waals'; Gase mit zusammengesetzten Molek\"{u}len; Gasdissociation; Schlussbemerkungen},
address = {Leipzig},
author = {Boltzmann, Ludwig},
keywords = {Kinetic theory of gases},
language = {ger},
mendeley-tags = {Kinetic theory of gases},
pages = {294},
publisher = {Leipzig : Johann Ambrosius Barth},
title = {{Vorlesungen \"{u}ber Gastheorie}},
url = {http://archive.org/details/vorlesungenber02bolt},
year = {1896}
}
@incollection{BertramLudascher2009,
annote = {doi:10.1201/9781420069815-c13},
author = {{Bertram Ludascher} and {Ilkay Altintas} and {Shawn Bowers} and {Julian Cummings} and {Terence Critchlow} and {Ewa Deelman} and {DavidDe Roure} and {Juliana Freire} and {Carole Goble} and {Matthew Jones} and {Scott Klasky} and {Timothy McPhillips} and {Norbert Podhorszki} and {Claudio Silva} and {Ian Taylor} and {Mladen Vouk}},
isbn = {978-1-4200-6980-8},
month = dec,
publisher = {Chapman and Hall/CRC},
series = {Chapman \& Hall/CRC Computational Science},
title = {{Scientific Process Automation and Workflow Management}},
url = {http://dx.doi.org/10.1201/9781420069815-c13},
year = {2009}
}
@incollection{Pichtel2014c,
author = {Pichtel, John},
booktitle = {Waste Management Practices: Municipal, Hazardous, and Industrial, Second Edition},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/XZZP5C4A/2014 - Identification of Hazardous Waste.pdf:pdf},
isbn = {978-1-4665-8518-8},
month = jan,
pages = {355--370},
publisher = {CRC Press},
title = {{Identification of Hazardous Waste}},
url = {http://www.crcnetbase.com/doi/abs/10.1201/b16576-15 http://www.crcnetbase.com/doi/pdf/10.1201/b16576-15},
year = {2014}
}
@article{Wittenberg1999,
author = {Wittenberg, H. and Sivapalan, M.},
journal = {Journal of Hydrology},
number = {1},
pages = {20--33},
title = {{Watershed groundwater balance estimation using streamflow recession analysis and baseflow separation}},
url = {http://www.sciencedirect.com/science/article/pii/S0022169499000402},
volume = {219},
year = {1999}
}
@article{Arlot2010d,
abstract = {Used to estimate the risk of an estimator or to perform model selection, cross-validation is a widespread strategy because of its simplicity and its (apparent) universality. Many results exist on model selection performances of cross-validation procedures. This survey intends to relate these results to the most recent advances of model selection theory, with a particular emphasis on distinguishing empirical statements from rigorous theoretical results. As a conclusion, guidelines are provided for choosing the best cross-validation procedure according to the particular features of the problem in hand.},
author = {Arlot, Sylvain and Celisse, Alain},
doi = {10.1214/09-SS054},
issn = {1935-7516},
journal = {Statistics Surveys},
keywords = {Model selection,cross-validation,leave-one-out},
language = {EN},
mendeley-tags = {Model selection,cross-validation,leave-one-out},
pages = {40--79},
title = {{A survey of cross-validation procedures for model selection}},
url = {http://projecteuclid.org/euclid.ssu/1268143839},
volume = {4},
year = {2010}
}
@article{Goodman1960,
abstract = {Abstract A simple exact formula for the variance of the product of two random variables, say, x and y, is given as a function of the means and central product-moments of x and y. The usual approximate variance formula for xy is compared with this exact formula; e.g., we note, in the special case where x and y are independent, that the ?variance? computed by the approximate formula is less than the exact variance, and that the accuracy of the approximation depends on the sum of the reciprocals of the squared coefficients of variation of x and y. The case where x and y need not be independent is also studied, and exact variance formulas are presented for several different ?product estimates.? (The usefulness of exact formulas becomes apparent when the variances of these estimates are compared.) When x and y are independent, simple unbiased estimates of these exact variances are suggested; in the more general case, consistent estimates are presented.
Abstract A simple exact formula for the variance of the product of two random variables, say, x and y, is given as a function of the means and central product-moments of x and y. The usual approximate variance formula for xy is compared with this exact formula; e.g., we note, in the special case where x and y are independent, that the ?variance? computed by the approximate formula is less than the exact variance, and that the accuracy of the approximation depends on the sum of the reciprocals of the squared coefficients of variation of x and y. The case where x and y need not be independent is also studied, and exact variance formulas are presented for several different ?product estimates.? (The usefulness of exact formulas becomes apparent when the variances of these estimates are compared.) When x and y are independent, simple unbiased estimates of these exact variances are suggested; in the more general case, consistent estimates are presented.},
author = {Goodman, Leo A.},
doi = {10.1080/01621459.1960.10483369},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
month = dec,
number = {292},
pages = {708--713},
publisher = {Taylor \& Francis},
title = {{On the Exact Variance of Products}},
url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1960.10483369},
volume = {55},
year = {1960}
}
@article{Ogden2001,
author = {Ogden, Fred L. and Senarath, U. S. and Downer, Charles W. and Sharif, Hatim O.},
doi = {10.1029/2001WR000952},
issn = {1944-7973},
journal = {Water Resources Research},
language = {en},
number = {12},
pages = {3397--3400},
title = {{Reply [to “Comment on ‘On the calibration and verification of two-dimensional, distributed, Hortonian, continuous watershed models‘ by Sharika U. S. Senarath et al.”]}},
url = {http://onlinelibrary.wiley.com/doi/10.1029/2001WR000952/abstract http://onlinelibrary.wiley.com/store/10.1029/2001WR000952/asset/wrcr9235.pdf?v=1\&t=hfey41nr\&s=37d3a53dd78806c0a8b83a122599c491c11a3a3a},
volume = {37},
year = {2001}
}
@book{NationalResearchCouncil1996,
author = {{National Research Council}},
booktitle = {Small},
file = {:Users/arthur/Google Drive/References/Reports/National Academies Press docs/Nuclear\_Waste\_1996.pdf:pdf},
isbn = {0-309-56195-7},
publisher = {National Academies Press},
title = {{Nuclear Wastes: Technologies for Separations and Transmutation}},
url = {http://www.nap.edu/catalog/4912.html},
year = {1996}
}
@book{LaGrega2010,
abstract = {Hazardous waste management is a complex, interdisciplinary field that continues to grow and change as global conditions change. Mastering this evolving and multifaceted field of study requires knowledge of the sources and generation of hazardous wastes, the scientific and engineering principles necessary to eliminate the threats they pose to people and the environment, the laws regulating their disposal, and the best or most cost-effective methods for dealing with them.Written for students with some background in engineering, this comprehensive, highly acclaimed text does not only provide detailed instructions on how to solve hazardous waste problems but also guides students to think about ways to approach these problems. Each richly detailed, self-contained chapter ends with a set of discussion topics and problems. Case studies, with equations and design examples, are provided throughout the book to give students the chance to evaluate the effectiveness of different treatment and containment technologies.},
author = {LaGrega, Michael D. and Buckingham, Phillip L. and Evans, Jeffrey C.},
isbn = {9781478609346},
keywords = {Technology \& Engineering / Environmental / Waste M},
language = {en},
mendeley-tags = {Technology \& Engineering / Environmental / Waste M},
month = jul,
pages = {1231},
publisher = {Waveland Press},
shorttitle = {Hazardous Waste Management},
title = {{Hazardous Waste Management: Second Edition}},
url = {http://books.google.com/books?id=NdYYAAAAQBAJ},
year = {2010}
}
@article{Palsson1993,
abstract = {Logarithmic sensitivity coefficients were promulgated for the analysis of metabolic regulation about 20 years ago. Interest in their use has risen significantly since their introduction. However, no comprehensive evaluation of the utility of these metabolic sensitivity coefficients is available for realistic metabolic models. In this study, logarithmic sensitivity coefficients calculated from three progressively simpler metabolic models of red blood cell metabolism were compared. Two simpler models were obtained from a comprehensive red cell model by first removing volume regulation, and second by removing two pathways. The comparisons of sensitivity coefficients obtained for these three models showed that model complexity has significant effects on the numerical values and interpretation of the metabolic sensitivity coefficients. Additionally, it was found that the physiochemical volume regulatory mechanism, namely electroneutrality and osmotic balances, play an important role in the red cell metabolic flux control. In general, there is no proportionate relationship between sensitivity coefficients calculated from the three different red cell metabolic models or other simple red cell models reported in the early literature. Some sensitivity coefficients determined by different models even have opposite signs. Thus, analysis of incomplete metabolic models can be seriously misleading and produce inappropriate indicators of the characteristics of a full model for the same metabolic network.},
author = {Palsson, Bernhard O. and Lee, I-Der},
doi = {10.1006/jtbi.1993.1057},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/K7REZ2AH/Palsson and Lee - 1993 - Model Complexity has a Significant Effect on the N.pdf:pdf},
issn = {0022-5193},
journal = {Journal of Theoretical Biology},
month = apr,
number = {3},
pages = {299--315},
title = {{Model Complexity has a Significant Effect on the Numerical Value and Interpretation of Metabolic Sensitivity Coefficients}},
url = {http://www.sciencedirect.com/science/article/pii/S002251938371057X http://www.sciencedirect.com/science/article/pii/S002251938371057X/pdf?md5=489528fe3bc78e38f130d83c270453de\&pid=1-s2.0-S002251938371057X-main.pdf},
volume = {161},
year = {1993}
}
@incollection{EwaDeelman2009,
annote = {doi:10.1201/9781420069815-c12},
author = {{Ewa Deelman} and {Bruce Berriman} and {Ann Chervenak} and {Oscar Corcho} and {Paul Groth} and {Luc Moreau}},
booktitle = {Scien},
isbn = {978-1-4200-6980-8},
month = dec,
publisher = {Chapman and Hall/CRC},
series = {Chapman \& Hall/CRC Computational Science},
title = {{Metadata and Provenance Management}},
url = {http://dx.doi.org/10.1201/9781420069815-c12},
year = {2009}
}
@article{Rousseeuw2011,
abstract = {When analyzing data, outlying observations cause problems because they may strongly influence the result. Robust statistics aims at detecting the outliers by searching for the model fitted by the majority of the data. We present an overview of several robust methods and outlier detection tools. We discuss robust procedures for univariate, low-dimensional, and high-dimensional data such as estimation of location and scatter, linear regression, principal component analysis, and classification. © 2011 John Wiley \& Sons, Inc. WIREs Data Mining Knowl Discov 2011 1 73-79 DOI: 10.1002/widm.2},
author = {Rousseeuw, Peter J. and Hubert, Mia},
doi = {10.1002/widm.2},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/N2QZUCP6/abstract.html:html},
issn = {1942-4795},
journal = {Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
language = {en},
number = {1},
pages = {73--79},
title = {{Robust statistics for outlier detection}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/widm.2/abstract http://onlinelibrary.wiley.com/doi/10.1002/widm.2/abstract?deniedAccessCustomisedMessage=\&userIsAuthenticated=false},
volume = {1},
year = {2011}
}
@incollection{McLeod2011,
abstract = {This chapter provides a summary of the practical issues associated with the collection of municipal solid waste and of the challenges faced in trying to develop accurate waste collection models. The chapter highlights the variety of materials that are collected and the many collection options available (e.g. containers, vehicles, collection frequencies and methods). Waste collection problems and methods include: locating facilities (e.g. vehicle depots, waste disposal sites); sub-dividing rounds into districts for ease of operation and of optimisation; specifying the aggregation level for the collection points to be modelled (e.g. postcode, street, block) and then estimating the waste volume to be collected from each collection point; and optimising vehicle routes and schedules. The chapter concludes with four case study examples of modelling research results from around the world.
This chapter deals with the process of waste collection. It describes the waste materials that are collected, the collection systems that are typically used, and the types of vehicles and other equipment used. It also explains vehicle routing and scheduling, in terms of its capabilities, limitations, and data requirements, and provides some case study examples from around the world to give an indication of the range of waste collection problems and of what benefits may be achievable through the use of waste collection vehicle routing and scheduling methods. There are many different types and sources of waste, ranging from household garbage to debris found in outer space. This chapter focuses on the collection of municipal solid waste (MSW), which normally comprises waste from households, streets, parks, schools, hospitals, and some commercial businesses. Waste collection is a multi-faceted problem that can be considered at different levels, from the high level, strategic, policy or planning viewpoints, to more low level, tactical or operational decisions. It is very much in the interests of waste collection authorities (WCAs) worldwide to devise efficient working methods to keep their operating costs as low as possible while providing a good level of service to householders, trade customers, and other interested parties.},
address = {Boston},
author = {McLeod, Fraser and Cherrett, Tom},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/5NK8ISN7/McLeod and Cherrett - 2011 - Chapter 4 - Waste Collection.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {61--73},
publisher = {Academic Press},
title = {{Chapter 4 - Waste Collection}},
url = {http://www.sciencedirect.com/science/article/pii/B978012381475310004X http://www.sciencedirect.com/science/article/pii/B978012381475310004X/pdfft?md5=77e1591f234094d6ca7bfa08bc6e0026\&pid=3-s2.0-B978012381475310004X-main.pdf},
year = {2011}
}
@article{Grayson1992a,
abstract = {THALES, a simple distributed parameter hydrologic model is presented and applied to two catchments in Australia and the United States, each with different dominant hydrologic responses. The model simulates Hortonian overland flow and runoff from saturated source areas and is used to identify some of the barriers to modeling the hydrology of small catchments. At Wagga Wagga in New South Wales, Australia, runoff is produced from saturated source areas, whereas on the Lucky Hills catchments at Walnut Gulch in Arizona, Hortonian overland flow processes dominate. Simulations at Wagga Wagga are based on published parameters and field data measured as part of an intensive field program and result in a relatively poor fit of the outflow hydrographs for a series of storms. The simulated position and growth of saturated areas coincides with the limited available information, indicating that at least the gross effects of subsurface water movement are being represented. For the Lucky Hills catchments, the hydrographs at the catchment outlet and points within the catchment are simulated for a storm series. The results are highly dependent on the parameter values, which are poorly defined, highlighting the lack of measured field data and lack of methodology for the collection of data at a scale appropriate for such models. The model structure is also shown to have a major influence on the output. The influence of simulating surface flow as sheet flow or rill flow or through a series of ephemeral gullies, as well as the choice of the surface roughness parameter and antecedent soil water conditions, is shown to have a profound effect on the distributed flow depth and velocity predictions. By fitting model parameters, a simulation assuming Hortonian overland flow produced similar results at the catchment outlet to those based on partial area runoff. These results are of concern since it is common to calibrate and verify hydrologic models based on the accuracy with which the catchment outflow is predicted. The internal estimates of flow characteristics following such a calibration often provide the input to sediment and nutrient transport models. Models such as THALES produce an enormous amount of information and have the theoretical potential to provide a “universal” tool for the representation of hydrologic response. However, problems of verification and validation of such models are acute. These problems relate to the difficulty in measuring/deriving parameters a priori, measurement of the catchment response in sufficient detail for testing, and the validity of the fundamental assumptions and algorithms used in model development.},
author = {Grayson, Rodger B. and Moore, Ian D. and McMahon, Thomas A.},
doi = {10.1029/92WR01258},
issn = {1944-7973},
journal = {Water Resources Research},
language = {en},
number = {10},
pages = {2639--2658},
shorttitle = {Physically based hydrologic modeling},
title = {{Physically based hydrologic modeling: 1. A terrain-based model for investigative purposes}},
url = {http://onlinelibrary.wiley.com/doi/10.1029/92WR01258/abstract http://onlinelibrary.wiley.com/store/10.1029/92WR01258/asset/wrcr5853.pdf?v=1\&t=hfezhhyc\&s=1f2a6e1246c30086f958c8ffc4a4dfb34faa8344},
volume = {28},
year = {1992}
}
@article{Jamshidzadeh2013,
abstract = {Abstract This study introduces the dispersive fluid flux of total fluid mass to the density-driven flow equation to improve thermohaline modeling of salt and heat transports in porous media. The dispersive fluid flux in the flow equation is derived to account for an additional fluid flux driven by the density gradient and mechanical dispersion. The coupled flow, salt transport and heat transport governing equations are numerically solved by a fully implicit finite difference method to investigate solution changes due to the dispersive fluid flux. The numerical solutions are verified by the Henry problem and the thermal Elder problem under a moderate density effect and by the brine Elder problem under a strong density effect. It is found that increment of the maximum ratio of the dispersive fluid flux to the advective fluid flux results in increasing dispersivity for the Henry problem and the brine Elder problem. The effects of the dispersive fluid flux on salt and heat transports under high density differences and high dispersivities are more noticeable than under low density differences and low dispersivities. Values of quantitative indicators such as the Nusselt number, mass flux, salt mass stored and maximum penetration depth in the brine Elder problem show noticeable changes by the dispersive fluid flux. In the thermohaline Elder problem, the dispersive fluid flux shows a considerable effect on the shape and the number of developed fingers and makes either an upwelling or a downwelling flow in the center of the domain. In conclusion, for the general case that involves strong density-driven flow and transport modeling in porous media, the dispersive fluid flux should be considered in the flow equation.},
author = {Jamshidzadeh, Zahra and Tsai, FTC},
doi = {10.1016/j.advwatres.2013.08.006},
issn = {0309-1708},
journal = {Advances in Water \ldots},
keywords = {Density-driven flow,Elder problem,Fluid dispersion,HENRY problem,Porous media,Thermohaline},
mendeley-tags = {Density-driven flow,Elder problem,Fluid dispersion,HENRY problem,Porous media,Thermohaline},
title = {{Fluid dispersion effects on density-driven thermohaline flow and transport in porous media}},
url = {http://www.sciencedirect.com/science/article/pii/S0309170813001450 http://www.sciencedirect.com/science/article/pii/S0309170813001450/pdfft?md5=30dbdc729664f9720c2f88af1d010639\&pid=1-s2.0-S0309170813001450-main.pdf},
year = {2013}
}
@incollection{Pichtel2014ch2,
author = {Pichtel, John},
booktitle = {Waste Management Practices: Municipal, Hazardous, and Industrial, Second Edition},
chapter = {2},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/VK43QSNK/2014 - A Brief History of Waste Management.pdf:pdf},
isbn = {978-1-4665-8518-8},
month = jan,
pages = {21--46},
publisher = {CRC Press},
title = {{A Brief History of Waste Management}},
url = {http://www.crcnetbase.com/doi/abs/10.1201/b16576-4 http://www.crcnetbase.com/doi/pdf/10.1201/b16576-4},
year = {2014}
}
@techreport{EPA2004,
author = {{Environmental Protection Agency}},
institution = {United States Environmental Protection Agency},
title = {{Cleaning Up the Nation's Waste Sites: Markets and Technology Trends}},
url = {http://clu-in.org/download/market/2004market.pdf},
year = {2004}
}
@article{Sacks:1989p345,
author = {Sacks, Jerry and Welch, W J and Mitchell, T J and Wynn, H P},
journal = {Statistical Science},
pages = {409--423},
title = {{Design and analysis of computer experiments}},
year = {1989}
}
@article{Woods2002,
author = {Grayson, Rodger B. and Bl\"{o}schl, G\"{u}nter and Woods, Ross A.},
doi = {10.1002/hyp.539},
issn = {0885-6087},
journal = {Hydrol. Process},
month = apr,
number = {5},
pages = {1111--1113},
title = {{Seeing catchments with new eyes}},
url = {http://www.cof.orst.edu/cof/fe/watershd/Documents/HPToday/web/pdfs/woods-bookreview.pdf},
volume = {16},
year = {2002}
}
@article{Vuorinen2007,
author = {Vuorinen, H.S. and Juuti, P.S. and Katko, T.S.},
doi = {10.2166/ws.2007.006},
issn = {16069749},
journal = {Water Science \& Technology: Water Supply},
keywords = {Folder - ch1},
mendeley-tags = {Folder - ch1},
month = mar,
number = {1},
pages = {49},
title = {{History of water and health from ancient civilizations to modern times}},
url = {http://www.iwaponline.com/ws/00701/ws007010049.htm},
volume = {7},
year = {2007}
}
@article{Kaplan2013,
author = {Kaplan, Daniel I. and Zhang, Saijin and Roberts, Kimberly A. and Schwehr, Kathy and Xu, Chen and Creeley, Danielle and Ho, Yi-Fang and Li, Hsiu-Ping and Yeager, Chris M. and Santschi, Peter H.},
doi = {10.1016/j.jenvrad.2013.09.001},
issn = {0265931X},
journal = {Journal of Environmental Radioactivity},
month = sep,
title = {{Radioiodine concentrated in a wetland}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0265931X13002014},
year = {2013}
}
@book{NationalResearchCouncil1984,
address = {Washington, D.C.},
author = {{National Research Council}},
file = {:Users/arthur/Google Drive/References/Reports/National Academies Press docs/Groundwater\_Contamination\_1984\_1770.pdf:pdf},
isbn = {0309034418},
pages = {179},
publisher = {The National Academies Press},
title = {{Groundwater Contamination}},
year = {1984}
}
@article{Bea2013a,
abstract = {Abstract Acidic low-level waste radioactive waste solutions were discharged to three unlined seepage basins at the F-Area of the Department of Energy (DOE) Savannah River Site (SRS), South Carolina, USA, from 1955 through 1989. Despite of many years of active remediation, the groundwater remains acidic and contaminated with significant levels of U(VI) and other radionuclides. Monitored Natural Attenuation (MNA) is a desired closure strategy for the site, based on the premise that regional flow of clean background groundwater will eventually neutralize the groundwater acidity, immobilizing U(VI) through adsorption. An in situ treatment system is currently in place to accelerate this in the downgradient portion of the plume and similar measures could be taken upgradient if necessary. Understanding the long-term pH and U(VI) adsorption behavior at the site is critical to assess feasibility of MNA along with the in-situ remediation treatments. This paper presents a reactive transport (RT) model and uncertainty quantification (UQ) analyses to explore key controls on the U(VI)-plume evolution and long-term mobility at this site. Two-dimensional numerical RT simulations are run including the saturated and unsaturated (vadose) zones, U(VI) and H+ adsorption (surface complexation) onto sediments, dissolution and precipitation of Al and Fe minerals, and key hydrodynamic processes are considered. UQ techniques are applied using a new open-source tool that is part of the developing ASCEM reactive transport modeling and analysis framework to: (1) identify the complex physical and geochemical processes that control the U(VI) plume migration in the pH range where the plume is highly mobile, (2) evaluate those physical and geochemical parameters that are most controlling, and (3) predict the future plume evolution constrained by historical chemical and hydrological data. The RT simulation results show a good agreement with the observed historical pH and concentrations of U(VI), nitrates and Al concentrations at multiple locations. Mineral dissolution and precipitation combined with adsorption reactions on goethite and kaolinite (the main minerals present with quartz) could buffer pH at the site for long periods of time. UQ analyses using the Morris one-at-a-time (OAT) method indicates that the model/parameter are most sensitive to the pH of the waste solution, discharge rates, and the reactive surface area available for adsorption. However, as a key finding, UQ analysis also indicates that this model (and parameters) sensitivity evolves in space and time, and its understanding could be crucial to assess the temporal efficiency of a remediation strategy in contaminated sites. Results also indicate that residual U(VI) and H + adsorbed in the vadose zone, as well as aquifer permeability, could have a significant impact on the acidic plume long-term mobility.},
author = {Bea, SA and Wainwright, Haruko},
doi = {10.1016/j.jconhyd.2013.04.005},
issn = {0169-7722},
journal = {Journal of contaminant \ldots},
keywords = {ASCEM,Acidic Plume,Reactive Facies,Reactive Transport Modeling,Richards equation,Surface Complexation Modeling,Uncertainty Quantification,Uranium,Vadose Zone},
mendeley-tags = {ASCEM,Acidic Plume,Reactive Facies,Reactive Transport Modeling,Richards equation,Surface Complexation Modeling,Uncertainty Quantification,Uranium,Vadose Zone},
title = {{Identifying key controls on the behavior of an acidic-U (VI) plume in the Savannah River Site using reactive transport modeling}},
url = {http://www.sciencedirect.com/science/article/pii/S0169772213000612 http://www.sciencedirect.com/science?\_ob=MiamiImageURL\&\_cid=271864\&\_user=4420\&\_pii=S0169772213000612\&\_check=y\&\_origin=article\&\_zone=toolbar\&\_coverDate=2013-May-01\&view=c\&originContentFamily=serial\&wchp=dGLzVBA-zSkWz\&md5=15356e206e4573f445afe0b5a4d90d4c\&pid=1-s2.0-S0169772213000612-main.pdf},
year = {2013}
}
@article{Sun2003,
abstract = {Several numerical codes have been used to simulate radionuclide transport in fractured rock systems. The validation of such numerical codes can be accomplished by comparison of numerical simulations against appropriate analytical solutions. In this paper, we present analytical solutions for the reactive transport of N-member radionuclide chains (i.e., multiple species of radionuclides and their daughter species) through a discrete fracture in a porous rock matrix applying a system decomposition approach. We consider the transport of N-member radionuclide chains in a single-fracture–matrix system as a starting point to simulate more realistic and complex systems. The processes considered are advection along the fracture, lateral diffusion in the matrix, radioactive decay of multiple radionuclides, and adsorption in both the fracture and matrix. Different retardation factors can be specified for the fracture and matrix. However, all species are assumed to share the same retardation factors for the fracture and matrix, respectively. Although a daughter species may penetrate farther along the fracture than its parent species when a constant-concentration boundary condition is applied, our results indicate that all species retain the same transport speed in the fracture if a pulse of the first species is released into the fracture. This solution scheme provides a way to validate numerical computer codes of radionuclide transport in fractured rock, such as those being used to assess the performance of a potential nuclear-waste repository at Yucca Mountain.},
author = {Sun, Yunwei and Buscheck, Thomas A.},
doi = {10.1016/S0169-7722(02)00181-X},
issn = {0169-7722},
journal = {Journal of Contaminant Hydrology},
keywords = {Analytical solution,Decay,Fracture,Multi-species,Radionuclide,Reactive transport},
mendeley-tags = {Analytical solution,Decay,Fracture,Multi-species,Radionuclide,Reactive transport},
month = apr,
pages = {695--712},
shorttitle = {JCH SI. Yucca Mountain},
title = {{Analytical solutions for reactive transport of N-member radionuclide chains in a single fracture}},
url = {http://www.sciencedirect.com/science/article/pii/S016977220200181X http://pdn.sciencedirect.com/science?\_ob=MiamiImageURL\&\_cid=271864\&\_user=4420\&\_pii=S016977220200181X\&\_check=y\&\_origin=article\&\_zone=toolbar\&\_coverDate=2003--31\&view=c\&originContentFamily=serial\&wchp=dGLbVlV-zSkWz\&md5=5ce9128e602fdf31a40fb80d86f08632\&pid=1-s2.0-S016977220200181X-main.pdf},
volume = {62–63},
year = {2003}
}
@incollection{PerSvensson2009,
annote = {doi:10.1201/9781420069815-c7},
author = {{Per Svensson} and {Peter Boncz} and {Milena Ivanova} and {Martin Kersten} and {Niels Nes} and {Doron Rotem}},
booktitle = {Scien},
isbn = {978-1-4200-6980-8},
month = dec,
publisher = {Chapman and Hall/CRC},
series = {Chapman \& Hall/CRC Computational Science},
title = {{Emerging Database Systems in Support of Scientific Data}},
url = {http://dx.doi.org/10.1201/9781420069815-c7},
year = {2009}
}
@article{Bloschl1995a,
author = {Bl\"{o}schl, G\"{u}nter and Grayson, Rodger B. and Sivapalan, M.},
journal = {Hydrological Processes},
number = {3-4},
pages = {313--330},
title = {{On the representative elementary area (REA) concept and its utility for distributed rainfall-runoff modelling}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/hyp.3360090307/abstract http://www.hydro.tuwien.ac.at/fileadmin/mediapool-hydro/Publikationen/bloeschl/1995\_Bloeschl\_HP\_b.pdf},
volume = {9},
year = {1995}
}
@book{NationalResearchCouncil2011,
address = {Washington, D.C.},
author = {{National Research Council}},
isbn = {9780309187336},
title = {{Waste Forms Technology and Performance : Final Report}},
year = {2011}
}
@article{Steiger1990,
author = {Steiger, James H.},
doi = {10.1207/s15327906mbr2502\_4},
issn = {0027-3171},
journal = {Multivariate Behavioral Research},
number = {2},
pages = {173--180},
shorttitle = {Structural Model Evaluation and Modification},
title = {{Structural Model Evaluation and Modification: An Interval Estimation Approach}},
url = {http://dx.doi.org/10.1207/s15327906mbr2502\_4},
volume = {25},
year = {1990}
}
@article{Fedchenko2014,
abstract = {Abstract The purpose of the nuclear security regime is to prevent, detect and respond to nuclear security events (e.g. illicit trafficking of nuclear material or a nuclear terrorism attack). Nuclear forensic analysis is a key technical capability that utilises signatures inherent to nuclear or other radioactive material to provide information on its source, production and history. It can be used as part of the response to the nuclear security event, as well as to help prevent it. Section I of this article will introduce the basic information about nuclear forensic analysis. Section II, which constitutes the main body of the article, will describe in detail how the process of nuclear forensic analysis works in case of a nuclear security event investigation, and provide examples to illustrate specific points. Section III will conclude the article by discussing how nuclear forensics can be utilised not just for a post-event investigation but also for prevention of nuclear security events.},
author = {Fedchenko, Vitaly},
doi = {10.1080/09700161.2014.884442},
issn = {0970-0161},
journal = {Strategic Analysis},
number = {2},
pages = {230--247},
title = {{The Role of Nuclear Forensics in Nuclear Security}},
url = {http://www.tandfonline.com/doi/abs/10.1080/09700161.2014.884442},
volume = {38},
year = {2014}
}
@article{Hassan2011,
abstract = {This article seeks to explore the spatial variability of groundwater arsenic (As) concentrations in Southwestern Bangladesh. Facts about spatial pattern of As are important to understand the complex processes of As concentrations and its spatial predictions in the unsampled areas of the study site. The relevant As data for this study were collected from Southwest Bangladesh and were analyzed with Flow Injection Hydride Generation Atomic Absorption Spectrometry (FI-HG-AAS). A geostatistical analysis with Indicator Kriging (IK) was employed to investigate the regionalized variation of As concentration. The IK prediction map shows a highly uneven spatial pattern of arsenic concentrations. The safe zones are mainly concentrated in the north, central and south part of the study area in a scattered manner, while the contamination zones are found to be concentrated in the west and northeast parts of the study area. The southwest part of the study area is contaminated with a highly irregular pattern. A Generalized Linear Model (GLM) was also used to investigate the relationship between As concentrations and aquifer depths. A negligible negative correlation between aquifer depth and arsenic concentrations was found in the study area. The fitted value with 95 \% confidence interval shows a decreasing tendency of arsenic concentrations with the increase of aquifer depth. The adjusted mean smoothed lowess curve with a bandwidth of 0.8 shows an increasing trend of arsenic concentration up to a depth of 75 m, with some erratic fluctuations and regional variations at the depth between 30 m and 60 m. The borehole lithology was considered to analyze and map the pattern of As variability with aquifer depths. The study has performed an investigation of spatial pattern and variation of As concentrations.},
author = {Hassan, M Manzurul and Atkins, Peter J},
doi = {10.1080/10934529.2011.598771},
issn = {1532-4117},
journal = {Journal of environmental science and health. Part A, Toxic/hazardous substances \& environmental engineering},
keywords = {Arsenic,Bangladesh,Environmental Monitoring,Groundwater,Models- Chemical,Risk Assessment,Statistics- Nonparametric,Water Pollutants- Chemical},
language = {eng},
mendeley-tags = {Arsenic,Bangladesh,Environmental Monitoring,Groundwater,Models- Chemical,Risk Assessment,Statistics- Nonparametric,Water Pollutants- Chemical},
number = {11},
pages = {1185--1196},
title = {{Application of geostatistics with Indicator Kriging for analyzing spatial variability of groundwater arsenic concentrations in Southwest Bangladesh}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21879851 http://www.tandfonline.com/doi/abs/10.1080/10934529.2011.598771?url\_ver=Z39.88-2003\&rfr\_id=ori:rid:crossref.org\&rfr\_dat=cr\_pub=pubmed\#.UZXNbcGk-So http://www.tandfonline.com/doi/pdf/10.1080/10934529.2011.598771},
volume = {46},
year = {2011}
}
@article{Grayson1992,
author = {Grayson, Rodger B. and Moore, Ian D. and McMahon, Thomas a.},
doi = {10.1029/92WR01258},
issn = {00431397},
journal = {Water Resources Research},
month = oct,
number = {10},
pages = {2639--2658},
title = {{Physically based hydrologic modeling: 1. A terrain-based model for investigative purposes}},
url = {http://doi.wiley.com/10.1029/92WR01258},
volume = {28},
year = {1992}
}
@article{Butters1989,
abstract = {Modeling the field scale movement of chemicals in unsaturated soil is of intense interest to both the public and private sectors and has become an area of active theoretical research in a number of environmentally based disciplines. However, the experimental data needed to validate existing solute transport models and to inspire the development of more refined approaches is very limited. In this research study, the movement of a mobile tracer (Br−) was monitored as it moved through the unsaturated zone beneath the soil surface of a 0.64 ha loamy sand field. Under flux-controlled, steady state water flow achieved by bidaily sprinkler irrigation, a narrow pulse of 58.9 mol/m−3 NaBr(aq) was applied uniformly to the field and subsequently leached downward while monitored by vacuum solution samplers replicated 16 times at each of 6 depths between 0.3 and 3.0 m and 6 times at the 4.5-m depth. Six deep soil cores to a maximum of 25 m were taken to characterize the final field average bromide depth profile after the pulse had passed the 4.5-m depth. Although the mass recovery of the area-averaged pulse was near 100\% at all depths, the coefficient of variation (CV) of mass recovery between samplers at a given depth was near 50\%. Lateral variations in apparent vertical solute velocity or in solute transport volume were considerable, with CVs near 50\% in the shallow monitoring depths. However, variations in transport volume with depth at a given site were also large, even though the solution samplers for different depths were displaced laterally by only 0.3–0.6 m at different sites. The mean vertical velocity of the area-averaged solute pulse was significantly less than the ratio of the average net water flux to the average volumetric water content, until approximately 1.8 m. The difference between the two average velocities near the surface was large enough (nearly a factor of 2) to suggest that transient effects from the bidaily irrigations were influencing solute transport.},
author = {Butters, Greg L. and Jury, William A. and Ernst, Frederick F.},
doi = {10.1029/WR025i007p01575},
issn = {1944-7973},
journal = {Water Resources Research},
language = {en},
number = {7},
pages = {1575--1581},
shorttitle = {Field scale transport of bromide in an unsaturated},
title = {{Field scale transport of bromide in an unsaturated soil: 1. Experimental methodology and results}},
url = {http://onlinelibrary.wiley.com/doi/10.1029/WR025i007p01575/abstract http://onlinelibrary.wiley.com/doi/10.1029/WR025i007p01575/full http://onlinelibrary.wiley.com/store/10.1029/WR025i007p01575/asset/wrcr4863.pdf?v=1\&t=hl1oz0t3\&s=29be8610c3ba14b93379240cd654bfb7e569aff8},
volume = {25},
year = {1989}
}
@incollection{Macias-Zamora2011,
abstract = {Ocean pollution has become one of the largest and sometimes even conflicting subjects which very often result in threats to marine ecosystems, human health, and diminishing food sources. Ocean waste includes all material that is discarded accidentally or purposefully from vessels, ships, and other ocean transport. It also includes waste that enters waterways and rivers which flows into the sea and also waste from human habitation living in coastal areas close to the sea. Ocean waste can also result from ocean storms waves, tsunamis, and other extreme marine events. Some of these are the result of poor handling of cargo on ships and vessels. In some countries such as the United States, the Environmental Protection Agency (EPA) and the National Oceanic and Atmospheric Administration are responsible, along with the U.S. Navy and the Coast Guard and other agencies, for the management and control of ocean waste. The Inter-agency of the Marine Debris Coordinating Committee are responsible for the rules and regulation and recommendations for the handling this form of waste. In less developed nations such as Mexico, there are also incipient programs to handle ocean waste. It is important that progress be made in controlling waste discharges into the ocean. There is strong evidence that when correct measures are taken, not only the ocean but also land and many organisms are spared from the consequences of chemical pollutants.},
address = {Boston},
author = {Mac\'{\i}as-Zamora, J. Vinicio},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
isbn = {978-0-12-381475-3},
pages = {265--279},
publisher = {Academic Press},
title = {{Chapter 19 - Ocean Pollution}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100191 http://www.sciencedirect.com/science/article/pii/B9780123814753100191/pdfft?md5=c0d7e3e45edc1c01b43f9cb706b1cc20\&pid=3-s2.0-B9780123814753100191-main.pdf},
year = {2011}
}
@article{Grayson2001,
author = {Grayson, Rodger B. and Bl\"{o}schl, G\"{u}nter},
journal = {Spatial Patterns in Catchment Hydrology: Observations and Modelling},
pages = {51--81},
title = {{Spatial modelling of catchment dynamics}},
url = {http://books.google.com/books?hl=en\&lr=\&id=ZPQ8AAAAIAAJ\&oi=fnd\&pg=PA51\&dq=G\"{u}nter+Bl\"{o}schl\&ots=jVXD-uabT-\&sig=Zpwr\_9FRqsCRT-y7HqQJ-IUDE5E http://www.catchment.crc.org.au/downloads/spatial\_patterns/Part1\_chapters/Chapter3.pdf},
year = {2001}
}
@article{Gong2013,
abstract = {With growing interest in understanding the magnitudes and sources of uncertainty in hydrological modeling, the difficult problem of characterizing model structure adequacy is now attracting considerable attention. Here, we examine this problem via a model-structure-independent approach based in information theory. In particular, we (a) discuss how to assess and compute the information content in multivariate hydrological data, (b) present practical methods for quantifying the uncertainty and shared information in data while accounting for heteroscedasticity, (c) show how these tools can be used to estimate the best achievable predictive performance of a model (for a system given the available data), and (d) show how model adequacy can be characterized in terms of the magnitude and nature of its aleatory uncertainty that cannot be diminished (and is resolvable only up to specification of its density), and its epistemic uncertainty that can, in principle, be suitably resolved by improving the model. An illustrative modeling example is provided using catchment-scale data from three river basins, the Leaf and Chunky River basins in the United States and the Chuzhou basin in China. Our analysis shows that the aleatory uncertainty associated with making catchment simulations using this data set is significant (∼50\%). Further, estimated epistemic uncertainties of the HyMod, SAC-SMA, and Xinanjiang model hypotheses indicate that considerable room for model structural improvements remain.},
author = {Gong, Wei and Gupta, Hoshin V. and Yang, Dawen and Sricharan, Kumar and Hero, Alfred O.},
doi = {10.1002/wrcr.20161},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/UAB23VH7/Gong et al. - 2013 - Estimating epistemic and aleatory uncertainties du.pdf:pdf},
issn = {1944-7973},
journal = {Water Resources Research},
keywords = {entropy,information theory,model structure adequacy,mutual information,uncertainty analysis},
language = {en},
mendeley-tags = {entropy,information theory,model structure adequacy,mutual information,uncertainty analysis},
number = {4},
pages = {2253--2273},
shorttitle = {Estimating epistemic and aleatory uncertainties du},
title = {{Estimating epistemic and aleatory uncertainties during hydrologic modeling: An information theoretic approach}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/wrcr.20161/abstract http://onlinelibrary.wiley.com/store/10.1002/wrcr.20161/asset/wrcr20161.pdf?v=1\&t=hrhgfiph\&s=9ff9ec54a7c9a49a44a133da2f4bd923f50255a9},
volume = {49},
year = {2013}
}
@article{Beck1987,
author = {Beck, M. B.},
doi = {10.1029/WR023i008p01393},
issn = {00431397},
journal = {Water Resources Research},
month = aug,
number = {8},
pages = {1393--1442},
title = {{Water quality modeling: A review of the analysis of uncertainty}},
url = {http://doi.wiley.com/10.1029/WR023i008p01393},
volume = {23},
year = {1987}
}
@article{Amoozegar-Fard1982,
author = {Amoozegar-Fard, A. and Nielsen, D. R. and Warrick, A. W.},
doi = {10.2136/sssaj1982.03615995004600010001x},
issn = {0361-5995},
journal = {Soil Science Society of America Journal},
language = {en},
number = {1},
pages = {3--9},
title = {{Soil Solute Concentration Distributions for Spatially Varying Pore Water Velocities and Apparent Diffusion Coefficients}},
url = {https://dl.sciencesocieties.org/publications/sssaj/abstracts/46/1/SS0460010003},
volume = {46},
year = {1982}
}
@incollection{Cui2011a,
abstract = {This chapter provides an overview of electronic waste, current status of the management of electronic waste (e-waste), and recycling technologies for the recovery of metals from end-of-life electronic equipment. Because of the ever increasing generation of e-waste and the hazardous nature of this waste stream, e-waste is an emerging issue. Many countries have drafted legislation to improve the reuse, recycling, and other forms of recovery of such waste. Electronic waste is significantly heterogeneous and complex in terms of the type of components and materials. However, copper and precious metals make up more than 80\% of the value for most of the e-waste samples. This indicates that the recovery of precious metals and copper may remain as the major economic driver for a long time. The hierarchy of treatment of e-waste encourages the reuse of the whole equipment first, remanufacturing, then recovery of materials by recycling techniques, and as a last resort, disposal by incineration and landfilling. Recycling of e-waste can be broadly divided into three major steps—selective disassembly, targeting, and singling out hazardous or valuable components for special treatment; mechanical and metallurgical processing to upgrade desirable materials content; and refining recovered materials that are retreated or purified by using chemical (metallurgical) processing so as to be acceptable for further use in their original application.},
address = {Boston},
author = {Cui, Jirang and {J\o rgen Roven}, Hans},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
isbn = {978-0-12-381475-3},
pages = {281--296},
publisher = {Academic Press},
title = {{Chapter 20 - Electronic Waste}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100208 http://www.sciencedirect.com/science/article/pii/B9780123814753100208/pdfft?md5=dd95960890b739e94178daf3445d1e55\&pid=3-s2.0-B9780123814753100208-main.pdf},
year = {2011}
}
@article{She2011,
author = {She, Yiyuan and Owen, Art B.},
doi = {10.1198/jasa.2011.tm10390},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/WEIKDHVZ/jasa.2011.html:html;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/DKK3DNMG/jasa.2011.html:html},
issn = {0162-1459, 1537-274X},
journal = {Journal of the American Statistical Association},
month = jun,
number = {494},
pages = {626--639},
title = {{Outlier Detection Using Nonconvex Penalized Regression}},
url = {http://amstat.tandfonline.com/doi/abs/10.1198/jasa.2011.tm10390},
volume = {106},
year = {2011}
}
@article{Nash1970,
abstract = {The principles governing the application of the conceptual model technique to river flow forecasting are discussed. The necessity for a systematic approach to the development and testing of the model is explained and some preliminary ideas suggested.},
author = {Nash, J.E. and Sutcliffe, J.V.},
doi = {10.1016/0022-1694(70)90255-6},
issn = {0022-1694},
journal = {Journal of Hydrology},
month = apr,
number = {3},
pages = {282--290},
title = {{River flow forecasting through conceptual models part I — A discussion of principles}},
url = {http://www.sciencedirect.com/science/article/pii/0022169470902556 http://pdn.sciencedirect.com/science?\_ob=MiamiImageURL\&\_cid=271842\&\_user=4420\&\_pii=0022169470902556\&\_check=y\&\_origin=article\&\_zone=toolbar\&\_coverDate=1970--30\&view=c\&originContentFamily=serial\&wchp=dGLbVlB-zSkzS\&md5=dbe0a52180a8b34b2c9447e443053439\&pid=1-s2.0-0022169470902556-main.pdf},
volume = {10},
year = {1970}
}
@incollection{EkowOtoo2009,
annote = {doi:10.1201/9781420069815-c6},
author = {{Ekow Otoo} and {Kesheng Wu}},
booktitle = {Scien},
isbn = {978-1-4200-6980-8},
month = dec,
publisher = {Chapman and Hall/CRC},
series = {Chapman \& Hall/CRC Computational Science},
title = {{Accelerating Queries on Very Large Datasets}},
url = {http://dx.doi.org/10.1201/9781420069815-c6},
year = {2009}
}
@book{NationalResearchCouncil2006,
address = {Washington, D.C.},
author = {{National Research Council}},
booktitle = {Management},
isbn = {0309658381},
publisher = {National Academies Press},
title = {{Improving the Regulation and Management of Low-Activity Radioactive Wastes}},
url = {http://www.nap.edu/catalog/11595.html},
year = {2006}
}
@article{Foglia2007,
abstract = {Many methods can be used to test alternative ground water models. Of concern in this work are methods able to (1) rank alternative models (also called model discrimination) and (2) identify observations important to parameter estimates and predictions (equivalent to the purpose served by some types of sensitivity analysis). Some of the measures investigated are computationally efficient; others are computationally demanding. The latter are generally needed to account for model nonlinearity. The efficient model discrimination methods investigated include the information criteria: the corrected Akaike information criterion, Bayesian information criterion, and generalized cross-validation. The efficient sensitivity analysis measures used are dimensionless scaled sensitivity (DSS), composite scaled sensitivity, and parameter correlation coefficient (PCC); the other statistics are DFBETAS, Cook's D, and observation-prediction statistic. Acronyms are explained in the introduction. Cross-validation (CV) is a computationally intensive nonlinear method that is used for both model discrimination and sensitivity analysis. The methods are tested using up to five alternative parsimoniously constructed models of the ground water system of the Maggia Valley in southern Switzerland. The alternative models differ in their representation of hydraulic conductivity. A new method for graphically representing CV and sensitivity analysis results for complex models is presented and used to evaluate the utility of the efficient statistics. The results indicate that for model selection, the information criteria produce similar results at much smaller computational cost than CV. For identifying important observations, the only obviously inferior linear measure is DSS; the poor performance was expected because DSS does not include the effects of parameter correlation and PCC reveals large parameter correlations.},
author = {Foglia, L and Mehl, S W and Hill, M C and Perona, P and Burlando, P},
doi = {10.1111/j.1745-6584.2007.00341.x},
issn = {0017-467X},
journal = {Ground water},
keywords = {Models, Statistical,Models, Theoretical,Reproducibility of Results,Switzerland,Water Movements,Water Supply},
number = {5},
pages = {627--41},
pmid = {17760588},
title = {{Testing alternative ground water models using cross-validation and other methods.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17760588},
volume = {45},
year = {2007}
}
@article{Webster1984,
abstract = {The purpose of this paper is to present a statistically based methodology for selecting the method to be used for generating sample values in a simulation model when alternate methods are available. Choosing which method to use is not a simple task, but very important because it affects the complexity and ultimately the costs associated with the model's development and the model's expected uses. The methodology is presented by means of a case study where it was used in the development of a timber harvesting simulation model. The methodology is primarily based upon analysis of variance and demonstrates one way which has been used in choosing between varying levels of complexity in generating random samples within a simulation model using as a criterion the validity of the alternate methods' results.},
author = {Webster, Dennis B. and Padgett, Mary L. and Hines, Gail S. and Sirois, Donald L.},
doi = {10.1016/0360-8352(84)90014-7},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/QVSJZ6EP/Webster et al. - 1984 - Determining the level of detail in a simulation mo.pdf:pdf},
issn = {0360-8352},
journal = {Computers \& Industrial Engineering},
number = {3–4},
pages = {215--225},
title = {{Determining the level of detail in a simulation model—a case study}},
url = {http://www.sciencedirect.com/science/article/pii/0360835284900147 http://www.sciencedirect.com/science/article/pii/0360835284900147/pdf?md5=89d8a826ab857ecad7326d02f66ae8c3\&pid=1-s2.0-0360835284900147-main.pdf},
volume = {8},
year = {1984}
}
@article{Mouri2014,
abstract = {We estimated the flux of caesium-137 adsorbed to suspended sediment in the Kusaki Dam reservoir in the Fukushima region of eastern Japan, which was contaminated by the Fukushima Nuclear Power Plant accident. The amount and rate of reservoir sedimentation and the caesium-137 concentration were validated based on the mixed-particle distribution and a sediment transport equation. The caesium-137 and sediment flux data suggested that wash load, suspended load sediment, and caesium-137 were deposited and the discharge and transport processes generated acute pollution, especially during extreme rainfall-runoff events. Additionally, we qualitatively assessed future changes in caesium-137 and sediment fluxes in the reservoir. The higher deposition and discharge at the start of the projection compared to the 2090s are most likely explained by the radioactive decay of caesium-137 and the effects of reservoir sedimentation. Predictions of the impacts of future climate on sediment and caesium-137 fluxes are crucial for environmental planning and management.},
author = {Mouri, Goro and Golosov, Valentin and Shiiba, Michiharu and Hori, Tomoharu},
doi = {10.1016/j.envpol.2013.12.018},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/ZIHSFIU5/S0269749113006519.html:html;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/8TFVEIDI/Mouri et al. - 2014 - Assessment of the caesium-137 flux adsorbed to sus.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/3A7E8CSZ/S0269749113006519.html:html;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/78CWZIGJ/Mouri et al. - 2014 - Assessment of the caesium-137 flux adsorbed to sus.pdf:pdf},
issn = {0269-7491},
journal = {Environmental Pollution},
keywords = {Caesium-137,Fukushima accident,Kusaki Dam basin,Numerical hydrodynamic model,Reservoir sedimentation,suspended sediment},
mendeley-tags = {Caesium-137,Fukushima accident,Kusaki Dam basin,Numerical hydrodynamic model,Reservoir sedimentation,suspended sediment},
month = apr,
pages = {31--41},
title = {{Assessment of the caesium-137 flux adsorbed to suspended sediment in a reservoir in the contaminated Fukushima region in Japan}},
url = {http://www.sciencedirect.com/science/article/pii/S0269749113006519 http://www.sciencedirect.com/science/article/pii/S0269749113006519/pdfft?md5=f4dd0d5847cce4e1e7bb89b4b32b2c8e\&pid=1-s2.0-S0269749113006519-main.pdf},
volume = {187},
year = {2014}
}
@article{Clogg1995,
abstract = {Statistical methods are developed for comparing regression coefficients between models in the setting where one of the models is nested in the other. Comparisons of this kind are of interest whenever two explanations of a given phenomenon are specified as linear models. In this case, researchers should ask whether the coefficients associated with a given set of predictors change in a significant way when other predictors or covariates are added as controls. Simple calculations based on quantities provided by routines for regression analysis can be used to obtain the standard errors and other statistics that are required. Results are also given for the class of generalized linear models (e.g., logistic regression, log-linear models, etc.). We recommend fundamental change in strategies for model comparison in social research as well as modifications in the presentation of results from regression or regression-type models.},
author = {Clogg, Clifford C. and Petkova, Eva and Haritou, Adamantios},
doi = {10.2307/2782277},
issn = {0002-9602},
journal = {American Journal of Sociology},
month = mar,
number = {5},
pages = {1261--1293},
title = {{Statistical Methods for Comparing Regression Coefficients Between Models}},
url = {http://www.jstor.org/stable/2782277 http://www.jstor.org/stable/pdfplus/2782277.pdf?acceptTC=true},
volume = {100},
year = {1995}
}
@article{Coppola,
abstract = {Abstract Interpreting and predicting the evolution of non-point source (NPS) pollution of soil and surface and subsurface water from agricultural chemicals and pathogens, as well as overexploitation of groundwater resources at regional scale, are continuing challenges for natural scientists. Accordingly, in this study we present a regional-scale modeling approach for vadose zone solute leaching that is based on stochastic application of a deterministic vadose zone model describing the water flow and solute transport processes in the unsaturated zone using the Richards equation (RE) and the advective-dispersive equation (ADE), respectively. The stochastic framework (Monte Carlo technique) allows accounting for uncertainty in the vulnerability outputs. As the approach is built on physically-based equations, it may be extended to the predictions of water fluxes (i.e., groundwater recharge) in the vadose zone. The approach relies on available datasets coming from different sources (detailed pedological information, hydrological properties in different soil horizons, water table depth, spatially distributed climatic temporal series and land use) and offers quantitative answers to soil and groundwater vulnerability to NPS of chemicals at regional scale within a defined confidence interval. Interpolation of these local distributions by geostatistical tools provides areal distributions of the statistical moments of solute and water fluxes. A preliminary evaluation of methodology was carried out for quantifying contaminant transport and groundwater recharge profile in the Metaponto plain in Southern Basilicata, Italy. Results showed large differences in the magnitude of the different travel times and related uncertainties among different profiles. The lower or higher vulnerability was found to be mainly related to the average silt content of the soil profiles.},
author = {Coppola, A. and Dragonetti, G. and Comegna, A. and Zdruli, P. and Lamaddalena, N. and Pace, S. and {De Simone}, L.},
doi = {10.1080/00380768.2013.855615},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/SS3AJ8D6/Coppola et al. - Mapping solute deep percolation fluxes at regional.pdf:pdf},
issn = {0038-0768},
journal = {Soil Science and Plant Nutrition},
number = {0},
pages = {1--21},
title = {{Mapping solute deep percolation fluxes at regional scale by integrating a process-based vadose zone model in a Monte Carlo approach}},
url = {http://www.tandfonline.com/doi/abs/10.1080/00380768.2013.855615 http://www.tandfonline.com/doi/pdf/10.1080/00380768.2013.855615},
volume = {0}
}
@techreport{NationalResearchCouncil1996a,
address = {Washington, D.C.},
author = {{National Research Council}},
isbn = {0309561957},
title = {{Nuclear Wastes: Technologies for Separations and Transmutation}},
url = {http://www.nap.edu/catalog/4912.html},
year = {1996}
}
@incollection{Chertow2011,
abstract = {Nonhazardous industrial waste (NHIW) is distinct from both municipal solid waste (MSW), the more familiar mix from homes and businesses, and hazardous waste, materials that are more highly regulated owing to their toxicity and related public health concerns. The sheer quantities of NHIW raise the question of how best to manage it. The first defense is cleaner production—generating less waste by increasing industrial efficiency and effectiveness. A broad range of companies now produce annual sustainability reports detailing the amount of waste reduced in particular categories, year to year. For wastes that continue to be generated, many large volume industrial streams are amenable to separate handling such as foundry sand, coal ash, and paper mill sludge, some of these streams have an excellent track record for reuse. Specifically, industrial symbiosis is part of a new field called industrial ecology. Industrial ecology is principally concerned with the flow of materials and energy through systems at different scales, from products to factories and up to national and global levels. Industrial symbiosis focuses on these flows through networks of businesses and other organizations in local and regional economies as a means of approaching ecologically sustainable industrial development. It engages traditionally separate industries in a collective approach to competitive advantage involving physical exchange of materials, energy, water, and/or by-products. The keys to industrial symbiosis are collaboration and the synergistic possibilities offered by geographic proximity.},
address = {Boston},
author = {Chertow, Marian and Park, Jooyoung},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/EH9MJDC7/Chertow and Park - 2011 - Chapter 14 - Reusing Nonhazardous Industrial Waste.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {197--206},
publisher = {Academic Press},
title = {{Chapter 14 - Reusing Nonhazardous Industrial Waste Across Business Clusters}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100142 http://www.sciencedirect.com/science/article/pii/B9780123814753100142/pdfft?md5=94d5f8e71e1e8842ae5974af164857a4\&pid=3-s2.0-B9780123814753100142-main.pdf},
year = {2011}
}
@article{YewGan1997,
abstract = {Three medium sized, dry catchments located in Africa and USA were modeled with four or five conceptual rainfall-runoff (CRR) models of different complexity. The models were the Pitman model of South Africa (16 parameters), the Sacramento model of USA (21 parameters), the NAM model of Europe (15 parameters), the Xinanjiang model of China (15 parameters), and the SMAR model of Ireland (nine parameters). Between these models, the Xinanjiang model has been consistently doing better mainly because it is the only model that considers the non-uniform distribution of runoff producing areas to simulate the runoff. On the whole, it seems that standard, good quality hydrologic data can still support modeling of dry catchments with traditional CRR models. The model performance depends more on the model structure, the objective function used in automatic calibration, and data quality, than on model complexity or calibration data length. For relatively dry catchments such as the great Usuthu catchment, wet years should be preferred over dry years for the calibration data.},
author = {{Yew Gan}, Thian and Dlamini, Enoch M. and Biftu, Getu Fana},
doi = {10.1016/S0022-1694(96)03114-9},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/TW5BVE7C/Yew Gan et al. - 1997 - Effects of model complexity and structure, data qu.pdf:pdf},
issn = {0022-1694},
journal = {Journal of Hydrology},
month = may,
number = {1–4},
pages = {81--103},
title = {{Effects of model complexity and structure, data quality, and objective functions on hydrologic modeling}},
url = {http://www.sciencedirect.com/science/article/pii/S0022169496031149 http://www.sciencedirect.com/science/article/pii/S0022169496031149/pdf?md5=fa56531468fb7389c6fb2b9a0557debe\&pid=1-s2.0-S0022169496031149-main.pdf},
volume = {192},
year = {1997}
}
@incollection{Vallero2011a,
abstract = {Air pollution is the presence of contaminants or substances in the air that interfere with human health or welfare, or produce other harmful environmental effects. This chapter focuses on the waste streams that affect the atmosphere. The predominant concern with atmospheric waste is chemical contamination, which presents a hazard to human health. Thus, public health is usually the principal driver for assessing and controlling air contaminants. However, air pollution abatement laws and programs have also recognized that effects beyond health are also important, especially welfare protection. One of the main welfare considerations is that ecosystems are important receptors of contamination. Another welfare concern is that contaminants impact structures and other engineered systems by corrosion. Thus, from an air pollution perspective, there is a cascade of hazards from human health to ecosystems to abiotic (i.e., nonliving) systems. As far as pollution control is concerned, air pollution control must be strategic and tactical. The former is the long-term reduction of pollution levels at all scales of the problem from local to global. Goals can be set for air quality improvement 5, 10, or 15 years ahead and plans can be made to achieve these improvements.},
address = {Boston},
author = {Vallero, Daniel A.},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/9Q6RDX7U/Vallero - 2011 - Chapter 18 - Air Pollution Atmospheric Wastes.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {243--264},
publisher = {Academic Press},
shorttitle = {Chapter 18 - Air Pollution},
title = {{Chapter 18 - Air Pollution: Atmospheric Wastes}},
url = {http://www.sciencedirect.com/science/article/pii/B978012381475310018X http://www.sciencedirect.com/science/article/pii/B978012381475310018X/pdfft?md5=93ad1eceb7e4f2291f32eef9b27ab422\&pid=3-s2.0-B978012381475310018X-main.pdf},
year = {2011}
}
@article{Vesselinov2013,
abstract = {In contrast to many other engineering fields, the uncertainties in subsurface processes (e.g., fluid flow and contaminant transport in aquifers) and their parameters are notoriously difficult to observe, measure, and characterize. This causes severe uncertainties that need to be addressed in any decision analysis related to optimal management and remediation of groundwater contamination sites. Furthermore, decision analyses typically rely heavily on complex data analyses and/or model predictions, which are often poorly constrained as well. Recently, we have developed a model-driven decision-support framework (called MADS; http://mads.lanl.gov) for the management and remediation of subsurface contamination sites in which severe uncertainties and complex physics-based models are coupled to perform scientifically defensible decision analyses. The decision analyses are based on Information Gap Decision Theory (IGDT). We demonstrate the MADS capabilities by solving a decision problem related to optimal monitoring network design.},
author = {Vesselinov, Velimir V. and O'Malley, Daniel and Katzman, Danny},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/QMSRT6J3/Vesselinov et al. - 2013 - Robust decision analysis for environmental managem.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/9WV3593U/1311.html:html},
journal = {arXiv:1311.6014 [physics, stat]},
keywords = {Physics - Geophysics,Statistics - Applications},
mendeley-tags = {Physics - Geophysics,Statistics - Applications},
month = nov,
title = {{Robust decision analysis for environmental management of groundwater contamination sites}},
url = {http://arxiv.org/abs/1311.6014 http://www.arxiv.org/pdf/1311.6014.pdf},
year = {2013}
}
@techreport{ICRP2007,
author = {ICRP},
institution = {International Commission on Radiological Protection},
series = {Annals of the ICRP},
title = {{The 2007 Recommendations of the International Commission on Radiological Protection. ICRP Publication 103.}},
year = {2007}
}
@article{Wang2014,
abstract = {Non-Fickian transport ubiquitously occurs across all scales within fractured geological media. Detailed characterization of non-Fickian transport through single fractures is thus critical for predicting the fate of solutes and other fluid-borne entities through fractured media. Our direct numerical simulations of solute transport through two-dimensional rough-walled fractures showed early arrival and heavy tailing in breakthrough curves (BTCs), which are salient characteristics of non-Fickian transport. Analyses for dispersion coefficients (DADE) using the standard advection-dispersion equation (ADE) led to errors which increased linearly with fracture heterogeneity. Estimated Taylor dispersion coefficients deviated from estimated DADE even at higher Peclet numbers. Alternatively, we used continuous time random walk (CTRW) model with truncated power law transition rate probability to characterize the non-Fickian transport. CTRW modeling markedly and consistently improved fits to the BTCs relative to those fitted with ADE solutions. The degree of deviation of transport from Fickian to non-Fickian is captured by the parameter $\beta$ of the truncated power law. We found that $\beta$ is proportional to fracture heterogeneity. We also found that the CTRW transport velocity can be predicted based on the flow velocity. Along with the ability to predict $\beta$, this is a major step towards prediction of transport through CTRW using measurable physical properties.},
author = {Wang, Lichun and Cardenas, M. Bayani},
doi = {10.1002/2013WR014459},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/N4GCRUDN/abstract.html:html;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/WJ3MMDRH/Wang and Cardenas - 2014 - Non-Fickian transport through two-dimensional roug.pdf:pdf},
issn = {1944-7973},
journal = {Water Resources Research},
keywords = {CTRW,Fractures,Navier-Stokes,non-Fickian transport},
language = {en},
mendeley-tags = {CTRW,Fractures,Navier-Stokes,non-Fickian transport},
pages = {n/a--n/a},
shorttitle = {Non-Fickian transport through two-dimensional roug},
title = {{Non-Fickian transport through two-dimensional rough fractures: Assessment and prediction}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/2013WR014459/abstract http://onlinelibrary.wiley.com/store/10.1002/2013WR014459/asset/wrcr20720.pdf?v=1\&t=hqfiwi4p\&s=c56af4b7b5d38519364e67843325f87d8fdd105d},
year = {2014}
}
@article{Longobardi2013,
abstract = {The flow duration curve (FDC) can provide information about the integral catchment response to rainfall events that span from low volume events to events of flood magnitude, and the FDC is particularly useful for low flow regime characterization. The focus of this study was to introduce a statistical, parsimonious approach with a conceptually based parameterization that can lead to simple and practical tools for FDC predictions that can be applied to contexts, such as the Mediterranean climate, that involve scarce data and regional geological and hydro-geological features that strongly affect low-flow hydrological regimes. At-site, dimensionless, empirical FDCs were represented with three-parameter log normal distributions, the variations in the corresponding parameters versus the base flow index (BFI) were explored, and the conceptual relationship of these parameters is further discussed. In cases of ungauged catchments for which the BFI is not known, a priori estimates of such indices can be derived from permeability indices, as BFIs are strongly related to permeability indices in the studied region (Longobardi and Villani, 2008). For moderate to large permeability catchments, which represent the largest fraction of the investigated catchments, prediction errors associated with the proposed regional method of FDC assessment, which is particularly suited for regions for which only scarce or poor data are available, averaged approximately 18\%.},
author = {Longobardi, Antonia and Villani, Paolo},
doi = {10.1016/j.jhydrol.2013.10.019},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/T3Z8T7RJ/Longobardi and Villani - 2013 - A statistical, parsimonious, empirical framework f.pdf:pdf},
issn = {0022-1694},
journal = {Journal of Hydrology},
keywords = {BFI,Flow duration curve,High permeability areas,Low flow indices,Regionalization methods},
mendeley-tags = {BFI,Flow duration curve,High permeability areas,Low flow indices,Regionalization methods},
month = dec,
pages = {174--185},
title = {{A statistical, parsimonious, empirical framework for regional flow duration curve shape prediction in high permeability Mediterranean region}},
url = {http://www.sciencedirect.com/science/article/pii/S0022169413007385 http://www.sciencedirect.com/science/article/pii/S0022169413007385/pdfft?md5=dd73ab990d23280f54cad4ee59378862\&pid=1-s2.0-S0022169413007385-main.pdf},
volume = {507},
year = {2013}
}
@article{Western1998,
author = {Western, Andrew W. and Bl\"{o}schl, G\"{u}nter and Grayson, Rodger B.},
journal = {Journal of Hydrology},
number = {1},
pages = {20--37},
title = {{Geostatistical characterisation of soil moisture patterns in the Tarrawarra catchment}},
url = {http://www.sciencedirect.com/science/article/pii/S002216949700142X http://www.idrologia.polito.it/~alviglio/TUWsite/1998\_Western\_JH.pdf},
volume = {205},
year = {1998}
}
@article{Norman2011,
author = {Norman, Eric B. and Angell, Christopher T. and Chodash, Perry A.},
doi = {10.1371/journal.pone.0024330},
editor = {A\~{n}el, Juan A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/BGWDKXEJ/Norman et al. - 2011 - Observations of Fallout from the Fukushima Reactor.html:html},
issn = {1932-6203},
journal = {PLoS ONE},
language = {en},
month = sep,
number = {9},
pages = {e24330},
title = {{Observations of Fallout from the Fukushima Reactor Accident in San Francisco Bay Area Rainwater}},
url = {http://www.reddit.com/r/science/comments/20b7v9/science\_ama\_series\_were\_professors\_in\_the/},
volume = {6},
year = {2011}
}
@article{Karanovic2009,
abstract = {It is often necessary to estimate the zone of contribution to, or the capture zone developed by, pumped wells: for example, when evaluating pump-and-treat remedies and when developing wellhead protection areas for supply wells. Tonkin and Larson (2002) and Brochu and Marcotte (2003) describe a mapping-based method for estimating the capture zone of pumped wells, developed by combining universal kriging (kriging with a trend) with analytical expressions that describe the response of the potentiometric surface to certain applied stresses. This Methods Note describes (a) expansions to the techinque described by Tonkin and Larson (2002); (b) the concept of the capture frequency map (CFM), a technique that combines information from multiple capture zone maps into a single depiction of capture; (c) the development of a graphical user interface to facilitate the use of the methods described; and (d) the integration of these programs within the MapWindow geographic information system environment. An example application is presented that illustrates ground water level contours, capture zones, and a CFM prepared using the methods and software described.},
author = {Karanovic, Marinko and Tonkin, Matthew and Wilson, David},
doi = {10.1111/j.1745-6584.2009.00565.x},
issn = {1745-6584},
journal = {Ground Water},
language = {en},
number = {4},
pages = {580--586},
shorttitle = {KT3D\_H2O},
title = {{KT3D\_H2O: A Program for Kriging Water Level Data Using Hydrologic Drift Terms}},
url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1745-6584.2009.00565.x/abstract http://onlinelibrary.wiley.com/store/10.1111/j.1745-6584.2009.00565.x/asset/j.1745-6584.2009.00565.x.pdf?v=1\&t=hfgcwlt4\&s=be41eff8fef1f094783878929ce8b949f85bacd4},
volume = {47},
year = {2009}
}
@article{Loague1990,
author = {Loague, Keith},
doi = {10.1016/0022-1694(90)90161-P},
issn = {0022-1694},
journal = {Journal of Hydrology},
month = dec,
number = {1–4},
pages = {405--407},
title = {{Changing ideas in hydrology — The case of physically based models — Comment}},
url = {http://www.sciencedirect.com/science/article/pii/002216949090161P http://pdn.sciencedirect.com/science?\_ob=MiamiImageURL\&\_cid=271842\&\_user=4420\&\_pii=002216949090161P\&\_check=y\&\_origin=article\&\_zone=toolbar\&\_coverDate=1990--01\&view=c\&originContentFamily=serial\&wchp=dGLbVlt-zSkWb\&md5=90fe1cf2328e69b633400038e54f2e58\&pid=1-s2.0-002216949090161P-main.pdf},
volume = {120},
year = {1990}
}
@incollection{JasonHick2009,
annote = {doi:10.1201/9781420069815-c1},
author = {{Jason Hick} and {John Shalf}},
booktitle = {Scien},
isbn = {978-1-4200-6980-8},
month = dec,
publisher = {Chapman and Hall/CRC},
series = {Chapman \& Hall/CRC Computational Science},
title = {{Storage Technology}},
url = {http://dx.doi.org/10.1201/9781420069815-c1},
year = {2009}
}
@article{Hooten2008,
abstract = {The spread of invasive species is a long studied subject that garners much interest in the ecological research community. Historically the phenomenon has been approached using a purely deterministic mathematical framework (usually involving differential equations of some form). These methods, while scientifically meaningful, are generally highly simplified and fail to account for uncertainty in the data and process, of which our knowledge could not possibly exist without error. We propose a hierarchical Bayesian model for population spread that accommodates data sources with errors, dependence structures between population dynamics parameters, and takes into account prior scientific understanding via non-linear relationships between model parameters and space-time response variables. We model the process (i.e., the bird population in this case) as a Poisson response with spatially varying diffusion coefficients as well as a logistic population growth term using a common reaction-diffusion equation that realistically mimics the ecological process. We focus the application on the ongoing invasion of the Eurasian Collared-Dove.},
author = {Hooten, Mevin B. and Wikle, Christopher K.},
doi = {10.1007/s10651-007-0040-1},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/BQHZ6N3V/Hooten and Wikle - 2008 - A hierarchical Bayesian non-linear spatio-temporal.pdf:pdf},
issn = {1352-8505, 1573-3009},
journal = {Environmental and Ecological Statistics},
keywords = {Ecology,Evolutionary Biology,Folder - geostats,Invasive species,Mathematical Biology in General,Partial differential equations,Reaction-diffusion models,Statistics- general},
language = {en},
mendeley-tags = {Ecology,Evolutionary Biology,Folder - geostats,Invasive species,Mathematical Biology in General,Partial differential equations,Reaction-diffusion models,Statistics- general},
month = mar,
number = {1},
pages = {59--70},
title = {{A hierarchical Bayesian non-linear spatio-temporal model for the spread of invasive species with application to the Eurasian Collared-Dove}},
url = {http://link.springer.com/article/10.1007/s10651-007-0040-1 http://link.springer.com/content/pdf/10.1007\%2Fs10651-007-0040-1.pdf},
volume = {15},
year = {2008}
}
@article{Bamber2000,
abstract = {Formal definitions are given of the following intuitive concepts: (a) A model is quantitatively testable if its predictions are highly precise and narrow. (b) A model is identifiable if the values of its parameters can be ascertained from empirical observations. (c) A model is redundant if the values of some parameters can be deduced from others or if the values of some observables can be deduced from others. Various rules of thumb for nonredundant models are examined. The Counting Rule states that a model is quantitatively testable if and only if it has fewer parameters than observables. This rule can be safely applied only to identifiable models. If a model is unidentifiable, one must apply a generalization of the Counting Rule known as the Jacobian Rule. This rule states that a model is quantitatively testable if and only if the maximum rank (i.e., the number of linearly independent columns) of its Jacobian matrix (i.e., the matrix of partial derivatives of the function that maps parameter values to the predicted values of observables) is smaller than the number of observables. The Identifiability Rule states that a model is identifiable if and only if the maximum rank of its Jacobian matrix equals the number of parameters. The conclusions provided by these rules are only presumptive. To reach definitive conclusions, additional analyses must be performed. To illustrate the foregoing, the quantitative testability and identifiability of linear models and of discrete-state models are analyzed. Copyright 2000 Academic Press.},
author = {Bamber, D and {van Santen JP}},
doi = {10.1006/jmps.1999.1275},
issn = {0022-2496},
journal = {Journal of mathematical psychology},
month = mar,
number = {1},
pages = {20--40},
pmid = {10733856},
title = {{How to Assess a Model's Testability and Identifiability.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10733856},
volume = {44},
year = {2000}
}
@article{McDonnell2007,
author = {McDonnell, J. J. and Sivapalan, Murugesu and Vach\'{e}, K. and Dunn, S. and Grant, G. and Haggerty, R. and Hinz, C. and Hooper, R. and Kirchner, J. and Roderick, M. L. and Selker, J. and Weiler, M.},
doi = {10.1029/2006WR005467},
issn = {0043-1397},
journal = {Water Resources Research},
month = jul,
number = {7},
pages = {W07301},
title = {{Moving beyond heterogeneity and process complexity: A new vision for watershed hydrology}},
url = {http://www.agu.org/pubs/crossref/2007/2006WR005467.shtml http://doi.wiley.com/10.1029/2006WR005467},
volume = {43},
year = {2007}
}
@incollection{Vallero2011d,
abstract = {This chapter approaches wastes from a life cycle perspective. The best waste is no waste at all, so the waste manager must look for opportunities to prevent the generation of wastes. One tool for identifying and characterizing wastes is the life cycle assessment, which considers products before they are manufactured and after they are disassembled. The energy and matter must be considered thermodynamically.
Traditionally, addressing wastes has often been a matter of reacting to problems as they arose individually in a situationally dependent way. However, the processes that lead to waste can be viewed much more proactively and systematically, with the focus now being on prevention. Engineers and other waste managers have begun to embrace waste minimization, pollution prevention, and other systematic approach, albeit incrementally. Green design and sustainable approaches to waste apply scientific principles to develop objective-oriented, function-based processes. They consider every element of a product's life cycle in a way that mutually benefits the client, the public, and the environment. Waste products can decrease in volume and mass as green designs replace traditional methods of manufacturing, use, and disposal. Wastes must be managed (and, ideally, avoided) by means of applying the laws of science. The better the designer understands these principles, the more likely that the products demanded by society can be produced and used predictably and sustainably. Therefore, strategic use of physical science laws must inform designs and engineering decisions, and forms the crux of green engineering and sustainable aspects of waste management.},
address = {Boston},
author = {Vallero, Daniel A.},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/NSZTEKKV/Vallero - 2011 - Chapter 2 - Green Engineering and Sustainable Desi.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {11--21},
publisher = {Academic Press},
title = {{Chapter 2 - Green Engineering and Sustainable Design Aspects of Waste Management}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100026 http://www.sciencedirect.com/science/article/pii/B9780123814753100026/pdfft?md5=2423f98c4843104ecef10dc0d51b4994\&pid=3-s2.0-B9780123814753100026-main.pdf},
year = {2011}
}
@article{Rexstad1985,
abstract = {This paper explores the possibility of model simplification in the context of ecological models. The techniques of simplification have arisen in a variety of disciplines and have received only limited attention in ecological studies. We applied some of these techniques in three instances and report our results in this paper. All of our simplification exercises were successful in the sense of making the models under scrutiny less complex. We present our results here as a demonstration of some of these simplification techniques and to generalize about the applicability of simplification to ecological models.},
author = {Rexstad, Eric and Innis, George S.},
doi = {10.1016/0304-3800(85)90021-3},
issn = {0304-3800},
journal = {Ecological Modelling},
month = mar,
number = {1–2},
pages = {1--13},
title = {{Model simplification — Three applications}},
url = {http://www.sciencedirect.com/science/article/pii/0304380085900213 http://www.sciencedirect.com/science/article/pii/0304380085900213/pdf?md5=27f19737b1fed37cbed34c5b9336fd89\&pid=1-s2.0-0304380085900213-main.pdf},
volume = {27},
year = {1985}
}
@incollection{Medina2011,
abstract = {This Chapter explores military waste issues. It focuses on the issues associated with the United States Army from existing military facilities and from base camp operations. The Army has facilities to house and train troops, store munitions, support operational commands, conduct research and development, and engage in the production of munitions. Of course, many facilities combine several aspects of these activities. Within these facilities, a wide range of activities can take place, each of which may result in the generation of various waste streams. These include typical household wastes from housing areas, office wastes from various administrative and command activities, landscaping wastes, and construction and demolition (C\&D) wastes. Therefore, in many ways, wastes generated at military facilities are similar to civilian residential communities and commercial facilities. However, training areas in particular provide substantially different waste issues than commonly found in civilian environments. Another area of substantial difference is the management of explosive munitions, particularly the decommissioning of out-of-specification materials.},
address = {Boston},
author = {Medina, Victor F. and Waisner, Scott A.},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
isbn = {978-0-12-381475-3},
pages = {357--376},
publisher = {Academic Press},
title = {{Chapter 25 - Military Solid and Hazardous Wastes—Assessment of Issues at Military Facilities and Base Camps}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100257 http://www.sciencedirect.com/science/article/pii/B9780123814753100257/pdfft?md5=84de8964c9be41b44448864fbd05b6d6\&pid=3-s2.0-B9780123814753100257-main.pdf},
year = {2011}
}
@article{Minasny2007,
author = {Minasny, Budiman and McBratney, Alex B.},
doi = {10.1016/j.geoderma.2007.04.028},
issn = {00167061},
journal = {Geoderma},
keywords = {Folder - geostats},
mendeley-tags = {Folder - geostats},
month = aug,
number = {4},
pages = {324--336},
title = {{Spatial prediction of soil properties using EBLUP with the Mat\'{e}rn covariance function}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0016706107001127},
volume = {140},
year = {2007}
}
@article{Hunt2007,
abstract = {The idea that models should be as simple as possible is often accepted without question. However, too much simplification and parsimony may degrade a model’s utility. Models are often constructed to make predictions; yet, they are commonly parameterized with a focus on calibration, regardless of whether (1) the calibration data can constrain simulated predictions or (2) the number and type of calibration parameters are commensurate with the hydraulic property details on which key predictions may depend. Parameterization estimated through the calibration process is commonly limited by the necessity that the number of calibration parameters be smaller than the number of observations. This limitation largely stems from historical restrictions in calibration and computing capability; we argue here that better methods and computing capabilities are now available and should become more widely used. To make this case, two approaches to model calibration are contrasted: (1) a traditional approach based on a small number of homogeneous parameter zones defined by the modeler a priori and (2) regularized inversion, which includes many more parameters than the traditional approach. We discuss some advantages of regularized inversion, focusing on the increased insight that can be gained from calibration data. We present these issues using reasoning that we believe has a common sense appeal to modelers; knowledge of mathematics is not required to follow our arguments. We present equations in an Appendix, however, to illustrate the fundamental differences between traditional model calibration and a regularized inversion approach.},
author = {Hunt, Randall J. and Doherty, John and Tonkin, Matthew J.},
doi = {10.1111/j.1745-6584.2007.00316.x},
issn = {1745-6584},
journal = {Ground Water},
language = {en},
number = {3},
pages = {254--262},
shorttitle = {Are Models Too Simple?},
title = {{Are Models Too Simple? Arguments for Increased Parameterization}},
url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1745-6584.2007.00316.x/abstract http://onlinelibrary.wiley.com/store/10.1111/j.1745-6584.2007.00316.x/asset/j.1745-6584.2007.00316.x.pdf?v=1\&t=hfgczra8\&s=d27f440bc0437ea71eed9de545db6ffcab09ac87},
volume = {45},
year = {2007}
}
@article{Nearing2013,
abstract = {Data assimilation and regression are two commonly used methods for combining models and remote sensing observations to estimate agricultural productivity. Data assimilation is a generative approach because it requires explicit approximations of a Bayesian prior and likelihood to compute a probability density function of biomass conditional on observations, and regression is discriminative because it models the conditional biomass density function directly. Both of these methods typically approximate Bayes’ law and therefore cannot be expected to be perfectly efficient at extracting information from remote sensing observations. In this paper we measure information in observations using Shannon’s theory and define missing information, used information, and bad information as partial divergences from the true Bayesian posterior (biomass conditional on observations). These concepts were applied to directly measure the amount and quality of information about end-of-season biomass extracted from observations by the ensemble Kalman filter (EnKF) and Gaussian process regression (GPR). Results suggest that the simpler discriminative approach can be as efficient as the more complex generative approach in terms of extracting high quality information from observations, and may therefore be better suited to dealing with the practical problems associated with remote sensed data (e.g., sub-footprint scale heterogeneity). Our method for analyzing information use has many potential applications: approximations of Bayes’ law are used regularly in predictive models of environmental systems of all kinds, and the efficiency of such approximations has heretofore not been directly measured.},
author = {Nearing, Grey S. and Gupta, Hoshin V. and Crow, Wade T.},
doi = {10.1016/j.jhydrol.2013.10.029},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/DJGPSWRS/Nearing et al. - 2013 - Information loss in approximately Bayesian estimat.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/CZAQ9TP8/Nearing et al. - 2013 - Information loss in approximately Bayesian estimat.pdf:pdf},
issn = {0022-1694},
journal = {Journal of Hydrology},
keywords = {Agriculture monitoring,Bayesian analysis,Ensemble Kalman filter,Gaussian process regression,data assimilation,information theory},
mendeley-tags = {Agriculture monitoring,Bayesian analysis,Ensemble Kalman filter,Gaussian process regression,data assimilation,information theory},
month = dec,
pages = {163--173},
shorttitle = {Information loss in approximately Bayesian estimat},
title = {{Information loss in approximately Bayesian estimation techniques: A comparison of generative and discriminative approaches to estimating agricultural productivity}},
url = {http://www.sciencedirect.com/science/article/pii/S0022169413007488 http://www.sciencedirect.com/science/article/pii/S0022169413007488/pdfft?md5=64b667e9f091af22f57ffbad657f1226\&pid=1-s2.0-S0022169413007488-main.pdf},
volume = {507},
year = {2013}
}
@incollection{Letcher2011e,
address = {Boston},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/P7U4QXKJ/Letcher and Vallero - 2011 - Epilogue.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {541--543},
publisher = {Academic Press},
title = {{Epilogue}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100385 http://www.sciencedirect.com/science/article/pii/B9780123814753100385/pdfft?md5=51e3b21a929e57e8c8316fab6875bc93\&pid=3-s2.0-B9780123814753100385-main.pdf},
year = {2011}
}
@article{Morens2000,
author = {Morens, David M},
doi = {10.1016/S0140-6736(05)70399-8},
issn = {0140-6736},
journal = {The Lancet},
month = nov,
number = {9242},
pages = {1688--1689},
shorttitle = {Snow and the Broad Street pump},
title = {{Snow and the Broad Street pump: a rediscovery}},
url = {http://www.sciencedirect.com/science/article/pii/S0140673605703998 http://www.sciencedirect.com/science?\_ob=MiamiImageURL\&\_cid=271074\&\_user=4420\&\_pii=S0140673605703998\&\_check=y\&\_origin=article\&\_zone=toolbar\&\_coverDate=11-Nov-2000\&view=c\&originContentFamily=serial\&wchp=dGLbVlB-zSkzS\&md5=0381177b6a20606ef861c8e8463418ae\&pid=1-s2.0-S0140673605703998-main.pdf},
volume = {356},
year = {2000}
}
@article{Bons2013,
abstract = {Perturbations of temperature or solute concentration in a porous medium spread out by heat or molecular diffusion, respectively. If the pore-filling medium (e.g. water in soil) flows, this causes additional spreading of the perturbation due to the variation of local flow velocities and the tortuous flow lines through pore space. Together, this is termed dispersion, which plays an important role in geothermal energy production, contaminant transport and reactor beds. Numerous models have been proposed to describe the dispersion coefficient as a function of flow rates, diffusion rates and other parameters, such as pore geometry. These models are either for heat (thermal) or solute dispersion, and often only valid for a limited range of flow rates, typically expressed in terms of the P\'{e}clet number. Here we present a single, universal expression for both the heat and solute dispersion coefficient in homogeneous porous media, valid over a wide range of P\'{e}clet numbers. Only three parameters have to be determined, which depend mainly on the pore geometry of the material. The expression facilitates the physical understanding of dispersion and may be helpful for the interpretation of numerical microscopic modeling results. It has the practical advantage that the heat dispersion coefficient can easily be calculated from the solute dispersion coefficient (or vice versa) and that dispersion coefficients over a wide range of P\'{e}clet numbers can be estimated from measurements over only a limited range.},
author = {Bons, Paul D. and van Milligen, Boudewijn Ph. and Blum, Philipp},
doi = {10.1002/wrcr.20488},
issn = {1944-7973},
journal = {Water Resources Research},
keywords = {Longitudinal dispersion,heat dispersion,particle dispersion,solute dispersion,transverse dispersion},
language = {en},
mendeley-tags = {Longitudinal dispersion,heat dispersion,particle dispersion,solute dispersion,transverse dispersion},
pages = {n/a--n/a},
title = {{A general unified expression for solute and heat dispersion in homogeneous media}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/wrcr.20488/abstract http://onlinelibrary.wiley.com/store/10.1002/wrcr.20488/asset/wrcr20488.pdf?v=1\&t=hkubtvxq\&s=8738dde3a143be8d68d927ac79ac4ff22b0ceabe},
year = {2013}
}
@article{Refsgaard1997,
author = {Refsgaard, Jens Christian},
doi = {10.1016/S0022-1694(96)03329-X},
issn = {00221694},
journal = {Journal of Hydrology},
month = nov,
number = {1-4},
pages = {69--97},
title = {{Parameterisation, calibration and validation of distributed hydrological models}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S002216949603329X},
volume = {198},
year = {1997}
}
@article{Goodrich1994,
author = {Goodrich, David C. and Woolhiser, David A.},
doi = {10.1029/93WR03156},
issn = {1944-7973},
journal = {Water Resources Research},
language = {en},
number = {3},
pages = {845--847},
shorttitle = {Comment on “Physically based hydrologic modeling},
title = {{Comment on “Physically based hydrologic modeling: 1, A terrain-based model for investigative purposes” by R. B. Grayson, I. D. Moore, and T. A. McMahon}},
url = {http://onlinelibrary.wiley.com/doi/10.1029/93WR03156/abstract http://onlinelibrary.wiley.com/store/10.1029/93WR03156/asset/wrcr6423.pdf?v=1\&t=hfezdsgj\&s=74881879cfd2b458f12adc00b377b7f2ff40f8a0 http://onlinelibrary.wiley.com/store/10.1029/93WR03156/asset/wrcr6423.pdf?v=1\&t=hfezgm5v\&s=23307db4783782f905b8c51f966b3575f725c51a},
volume = {30},
year = {1994}
}
@article{Wood2009,
author = {Wood, Brian D.},
doi = {10.1016/j.advwatres.2008.08.015},
issn = {03091708},
journal = {Advances in Water Resources},
month = may,
number = {5},
pages = {723--736},
publisher = {Elsevier Ltd},
title = {{The role of scaling laws in upscaling}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0309170808001498},
volume = {32},
year = {2009}
}
@article{Dawson2014,
abstract = {Environmental restoration projects can benefit from using performance models tied to monitoring plans and closure/exit strategies. Theoretical aspects are discussed and a case study is provided to illustrate how models can be developed and applied. Recognizing that site characterization cannot remove all uncertainty, most performance models cannot be narrowly developed (e.g., specific concentrations expected over time). Instead they must define threshold values at which performance data indicate the remedy is failing, or at least is not operating at the required level to achieve objectives within a reasonable timeframe. Ultimately, the performance model should be transformed to a closure model. The closure model is intended to document how closure was achieved and what measures remain in place to ensure protection of human health and the environment. In this context, the performance model is an intermediate step in the sequence starting from a conceptual site model and ending as the closure model. © 2014 Wiley Periodicals, Inc.},
author = {Dawson, Gaynor and McKeon, Tom},
doi = {10.1002/rem.21395},
issn = {1520-6831},
journal = {Remediation Journal},
language = {en},
month = jun,
number = {3},
pages = {71--83},
title = {{Use of Performance Models in Restoration Projects}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/rem.21395/abstract},
volume = {24},
year = {2014}
}
@incollection{ArieShoshani2009,
annote = {doi:10.1201/9781420069815-b},
author = {{Arie Shoshani} and {Doron Rotem}},
isbn = {978-1-4200-6980-8},
month = dec,
publisher = {Chapman and Hall/CRC},
series = {Chapman \& Hall/CRC Computational Science},
title = {{Conclusions and Future Outlook}},
url = {http://dx.doi.org/10.1201/9781420069815-b},
year = {2009}
}
@book{Chakraverty2014,
abstract = {For various scientific and engineering problems, how to deal with variables and parameters of uncertain value is an important issue. Full analysis of the specific errors in measurement, observations, experiments, and applications are vital in dealing with the parameters taken to simplify the problem. Mathematics of Uncertainty Modeling in the Analysis of Engineering and Science Problems aims to provide the reader with basic concepts for soft computing and other methods for various means of uncertainty in handling solutions, analysis, and applications. This book is an essential reference work for students, scholars, practitioners and researchers in the assorted fields of engineering and applied mathematics interested in a model for uncertain physical problems.},
author = {Chakraverty, Snehashish},
isbn = {9781466649927},
language = {en},
month = jan,
pages = {442},
publisher = {IGI Global},
title = {{Mathematics of Uncertainty Modeling in the Analysis of Engineering and Science Problems}},
url = {http://books.google.com/books?id=810rAgAAQBAJ},
year = {2014}
}
@article{Kaplan,
abstract = {ABSTRACT 129I is commonly either the top or among the top risk drivers, along with 99Tc, at radiological waste disposal sites and contaminated groundwater sites where nuclear material fabrication or reprocessing has occurred. The risk stems largely from 129I having a high toxicity, a high bioaccumulation factor (90\% of all the body's iodine concentrates in the thyroid), a high inventory at source terms (due to its high fission yield), an extremely long half-life (16M yr), and rapid mobility in the subsurface environment. Another important reason that 129I is a key risk driver is that there is the uncertainty regarding its biogeochemical fate and transport in the environment. We typically can define 129I mass balance and flux at sites, but cannot predict accurately its response to changes in the environment. As a consequence of some of these characteristics, 129I has a very low Drinking Water Standard, DWS, which is set at 1 pCi/L, the lowest of all radionuclides in the Federal Register. Recently, significant advancements have been made in detecting iodine species at ambient groundwater concentrations, defining the nature of the organic matter and iodine bond, and quantifying the role of naturally occurring sediment microbes to promote iodine oxidation and reduction. These recent studies have led to a more mechanistic understanding of radioiodine biogeochemistry. The objective of this review is to describe these advances and to provide a state of the science of radioiodine biogeochemistry relevant to its fate and transport in the terrestrial environment and provide information useful for making decisions regarding the stewardship and remediation of 129I contaminated sites. As part of this review, knowledge gaps were identified that would significantly advance the goals of basic and applied research programs for accelerating 129I environmental remediation and reducing uncertainty associated with disposal of 129I waste. Together the information gained from addressing these knowledge gaps will not alter the observation that 129I is primarily mobile, but it will likely permit demonstration that the entire 129I pool in the source term is not moving at the same rate and some may be tightly bound to the sediment, thereby “smearing” the modeled 129I peak and reducing maximum calculated risk.},
author = {Kaplan, D. I. and Denham, M. E. and Zhang, S. and Yeager, C. and Xu, C. and Schwehr, K. A. and Li, H. P. and Ho, Y. F. and Wellman, D. and Santschi, P. H.},
doi = {10.1080/10643389.2013.828273},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/ADT6WKHM/Kaplan et al. - Radioiodine Biogeochemistry and Prevalence in Grou.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/GIMTRKUS/10643389.2013.html:html},
issn = {1064-3389},
journal = {Critical Reviews in Environmental Science and Technology},
number = {ja},
pages = {null},
title = {{Radioiodine Biogeochemistry and Prevalence in Groundwater}},
url = {http://www.tandfonline.com/doi/abs/10.1080/10643389.2013.828273 http://www.tandfonline.com/doi/pdf/10.1080/10643389.2013.828273},
volume = {0}
}
@article{Browne2000,
abstract = {This paper gives a review of cross-validation methods. The original applications in multiple linear regression are considered first. It is shown how predictive accuracy depends on sample size and the number of predictor variables. Both two-sample and single-sample cross-validation indices are investigated. The application of cross-validation methods to the analysis of moment structures is then justified. An equivalence of a single-sample cross-validation index and the Akaike information criterion is pointed out. It is seen that the optimal number of parameters suggested by both single-sample and two-sample cross-validation indices will depend on sample size. Copyright 2000 Academic Press.},
author = {Browne, Mw},
doi = {10.1006/jmps.1999.1279},
issn = {0022-2496},
journal = {Journal of mathematical psychology},
month = mar,
number = {1},
pages = {108--132},
pmid = {10733860},
title = {{Cross-Validation Methods.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10733860},
volume = {44},
year = {2000}
}
@article{Gilbert2014a,
abstract = {The environmental chemodynamics of hydrophobic organic chemicals (HOCs) are often rate-limited by diffusion in stagnant boundary layers. This study investigated whether motile microorganisms can act as microbial carriers that enhance mass transfer of HOCs through diffusive boundary layers. A new experimental system was developed that allows (1) generation of concentration gradients of HOCs under the microscope, (2) exposure and direct observation of microorganisms in such gradients and (3) quantification of HOC mass transfer. Silicone O-rings were integrated into a Dunn chemotaxis chamber to serve as sink and source for polycyclic aromatic hydrocarbons (PAHs). This resulted in stable concentration gradients in water (> 24 h). Adding the model organism Tetrahymena pyriformis to the experimental system enhanced PAH mass transfer up to 100-fold (benzo[a]pyrene). Increasing mass transfer enhancement with hydrophobicity indicated PAH co-transport with the motile organisms. Fluorescence microscopy confirmed such transport. The effective diffusivity of T. pyriformis, determined by video imaging microscopy, was found to exceed molecular diffusivities of the PAHs up to four-fold. Cell-bound PAH fractions were determined to range from 28 \% (naphthalene) to 92 \% (pyrene). Motile microorganisms can therefore function as effective carriers for HOCs under diffusive conditions and might significantly enhance mobility and availability of HOCs.},
author = {Gilbert, Dorothea and Jakobsen, Hans Henrik and Winding, Anne and Mayer, Philipp},
doi = {10.1021/es404793u},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/V22I35UX/Gilbert et al. - 2014 - Co-transport of polycyclic aromatic hydrocarbons b.pdf:pdf},
issn = {0013-936X},
journal = {Environmental Science \& Technology},
month = mar,
title = {{Co-transport of polycyclic aromatic hydrocarbons by motile microorganisms leads to enhanced mass transfer under diffusive conditions}},
url = {http://dx.doi.org/10.1021/es404793u http://pubs.acs.org/doi/pdfplus/10.1021/es404793u},
year = {2014}
}
@article{Alagha,
abstract = {Nitrate concentration in groundwater is influenced by complex and interrelated variables, leading to great difficulty during the modeling process. The objectives of this study are (1) to evaluate the performance of two artificial intelligence (AI) techniques, namely artificial neural networks and support vector machine, in modeling groundwater nitrate concentration using scant input data, as well as (2) to assess the effect of data clustering as a pre-modeling technique on the developed models' performance. The AI models were developed using data from 22 municipal wells of the Gaza coastal aquifer in Palestine from 2000 to 2010. Results indicated high simulation performance, with the correlation coefficient and the mean average percentage error of the best model reaching 0.996 and 7 \%, respectively. The variables that strongly influenced groundwater nitrate concentration were previous nitrate concentration, groundwater recharge, and on-ground nitrogen load of each land use land cover category in the well's vicinity. The results also demonstrated the merit of performing clustering of input data prior to the application of AI models. With their high performance and simplicity, the developed AI models can be effectively utilized to assess the effects of future management scenarios on groundwater nitrate concentration, leading to more reasonable groundwater resources management and decision-making},
author = {Alagha, Jawad S. and Said, Md Azlin Md and Mogheir, Yunes},
doi = {10.1007/s10661-013-3353-6},
issn = {0167-6369, 1573-2959},
journal = {Environmental Monitoring and Assessment},
keywords = {Artificial neural networks (ANNs),Atmospheric Protection/Air Quality Control/Air Pol,Clustering,Ecology,Ecotoxicology,Environmental Management,Environmental Monitoring/Analysis,Gaza coastal aquifer (GCA),Land use,Support vector machine (SVM)},
language = {en},
mendeley-tags = {Artificial neural networks (ANNs),Atmospheric Protection/Air Quality Control/Air Pol,Clustering,Ecology,Ecotoxicology,Environmental Management,Environmental Monitoring/Analysis,Gaza coastal aquifer (GCA),Land use,Support vector machine (SVM)},
pages = {1--11},
title = {{Modeling of nitrate concentration in groundwater using artificial intelligence approach—a case study of Gaza coastal aquifer}},
url = {http://link.springer.com/article/10.1007/s10661-013-3353-6 http://link.springer.com/content/pdf/10.1007/s10661-013-3353-6.pdf}
}
@article{Farmer2003,
author = {Farmer, Darren and Sivapalan, Murugesu and Jothityangkoon, Chatchai},
journal = {Water Resources Research},
number = {2},
pages = {1035},
shorttitle = {Climate, soil, and vegetation controls upon the va},
title = {{Climate, soil, and vegetation controls upon the variability of water balance in temperate and semiarid landscapes: Downward approach to water balance analysis}},
url = {http://www.agu.org/pubs/crossref/2003/2001WR000328.shtml},
volume = {39},
year = {2003}
}
@incollection{Vallero2011e,
abstract = {Organisms and ecosystems survive within a finite range of environmental conditions. One of the key factors in these conditions is the temperature range. From a waste management perspective, heat is both a friend and foe. When properly designed and operated, incinerators and other thermal technologies reduce municipal and industrial wastes in volume and change their physical and chemical properties to make these wastes less toxic and more easily manageable. However, if not operated properly, these same technologies can form very toxic chemical compounds. Thermal pollutants can affect the environment in every phase and environmental media. Heat may be a water pollutant if its addition directly or indirectly harms the biota living in surface wards. Complete destruction of a toxic compound versus the release of even more toxic compounds in an incinerator can be determined by a relatively small temperature range. Adding heat to a stream or other ecosystem can completely alter its biological integrity. Food chains and the health of human populations are affected by direct heating or by the indirect effects of added heat. Thus, waste management must always devote attention to these and other possible impacts from heat in the design and operation of systems.},
address = {Boston},
author = {Vallero, Daniel A.},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/GTMNUHIB/Vallero - 2011 - Chapter 28 - Thermal Pollution.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {425--443},
publisher = {Academic Press},
title = {{Chapter 28 - Thermal Pollution}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100282 http://www.sciencedirect.com/science/article/pii/B9780123814753100282/pdfft?md5=d2bd77e36bacaeca7725beffc42b81b3\&pid=3-s2.0-B9780123814753100282-main.pdf},
year = {2011}
}
@article{Bloschl2005,
author = {Bl\"{o}schl, G\"{u}nter and Zehe, Erwin},
doi = {10.1002/hyp.6075},
issn = {0885-6087},
journal = {Hydrological Processes},
month = dec,
number = {19},
pages = {3923--3929},
title = {{On hydrological predictability}},
url = {http://doi.wiley.com/10.1002/hyp.6075 http://onlinelibrary.wiley.com/doi/10.1002/hyp.6075/abstract http://www.idrologia.polito.it/~alviglio/TUWsite/2005\_Bloeschl\_HP.pdf},
volume = {19},
year = {2005}
}
@techreport{EPA2013,
address = {Washington, D.C.},
author = {{Environmental Protection Agency}},
institution = {United States Environmental Protection Agency},
keywords = {Folder - ch1},
mendeley-tags = {Folder - ch1},
month = mar,
pages = {1--37},
title = {{Fiscal Year 2011 Drinking Water and Ground Water Statistics}},
url = {http://water.epa.gov/scitech/datait/databases/drink/sdwisfed/upload/epa816r13003.pdf},
year = {2013}
}
@article{Grayson1994a,
author = {Grayson, Rodger B. and Moore, Ian D. and McMahon, Thomas A.},
doi = {10.1029/93WR03157},
issn = {1944-7973},
journal = {Water Resources Research},
language = {en},
number = {3},
pages = {849--849},
shorttitle = {Reply [to “Comment on ‘Physically based hydrologic},
title = {{Reply [to “Comment on ‘Physically based hydrologic modeling: 1, A terrain-based model for investigative purposes’ by R. B. Grayson, I. D. Moore, and T. A. McMahon”]}},
url = {http://onlinelibrary.wiley.com/doi/10.1029/93WR03157/abstract http://onlinelibrary.wiley.com/store/10.1029/93WR03157/asset/wrcr6424.pdf?v=1\&t=hfeze4c9\&s=6e6fb6af2282d75d73eb998e465aa32c38196db3 http://onlinelibrary.wiley.com/store/10.1029/93WR03157/asset/wrcr6424.pdf?v=1\&t=hfezgjq1\&s=5777f7b0c4e9bc82dbd402f0ad863d93163e385b},
volume = {30},
year = {1994}
}
@inproceedings{Shinoda1996,
abstract = {A speaker adaptation method for continuous density HMMs, which performs well for any amount of data for adaptation, is proposed. This method estimates shift parameters for the means of Gaussian mixture components in the HMM. Each shift parameter is shared by more than one Gaussian components. Many sets of shift parameters with various degree of sharing are prepared, and the set with the appropriate complexity for the gives amount of data is selected using minimum description length (MDL) principle. Unlike previous similar works, the proposed method needs no control parameters for selecting models. A series of 5000-word recognition experiments have demonstrated the effectiveness of this new method},
author = {Shinoda, Koichi and Watanabe, T.},
doi = {10.1109/ICASSP.1996.543221},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/FQ7RJA44/Shinoda and Watanabe - 1996 - Speaker adaptation with autonomous model complexit.pdf:pdf},
keywords = {5000-word recognition experiments,Adaptation model,Bayesian methods,Gaussian mixture components,Gaussian processes,Information technology,Laboratories,MDL principle,National electric code,Robustness,Speech recognition,Training data,adaptive signal processing,autonomous model complexity control,continuous density HMM,hidden Markov models,minimum description length,parameter estimation,shift parameter estimation,speaker adaptation,speaker recognition},
mendeley-tags = {5000-word recognition experiments,Adaptation model,Bayesian methods,Gaussian mixture components,Gaussian processes,Information technology,Laboratories,MDL principle,National electric code,Robustness,Speech recognition,Training data,adaptive signal processing,autonomous model complexity control,continuous density HMM,hidden Markov models,minimum description length,parameter estimation,shift parameter estimation,speaker adaptation,speaker recognition},
month = may,
pages = {717--720 vol. 2},
title = {{Speaker adaptation with autonomous model complexity control by MDL principle}},
url = {http://ieeexplore.ieee.org/ielx3/3856/11265/00543221.pdf?tp=\&arnumber=543221\&isnumber=11265},
volume = {2},
year = {1996}
}
@incollection{Shulman2011,
abstract = {Historically, waste management has been inextricably linked with the evolution of human communities, population growth, and the emergence and development of commerce. During the past century, consumption and production patterns have changed radically—due in part to the greater freedom of movement of money, goods, and people. A horizontal framework has been established for waste management, including definitions and principles. Treatment operations were defined vertically—to include the control of landfill and incineration. A body of standards is currently being prepared for treatment operations—through the International Standards Organization, with support from national standards bodies. Reuse and recycling are being integrated into industrial activities. However, as they are interpreted today, the concepts of reuse and recycling are inextricably linked to the production and management of waste and by extension, to its prevention and minimization. Reuse and recycling have evolved into two of the four pillars that support improved resource management through the prevention of waste and the reuse, recycling, and recovery of the wastes that do occur to achieve sustainable developmental goals by reducing reliance on natural resources.},
address = {Boston},
author = {Shulman, Valerie L.},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/IF6TJ7US/Shulman - 2011 - Chapter 1 - Trends in Waste Management.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {3--10},
publisher = {Academic Press},
title = {{Chapter 1 - Trends in Waste Management}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100014 http://www.sciencedirect.com/science/article/pii/B9780123814753100014/pdfft?md5=094ceadafce512bbca99395d88627ebf\&pid=3-s2.0-B9780123814753100014-main.pdf},
year = {2011}
}
@article{Harman2014,
abstract = {The time-varying transport dynamics of complex hydrodynamic systems with long transit times are difficult to observe due to the need for multiple tracer injections. Where only one or two distinct tracers are available, overprinting in the output concentrations limits the injection frequency. In this letter we propose an experimental method (the PERiodic Tracer Hierarchy - PERTH) that allows overprinted breakthrough curves to be decomposed into contributions from multiple injections of the same tracer,so long as the transporting flow is periodic. This method allows the time varying transit time distributions to be observed efficiently while making no a priori assumptions about the transport processes operating in the system. Simulations of transport through a soil column subject to a periodic sequence of irrigation events demonstrate that the distinct transit time distributions associated with each irrigation event can be retrieved almost exactly.},
author = {Harman, Ciaran J. and Kim, Minseok},
doi = {10.1002/2013GL058980},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/QV6TC6E5/Harman and Kim - 2014 - An efficient tracer test for time-variable transit.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/QV8882R5/Harman and Kim - 2014 - An efficient tracer test for time-variable transit.pdf:pdf},
issn = {1944-8007},
journal = {Geophysical Research Letters},
keywords = {Transport,experiment,method,time-variable,tracer},
language = {en},
mendeley-tags = {Transport,experiment,method,time-variable,tracer},
pages = {n/a--n/a},
title = {{An efficient tracer test for time-variable transit time distributions in periodic hydrodynamic systems}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/2013GL058980/abstract http://onlinelibrary.wiley.com/store/10.1002/2013GL058980/asset/grl51394.pdf?v=1\&t=hra6igpp\&s=553cb83b8155811d892d2f4687a3b3b3d7e6d903 http://onlinelibrary.wiley.com/store/10.1002/2013GL058980/asset/grl51394.pdf?v=1\&t=hra7ekea\&s=41d9ca20f856d9270a4f11336ea0ee5e556b8c64},
year = {2014}
}
@article{Sassen2012,
abstract = {Developing a predictive understanding of subsurface contaminant plume evolution and natural attenuation capacity is hindered by the inability to tractably characterize controlling reactive transport properties over field-relevant scales. Here we explore a concept of reactive facies, which is based on the hypothesis that subsurface units exist that have unique distributions of properties that influence reactive transport. We further hypothesize that geophysical methods can be used to identify and spatially distribute reactive facies and their associated parameters. We test the reactive facies concept at a U.S. Department of Energy uranium-contaminated groundwater site, where we have analyzed the relationships between laboratory and field (including radar and seismic tomographic) data sets. Our analysis suggests that there are two reactive facies that have unique distributions of mineralogy, texture, hydraulic conductivity, and geophysical attributes. We use these correlations within a Bayesian framework to integrate the dense geophysical data sets with the sparse core-based measurements. This yields high-resolution (0.25 m × 0.25 m) estimates of reactive facies and their associated properties and uncertainties along the 2-D tomographic transects. Comparison with colocated samples shows that the estimated properties fall within 95\% uncertainty bounds. To illustrate the value of reactive facies characterization approach, we used the geophysically estimated properties to parameterize reactive transport models, which were then used to simulate migration of an acidic-U plume through the domain. Modeling results suggest that each identified reactive facies exerts a unique control on plume evolution, highlighting the usefulness of the reactive facies concept for spatially distributing properties that control reactive transport over field-relevant scales.},
author = {Sassen, Douglas S. and Hubbard, Susan S. and Bea, Sergio A. and Chen, Jinsong and Spycher, Nicolas and Denham, Miles E.},
doi = {10.1029/2011WR011047},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/Z9VWMU4P/abstract.html:html;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/BJRN8G33/Sassen et al. - 2012 - Reactive facies An approach for parameterizing fi.pdf:pdf},
issn = {1944-7973},
journal = {Water Resources Research},
keywords = {Bayesian estimation,Reactive transport,Uranium,ground-penetrating radar,hydrogeophysics,tomography},
language = {en},
mendeley-tags = {Bayesian estimation,Reactive transport,Uranium,ground-penetrating radar,hydrogeophysics,tomography},
number = {10},
pages = {n/a--n/a},
shorttitle = {Reactive facies},
title = {{Reactive facies: An approach for parameterizing field-scale reactive transport models using geophysical methods}},
url = {http://onlinelibrary.wiley.com/doi/10.1029/2011WR011047/abstract http://onlinelibrary.wiley.com/store/10.1029/2011WR011047/asset/wrcr13568.pdf?v=1\&t=hr7fvjl6\&s=a4d013d637519aae245a2bc4b0688c5a34027b90},
volume = {48},
year = {2012}
}
@article{Ivanovic2009,
annote = {
        From Duplicate 2 ( 
        
          Science versus politics: truth and uncertainty in predictive modelling
        
         - Ivanovi\'{c}, R. F.; Freer, J. E. )

        
        

        

        

      },
author = {Ivanovi\'{c}, R. F. and Freer, J. E.},
doi = {10.1002/hyp.7406},
issn = {1099-1085},
journal = {Hydrological Processes},
language = {en},
number = {17},
pages = {2549--2554},
shorttitle = {Science versus politics},
title = {{Science versus politics: truth and uncertainty in predictive modelling}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/hyp.7406/abstract http://onlinelibrary.wiley.com/store/10.1002/hyp.7406/asset/7406\_ftp.pdf?v=1\&t=hf3ojjdh\&s=82b8d938e041aa4c2579c4de09b01cb06e0cd938},
volume = {23},
year = {2009}
}
@incollection{ChandrikaKamath2009,
annote = {doi:10.1201/9781420069815-c8},
author = {{Chandrika Kamath} and {Nikil Wale} and {George Karypis} and {Gaurav Pandey} and {Vipin Kumar} and {Krishna Rajan} and {NagizaF Samatova} and {Paul Breimyer} and {Guruprasad Kora} and {Chongle Pan} and {Srikanth Yoginath}},
booktitle = {Scien},
isbn = {978-1-4200-6980-8},
month = dec,
publisher = {Chapman and Hall/CRC},
series = {Chapman \& Hall/CRC Computational Science},
title = {{Scientific Data Analysis*}},
url = {http://dx.doi.org/10.1201/9781420069815-c8},
year = {2009}
}
@article{Haas1997,
abstract = {Disinfection contactors are frequently characterized using tracer studies to determine macromixing patterns. For some applications, such as compliance with the surface water treatment rule, this information can be interpreted directly without much analysis. However, when tracer studies are performed to characterize residence time distributions for design purposes, this information is frequently analyzed using a method of moments approach. This paper shows that the method of moments approach, when compared to a nonlinear regression approach, produces a biased estimate of mean residence time and dimensionless variance, and one with a greater mean square error. The amount of bias in moments estimators is significant in a numerical sense, and leads to qualitatively poor estimation of the resulting residence time distribution. Examples are given of characterization of a pilot-scale chlorine contactor and a pilot-scale ozone contactor.},
author = {Haas, C. and Joffe, J. and Heath, M. and Jacangelo, J.},
doi = {10.1061/(ASCE)0733-9372(1997)123:2(107)},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/I2UVZZWB/Haas et al. - 1997 - Continuous Flow Residence Time Distribution Functi.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/TQMH4M4B/Haas et al. - 1997 - Continuous Flow Residence Time Distribution Functi.html:html},
issn = {0733-9372},
journal = {Journal of Environmental Engineering},
number = {2},
pages = {107--114},
title = {{Continuous Flow Residence Time Distribution Function Characterization}},
url = {http://ascelibrary.org/doi/abs/10.1061/\%28ASCE\%290733-9372\%281997\%29123\%3A2\%28107\%29 http://ascelibrary.org/doi/pdf/10.1061/\%28ASCE\%290733-9372\%281997\%29123\%3A2\%28107\%29},
volume = {123},
year = {1997}
}
@incollection{Letcher2011j,
address = {Boston},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/CWKMABET/Letcher and Vallero - 2011 - Introduction.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {1},
publisher = {Academic Press},
title = {{Introduction}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100415 http://www.sciencedirect.com/science/article/pii/B9780123814753100415/pdfft?md5=80d0c518e60d8a65e6e1b76a303a3a7a\&pid=3-s2.0-B9780123814753100415-main.pdf},
year = {2011}
}
@article{Erdem2013,
author = {Erdem, Arzu},
doi = {10.1515/jip-2013-0019},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/UT4TMHIG/Erdem - 2013 - An adaptive algorithm for determination of source .html:html},
issn = {0928-0219, 1569-3945},
journal = {Journal of Inverse and Ill-Posed Problems},
month = jan,
number = {0},
title = {{An adaptive algorithm for determination of source terms in a linear parabolic problem}},
url = {http://www.degruyter.com/view/j/jip.ahead-of-print/jip-2013-0019/jip-2013-0019.xml?format=INT},
volume = {0},
year = {2013}
}
@article{Srinivasan2008,
abstract = {This is Part-II of a two-part article that presents analytical solutions to multi-species reactive transport equations coupled through sorption and sequential first-order reactions. In Part-I, we provide the mathematical derivations and in this article we discuss the computational techniques for implementing these solutions. We adopt these techniques to develop a general computer code and use it to verify the solutions. We also simplify the general solutions for various special-case transport scenarios involving zero initial condition, identical retardation factors and zero advection. In addition to this, we derive specialized solution expressions for zero dispersion and steady-state conditions. Whereever possible, we compare these special-case solutions against previously published analytical solutions to establish the validity of the new solution. Finally, we test the new solution against other published analytical and semi-analytical solutions using a set of example problems.},
author = {Srinivasan, V. and Clement, T.P.},
doi = {10.1016/j.advwatres.2007.08.001},
issn = {0309-1708},
journal = {Advances in Water Resources},
keywords = {Analytical solution,Coupled reactive transport,Model validation,Multispecies transport,Radio-active decay,Reactive transport,Sequential reactions},
mendeley-tags = {Analytical solution,Coupled reactive transport,Model validation,Multispecies transport,Radio-active decay,Reactive transport,Sequential reactions},
month = feb,
number = {2},
pages = {219--232},
shorttitle = {Analytical solutions for sequentially coupled one-},
title = {{Analytical solutions for sequentially coupled one-dimensional reactive transport problems – Part II: Special cases, implementation and testing}},
url = {http://www.sciencedirect.com/science/article/pii/S0309170807001285 http://pdn.sciencedirect.com/science?\_ob=MiamiImageURL\&\_cid=271718\&\_user=4420\&\_pii=S0309170807001285\&\_check=y\&\_origin=article\&\_zone=toolbar\&\_coverDate=2008--29\&view=c\&originContentFamily=serial\&wchp=dGLbVBA-zSkWA\&md5=053dfbdda60509c984d57af056e8a25d\&pid=1-s2.0-S0309170807001285-main.pdf http://pdn.sciencedirect.com/science?\_ob=MiamiImageURL\&\_cid=271718\&\_user=4420\&\_pii=S0309170807001285\&\_check=y\&\_origin=article\&\_zone=toolbar\&\_cove},
volume = {31},
year = {2008}
}
@article{Schoups2006a,
abstract = {The numerical simulation of long-term large-scale (field to regional) variably saturated subsurface flow and transport remains a computational challenge, even with today's computing power. Therefore, it is appropriate to develop and use simplified models that focus on the main processes operating at the pertinent time and space scales, as long as the error introduced by the simpler model is small relative to the uncertainties associated with the spatial and temporal variation of boundary conditions and parameter values. This study investigates the effects of various model simplifications on the prediction of long-term soil salinity and salt transport in irrigated soils. Average root-zone salinity and cumulative annual drainage salt load were predicted for a 10-year period using a one-dimensional numerical flow and transport model (i.e. UNSATCHEM) that accounts for solute advection, dispersion and diffusion, and complex salt chemistry. The model uses daily values for rainfall, irrigation, and potential evapotranspiration rates. Model simulations consist of benchmark scenarios for different hypothetical cases that include shallow and deep water tables, different leaching fractions and soil gypsum content, and shallow groundwater salinity, with and without soil chemical reactions. These hypothetical benchmark simulations are compared with the results of various model simplifications that considered (i) annual average boundary conditions, (ii) coarser spatial discretization, and (iii) reducing the complexity of the salt-soil reaction system. Based on the 10-year simulation results, we conclude that salt transport modelling does not require daily boundary conditions, a fine spatial resolution, or complex salt chemistry. Instead, if the focus is on long-term salinity, then a simplified modelling approach can be used, using annually averaged boundary conditions, a coarse spatial discretization, and inclusion of soil chemistry that only accounts for cation exchange and gypsum dissolution–precipitation. We also demonstrate that prediction errors due to these model simplifications may be small, when compared with effects of parameter uncertainty on model predictions. The proposed model simplifications lead to larger time steps and reduced computer simulation times by a factor of 1000. Copyright © 2006 John Wiley \& Sons, Ltd.},
author = {Schoups, G. and Hopmans, J. W. and Tanji, K. K.},
doi = {10.1002/hyp.6082},
issn = {1099-1085},
journal = {Hydrological Processes},
keywords = {gypsum,major ion chemistry,multicomponent transport,soil salinity,unsaturated flow},
language = {en},
mendeley-tags = {gypsum,major ion chemistry,multicomponent transport,soil salinity,unsaturated flow},
month = aug,
number = {13},
pages = {2647--2668},
title = {{Evaluation of model complexity and space–time resolution on the prediction of long-term soil salinity dynamics, western San Joaquin Valley, California}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/hyp.6082/abstract http://onlinelibrary.wiley.com/store/10.1002/hyp.6082/asset/6082\_ftp.pdf?v=1\&t=hv1codwi\&s=2a7c1233f9284e27c0f1e923c61c5439c61f2856},
volume = {20},
year = {2006}
}
@article{Yakirevich2013,
abstract = {Abstract Improving understanding of chemical transport in the subsurface commonly employs evolving groundwater monitoring networks. The objective of this work was to apply the information theory to propose an objective algorithm for augmenting a subsurface monitoring network (SMN) with the purpose of discrimination of conceptually different subsurface flow and transport models. This method determines new monitoring locations where the Kullback-Leibler total information gain is maximized. The latter is computed based on estimates of the uncertainty in modeling results and uncertainty in observations. The method was applied to discriminate models in 1) a synthetic case of groundwater contamination from a point source; 2) the tracer experiment conducted at the USDA-ARS OPE3 research site where a pulse of KCL solution was applied with irrigation water and CL- concentrations were subsequently monitored. Models were compared that included or ignored the effect of subsurface soil lenses on chemical transport Pedotransfer functions were used to develop the ensemble of models for estimating the uncertainty in modeling results obtained with the numerical 3D flow and transport model. Peak tracer breakthrough concentrations were used to define the information gains. The determination of the new locations to augment existing ones was conducted on a 2-D grid. The information gain peaked in narrow area, and additional observation locations were very well spatially defined. Well-calibrated models provided a single optimal location, whereas, if models were not calibrated well, the Bayesian estimates of the new observation location depended on the activation sequence assumed for existing locations. The information gain maximization can suggest data collection locations to reduce uncertainties in the conceptual models of subsurface flow and transport.},
author = {Yakirevich, A. and Pachepsky, Y.A. and Gish, T.J.},
doi = {10.1016/j.jhydrol.2013.07.032},
issn = {0022-1694},
journal = {Journal of \ldots},
keywords = {Contaminant transport model,Ensemble modeling,Groundwater monitoring network,Sequential design},
mendeley-tags = {Contaminant transport model,Ensemble modeling,Groundwater monitoring network,Sequential design},
title = {{Augmentation of groundwater monitoring networks using information theory and ensemble modeling with pedotransfer functions}},
url = {http://www.sciencedirect.com/science/article/pii/S0022169413005593 http://www.sciencedirect.com/science?\_ob=MiamiImageURL\&\_cid=271842\&\_user=4420\&\_pii=S0022169413005593\&\_check=y\&\_origin=article\&\_zone=toolbar\&\_coverDate=01-Aug-2013\&view=c\&originContentFamily=serial\&wchp=dGLbVBA-zSkzk\&md5=ce5dd7386e906be9b9c0482fc2bdd0bb\&pid=1-s2.0-S0022169413005593-main.pdf},
year = {2013}
}
@article{Bloschl2001,
author = {Bl\"{o}schl, G\"{u}nter},
doi = {10.1002/hyp.432},
issn = {0885-6087},
journal = {Hydrological Processes},
month = mar,
number = {4},
pages = {709--711},
title = {{Scaling in hydrology}},
url = {http://www.hydro.tuwien.ac.at/fileadmin/mediapool-hydro/Publikationen/bloeschl/2001\_Bloeschl\_HP.pdf http://doi.wiley.com/10.1002/hyp.432},
volume = {15},
year = {2001}
}
@article{Fan2014,
abstract = {This study proposes an environmental- and health-risk-induced remediation design approach for benzene-contaminated groundwater. It involves exposure frequency and intake rates that are important but difficult to be exactly quantified as breakthrough point. Flexible health-risk control is considered in the simulation and optimization work. The proposed approach is then applied to a petroleum-contaminated site in western Canada. Different situations about remediation durations, public concerns, and satisfactory degrees are addressed by the approach. The relationship between environmental standards and health-risk limits is analyzed, in association with their effect on remediation costs. Insights of three uncertain factors (i.e. exposure frequency, intake rate and health-risk threshold) for the remediation system are also explored, on a basis of understanding their impacts on health risk as well as their importance order. The case study results show that (1) nature attenuation plays a more important role in long-term remediation scheme than the pump-and-treat system; (2) carcinogenic risks have greater impact on total pumping rates than environmental standards for long-term remediation; (3) intake rates are the second important factor affecting the remediation system’s performance, followed by exposure frequency; (4) the 10-year remediation scheme is the most robust choice when environmental and health-risk concerns are not well quantified.},
author = {Fan, X. and He, L. and Lu, H. W. and Li, J.},
doi = {10.1016/j.chemosphere.2014.04.082},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/5UUM2XTI/Fan et al. - 2014 - Environmental- and health-risk-induced remediation.pdf:pdf},
issn = {0045-6535},
journal = {Chemosphere},
keywords = {Fuzzy set,Remediation design,ground water,health risk,uncertainty},
mendeley-tags = {Fuzzy set,Remediation design,ground water,health risk,uncertainty},
month = sep,
pages = {604--612},
shorttitle = {Environmental- and health-risk-induced remediation},
title = {{Environmental- and health-risk-induced remediation design for benzene-contaminated groundwater under parameter uncertainty: A case study in Western Canada}},
url = {http://www.sciencedirect.com/science/article/pii/S004565351400592X http://www.sciencedirect.com/science/article/pii/S004565351400592X/pdfft?md5=b0d66f43156d5dfbf86301e7dc9323b8\&pid=1-s2.0-S004565351400592X-main.pdf},
volume = {111},
year = {2014}
}
@techreport{Vinod2014,
abstract = {Theil (1968)  proposed a transformation of regression residuals so that they are best (minimizes the trace of its covariance matrix), linear, unbiased  and subject to the constraint that its covariance matrix is scalar (BLUS) in the sense that it is proportional to the identity matrix. Despite their desirable theoretical properties Theil's tests for autocorrelation and heteroscedasticity using BLUS residuals are not much used by researchers, perhaps because of computational difficulties. My R program is checked against  Ford (2008) , who provides an example with implementations in Eviews and SAS software.  Vinod (2010)  suggests going beyond testing by making  efficient adjustments to overcome the ill effects of non-scalar covariances. Links for R software to  implement those tools are provided here near the end of the paper. I hope that my R software will help researchers fill a gap in the literature by studying the size and power of Theil's tests in comparison with other tests in the literature, and begin to focus on simultaneously overcoming these two common problems.},
address = {Rochester, NY},
author = {Vinod, Hrishikesh D.},
institution = {Social Science Research Network},
keywords = {Serially correlated errors,regression,scalar covariance},
mendeley-tags = {Serially correlated errors,regression,scalar covariance},
month = mar,
title = {{Theil's BLUS Residuals and R Tools for Testing and Removing Autocorrelation and Heteroscedasticity}},
url = {http://papers.ssrn.com/abstract=2412740},
year = {2014}
}
@techreport{Qaddumi2009,
abstract = {Climate change is real, and taking prudent measures to plan for and adapt to climate change must become an integral part of the Bank's water practice. There is now ample evidence that increased hydrologic variability and change in climate has and will continue have a profound impact on the water sector through the hydrologic cycle, water availability, water demand, and water allocation at the global, regional, basin, and local levels. This report and the analytical work leading to it are focused on key topics related to the impact of climate change on the water cycle and water investments. This report contributes to the World Bank agenda on climate change and more specifically, informs the water sector investments on climate issues and climate-smart adaptation options. Using the existing knowledge and additional analysis commissioned. The report illustrates that climate change is affecting the hydrologic cycle and the projected future hydrology will have a direct impact on the water resources base availability, usage, and management. Depending on the type of the water investment, this impact can be positive, negative, or neutral. The report addresses the stress on and vulnerability of the water systems through use of reliability, resilience, and robustness as the key indicators of sensitivity of water systems for climate induced failure. Current practices in the sector are examined in order to better understand the state-of-the-science for incorporating current and future variability and change in hydrology and climate in the Bank's portfolio for project planning and design. New and innovative practices taking into account adaptation options for water systems and risk-based decision making in water investments are reviewed and assessed for application to investments in infrastructure. The climate change dimension is placed within the context of the impact of other factors (within and outside the sector) such as population growth (and associated increase in demand) and land management (particularly as related to water), which in some cases may be far more significant and critical than that of climate change in some parts of the world. Finally, recommendations for a progressive agenda on water and climate change are made.},
author = {Qaddumi, Halla Maher and Dickson, Eric and Diez, Sylvia Michele and Hirji, Rafik Fatehali and Puz, Gabrielle and Danilenko, Alexander V. and Jacobsen, Michael and Alavian, Vahid and Pizarro, Carolina and Blankespoor, Brian},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/HEGER34D/Qaddumi et al. - 2009 - Water and climate change  understanding the risks.pdf:pdf},
institution = {The World Bank},
keywords = {Atmospheric water,Atmospheric water vapor,Climate,Climate Action,basins,catchment level},
language = {en},
mendeley-tags = {Atmospheric water,Atmospheric water vapor,Climate,Climate Action,basins,catchment level},
month = nov,
pages = {1--174},
shorttitle = {Water and climate change},
title = {{Water and climate change : understanding the risks and making climate-smart investment decisions}},
url = {http://documents.worldbank.org/curated/en/2009/11/11717870/water-climate-change-understanding-risks-making-climate-smart-investment-decisions http://www-wds.worldbank.org/external/default/WDSContentServer/WDSP/IB/2010/02/01/000333038\_20100201020244/Rendered/PDF/529110NWP0Box31ge0web0large01128110.pdf},
year = {2009}
}
@article{Deolmi2013,
abstract = {This paper investigates the solution of a parabolic inverse problem based upon the convection–diffusion–reaction equation, which can be used to estimate both water and air pollution. We will consider both known and unknown source location: while in the first case the problem is solved using a Projected Damped Gauss Newton (PDGN), in the second one it is ill-posed and an adaptive parametrization with space–time localization will be adopted to regularize it.},
author = {Deolmi, G. and Marcuzzi, F.},
doi = {10.1016/j.amc.2013.02.040},
issn = {0096-3003},
journal = {Applied Mathematics and Computation},
keywords = {Adaptive parametrization,Finite Element method,Inverse problem,Regularization,Space–time localization},
mendeley-tags = {Adaptive parametrization,Finite Element method,Inverse problem,Regularization,Space–time localization},
month = apr,
number = {16},
pages = {8435--8454},
title = {{A parabolic inverse convection–diffusion–reaction problem solved using space–time localization and adaptivity}},
url = {http://www.sciencedirect.com/science/article/pii/S0096300313001719 http://pdn.sciencedirect.com/science?\_ob=MiamiImageURL\&\_cid=271588\&\_user=4420\&\_pii=S0096300313001719\&\_check=y\&\_origin=article\&\_zone=toolbar\&\_coverDate=2013--15\&view=c\&originContentFamily=serial\&wchp=dGLbVBA-zSkWA\&md5=eabbae783fa4a28e3a587ba03525c42d\&pid=1-s2.0-S0096300313001719-main.pdf},
volume = {219},
year = {2013}
}
@incollection{Nagendran2011,
abstract = {Agriculture refers to the production of food material and related goods through farming. Like other facets of developmental activities, agriculture too has been a major source of environmental pollution and waste generation. In this context, this chapter provides an overview of the complexities of agricultural wastes, their impacts and possible options to manage them. Agricultural waste refers to waste produced as a result of various agricultural operations. It includes manure and other wastes from farms, poultry houses and slaughterhouses; harvest waste; fertilizer run- off from fields; pesticides that enter into water, air or soils; and salt and silt drained from fields. Agriculture management is a complex process involving individual attention to address the issues related to all functional components such as water, fertilizers, and biocides. A significant constraint encountered in managing agriculture waste is lack of data pertaining to different geographical regions. Therefore, the urgent need is to formulate a tangible mechanism to create an international database on the quantity, composition and characteristics of agro wastes. Preparation of a compendium flagging the success stories and challenges in respect of developed and developing economies would serve well for officials in governance and on the field.},
address = {Boston},
author = {Nagendran, R.},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/4E5WR56X/Nagendran - 2011 - Chapter 24 - Agricultural Waste and Pollution.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {341--355},
publisher = {Academic Press},
title = {{Chapter 24 - Agricultural Waste and Pollution}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100245 http://www.sciencedirect.com/science/article/pii/B9780123814753100245/pdfft?md5=ddea9aea8441dc8c91941159ede241e0\&pid=3-s2.0-B9780123814753100245-main.pdf},
year = {2011}
}
@article{Soto-Varela,
abstract = {Abstract
Headwater stream, draining from a rural catchment in NW Spain, was sampled during baseflow and storm-event conditions to investigate the temporal variability in dissolved and particulate Al, Fe, Mn, Cu and Zn concentrations and the role of discharge (Q), pH, dissolved organic carbon (DOC) and suspended sediment (SS) in the transport of dissolved and particulate metals. Under baseflow and storm-event conditions, concentrations of the five metals were highly variable. The results of this study reveal that all metal concentrations are correlated with SS. DOC and SS appeared to influence both the metal concentrations and the partitioning of metals between dissolved and particulate. The SS was a good predictor of particulate metal levels. Distribution coefficients (KD) were similar between metals (4.72–6.55) and did not change significantly as a function of discharge regime. Stepwise multiple linear regression analysis reveals that the most important variable to explain storm-event KD for Al and Fe is DOC. The positive relationships found between metals, in each fraction, indicate that these elements mainly come from the same source. Metal concentrations in the stream were relatively low.},
author = {Soto-Varela, F. and Rodr\'{\i}guez-Blanco, M.L. and Taboada-Castro, M.M. and Taboada-Castro, M.T.},
doi = {10.1016/j.apgeochem.2013.08.006},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/ADK8N938/Soto-Varela et al. - Identifying environmental and geochemical variable.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/VQD7MHK8/Soto-Varela et al. - Identifying environmental and geochemical variable.html:html},
issn = {0883-2927},
journal = {Applied Geochemistry},
title = {{Identifying environmental and geochemical variables governing metal concentrations in a stream draining headwaters in NW Spain}},
url = {http://www.sciencedirect.com/science/article/pii/S0883292713002114 http://www.sciencedirect.com/science/article/pii/S0883292713002114/pdfft?md5=9e62ed1862b389dd5b95dd1ca42293b4\&pid=1-s2.0-S0883292713002114-main.pdf}
}
@incollection{Letcher2011h,
address = {Boston},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/MIJ66DH4/Letcher and Vallero - 2011 - Introduction.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {75},
publisher = {Academic Press},
title = {{Introduction}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100427 http://www.sciencedirect.com/science/article/pii/B9780123814753100427/pdfft?md5=1253e20cf8ae352be1a70c5d34fe65c9\&pid=3-s2.0-B9780123814753100427-main.pdf},
year = {2011}
}
@incollection{RobertRoss2009,
annote = {doi:10.1201/9781420069815-c2},
author = {{Robert Ross} and {Alok Choudhary} and {Garth Gibson} and {Wei-keng Liao}},
booktitle = {Scien},
isbn = {978-1-4200-6980-8},
month = dec,
publisher = {Chapman and Hall/CRC},
series = {Chapman \& Hall/CRC Computational Science},
title = {{Parallel Data Storage and Access}},
url = {http://dx.doi.org/10.1201/9781420069815-c2},
year = {2009}
}
@article{Meyer2012,
abstract = {The U.S. Department of Energy's (DOE) Office of Environmental Management (DOE/EM) currently supports an effort to understand and predict the fate of nuclear contaminants and their transport in natural and engineered systems. Geologists, hydrologists, physicists and computer scientists are working together to create models of existing nuclear waste sites, to simulate their behavior and to extrapolate it into the future. We use visualization as an integral part in each step of this process. In the first step, visualization is used to verify model setup and to estimate critical parameters. High-performance computing simulations of contaminant transport produces massive amounts of data, which is then analyzed using visualization software specifically designed for parallel processing of large amounts of structured and unstructured data. Finally, simulation results are validated by comparing simulation results to measured current and historical field data. We describe in this article how visual analysis is used as an integral part of the decision-making process in the planning of ongoing and future treatment options for the contaminated nuclear waste sites. Lessons learned from visually analyzing our large-scale simulation runs will also have an impact on deciding on treatment measures for other contaminated sites.},
author = {Meyer, J. and Bethel, E.W. and Horsman, J.L. and Hubbard, S.S. and Krishnan, H. and Romosan, A. and Keating, E.H. and Monroe, L. and Strelitz, R. and Moore, P. and Taylor, G. and Torkian, B. and Johnson, T.C. and Gorton, I.},
doi = {10.1109/TVCG.2012.278},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/SQ4I3MI2/Meyer et al. - 2012 - Visual Data Analysis as an Integral Part of Enviro.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/84QRK9X3/abs\_all.html:html},
issn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Computational modeling,Contaminant transport,Contamination,DOE/EM,Data models,Data visualization,Environmental Management,Google,Monitoring,Pollution measurement,Visual analytics,data management,data visualisation,decision-making process,environmental science computing,high-performance computing,large-scale simulation,nuclear contaminant,nuclear waste site,parallel processing,parallel rendering,visual data analysis,visualization software,waste management},
mendeley-tags = {Computational modeling,Contaminant transport,Contamination,DOE/EM,Data models,Data visualization,Environmental Management,Google,Monitoring,Pollution measurement,Visual analytics,data management,data visualisation,decision-making process,environmental science computing,high-performance computing,large-scale simulation,nuclear contaminant,nuclear waste site,parallel processing,parallel rendering,visual data analysis,visualization software,waste management},
month = dec,
number = {12},
pages = {2088--2094},
title = {{Visual Data Analysis as an Integral Part of Environmental Management}},
url = {http://ieeexplore.ieee.org/ielx5/2945/6327196/06327213.pdf?tp=\&arnumber=6327213\&isnumber=6327196 http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6327213\&tag=1},
volume = {18},
year = {2012}
}
@article{Li2013,
abstract = {Numerical models for variable-density flow and solute transport (VDFST) are widely used to simulate seawater intrusion and related problems. The mathematical model for VDFST is a coupled nonlinear dynamical system, so the numerical discretizations in time and space are usually required to be as fine as possible. As a result, fine-scale transient models require large computational time, which is a disadvantage for state estimation, forward prediction or model inversion. The purpose of this research is to develop mathematical and numerical methods to simulate VDFST via a model order reduction technique called Proper Orthogonal Decomposition (POD) designed for nonlinear dynamical systems. POD was applied to extract leading “model features” (basis functions) through singular value decomposition (SVD) from observational data or simulations (snapshots) of high-dimensional systems. These basis functions were then used in the Galerkin projection procedure that yielded low-dimensional (reduced-order) models. The original full numerical models were also discretized by the Galerkin Finite-Element Method (GFEM). The implementation of the POD reduced-order method was straightforward when applied to the full order model to the complex model. The developed GFEM-POD model was applied to solve two classic VDFST cases, the Henry problem and the Elder problem, in order to investigate the accuracy and efficiency of the POD model reduction method. Once the snapshots from full model results are obtained, the reduced-order model can reproduce the full model results with acceptable accuracy but with less computational cost in comparison with the full model, which is useful for model calibration and data assimilation problems. We found that the accuracy and efficiency of the POD reduced-order model is mainly determined by the optimal selection of snapshots and POD bases. Validation and verification experiments confirmed our POD model reduction procedure.},
author = {Li, Xinya and Chen, Xiao and Hu, Bill X. and Navon, I. Michael},
doi = {10.1016/j.jhydrol.2013.09.011},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/RMNCFWSJ/Li et al. - 2013 - Model reduction of a coupled numerical model using.pdf:pdf},
issn = {0022-1694},
journal = {Journal of Hydrology},
keywords = {Galerkin projection,Model reduction,Proper orthogonal decomposition,Single value decomposition,Variable density flow},
mendeley-tags = {Galerkin projection,Model reduction,Proper orthogonal decomposition,Single value decomposition,Variable density flow},
month = dec,
pages = {227--240},
title = {{Model reduction of a coupled numerical model using proper orthogonal decomposition}},
url = {http://www.sciencedirect.com/science/article/pii/S0022169413006562 http://www.sciencedirect.com/science/article/pii/S0022169413006562/pdfft?md5=628713cff94d3a13e1d75748e7ee02b8\&pid=1-s2.0-S0022169413006562-main.pdf},
volume = {507},
year = {2013}
}
@article{Wood2009a,
author = {Wood, Brian D.},
doi = {10.1016/j.advwatres.2008.08.015},
issn = {03091708},
journal = {Advances in Water Resources},
month = may,
number = {5},
pages = {723--736},
publisher = {Elsevier Ltd},
title = {{The role of scaling laws in upscaling}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0309170808001498},
volume = {32},
year = {2009}
}
@article{Perron2003,
abstract = {Abstract. Recently, Vogelsang (1999) proposed a method to detect outliers which explicitly imposes the null hypothesis of a unit root. It works in an iterative fashion to select multiple outlier in a given series. We show, via simulations, that, under the null hypothesis of no outliers, it has the right size in finite samples to detect a single outlier but, when applied in an iterative fashion to select multiple outliers, it exhibits severe size distortions towards finding an excessive number of outliers. We show that his iterative method is incorrect and derive the appropriate limiting distribution of the test at each step of the search. Whether corrected or not, we also show that the outliers need to be very large for the method to have any decent power. We propose an alternative method based on first-differenced data that has considerably more power. We also show that our method to identify outliers leads to unit root tests with more accurate finite sample size and robustness to departures from a unit root. The issues are illustrated using two US/Finland real-exchange rate series.},
author = {Perron, Pierre and Rodr\'{\i}guez, Gabriel},
doi = {10.1111/1467-9892.00303},
issn = {1467-9892},
journal = {Journal of Time Series Analysis},
keywords = {Additive outliers,JEL: C2- C3- C5,Wiener process,power,size,t-test,unit root},
language = {en},
mendeley-tags = {Additive outliers,JEL: C2- C3- C5,Wiener process,power,size,t-test,unit root},
month = mar,
number = {2},
pages = {193--220},
title = {{Searching for Additive Outliers in Nonstationary Time Series*}},
url = {http://onlinelibrary.wiley.com/doi/10.1111/1467-9892.00303/abstract},
volume = {24},
year = {2003}
}
@article{Myung2000,
abstract = {Model selection should be based not solely on goodness-of-fit, but must also consider model complexity. While the goal of mathematical modeling in cognitive psychology is to select one model from a set of competing models that best captures the underlying mental process, choosing the model that best fits a particular set of data will not achieve this goal. This is because a highly complex model can provide a good fit without necessarily bearing any interpretable relationship with the underlying process. It is shown that model selection based solely on the fit to observed data will result in the choice of an unnecessarily complex model that overfits the data, and thus generalizes poorly. The effect of over-fitting must be properly offset by model selection methods. An application example of selection methods using artificial data is also presented. Copyright 2000 Academic Press.},
author = {Myung, Ij},
doi = {10.1006/jmps.1999.1283},
issn = {0022-2496},
journal = {Journal of mathematical psychology},
month = mar,
number = {1},
pages = {190--204},
pmid = {10733864},
title = {{The Importance of Complexity in Model Selection.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10733864},
volume = {44},
year = {2000}
}
@article{Nearing2013a,
abstract = {Data assimilation is the Bayesian conditioning of uncertain model simulations on observations to reduce uncertainty about model states. In practice, it is common to make simplifying assumptions about the prior and posterior state distributions, and to employ approximations of the likelihood function, which can reduce the efficiency of the filter. We propose metrics that quantify how much of the uncertainty in a Bayesian posterior state distribution is due to (i) the observation operator, (ii) observation error, and (iii) approximations of Bayes' Law. Our approach uses discrete Shannon entropy to quantify uncertainty, and we define the utility of an observation (for reducing uncertainty about a model state) as the ratio of the mutual information between the state and observation to the entropy of the state prior. These metrics make it possible to analyze the efficiency of a proposed observation system and data assimilation strategy, and provide a way to examine the propagation of information through the dynamic system model. We demonstrate the procedure on the problem of estimating profile soil moisture from observations at the surface (top 5 cm). The results show that when synthetic observations of 5 cm soil moisture are assimilated into a three-layer model of soil hydrology, the ensemble Kalman filter does not use all of the information available in observations.},
author = {Nearing, Grey S. and Gupta, Hoshin V. and Crow, Wade T. and Gong, Wei},
doi = {10.1002/wrcr.20177},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/CG4JIM4Z/Nearing et al. - 2013 - An approach to quantifying the efficiency of a Bay.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/XWIW3JXQ/Nearing et al. - 2013 - An approach to quantifying the efficiency of a Bay.html:html;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/CC9P9FJ3/Nearing et al. - 2013 - An approach to quantifying the efficiency of a Bay.pdf:pdf},
issn = {1944-7973},
journal = {Water Resources Research},
keywords = {data assimilation,information theory},
language = {en},
mendeley-tags = {data assimilation,information theory},
number = {4},
pages = {2164--2173},
title = {{An approach to quantifying the efficiency of a Bayesian filter}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/wrcr.20177/abstract http://onlinelibrary.wiley.com/store/10.1002/wrcr.20177/asset/wrcr20177.pdf?v=1\&t=hp6f68gk\&s=01f95a5a6dd3c130acb2b2e001babd3cba9f26e6 http://onlinelibrary.wiley.com/store/10.1002/wrcr.20177/asset/wrcr20177.pdf?v=1\&t=hrhgf4km\&s=b4b8b1b5f90953c8a1a5b06516a054b30b4b4ef7},
volume = {49},
year = {2013}
}
@article{Bloschl2010,
author = {Bl\"{o}schl, G\"{u}nter and Montanari, Alberto},
doi = {10.1002/hyp.7574},
issn = {1099-1085},
journal = {Hydrological Processes},
language = {en},
month = jan,
number = {3},
pages = {374--381},
title = {{Climate change impacts—throwing the dice?}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/hyp.7574/abstract},
volume = {24},
year = {2010}
}
@book{Snow1855,
abstract = {Snow expanded his reports on his cholera research in a book entitled On the Mode of Communication of Cholera published in London the same year. That book contained more statistical data confirming his theories. Over the next five years Snow continued his research, publishing a second edition of the book in 1855. This was so greatly revised and expanded that it was essentially a new work. In it Snow set forth his views of the etiology and spread of cholera, which he believed to be caused by a living organism (a belief confirmed by Koch's discovery of the cholera vibrio in 1883), and included statistical surveys made during the great cholera epidemic of 1854, demonstrating that the number of cholera deaths in each area of southern London corresponded to the degree of contamination of the local drinking water. This 1855 edition was the first to tell the dramatic story of the Broad Street pump, which, after contamination with sewage from a nearby pipe, caused 500 cholera deaths within the space of ten days. Once the epidemic had peaked, Snow persuaded the parish councilors to remove the pump handle, and the number of cholera attacks decreased rapidly. Snow's report of the Broad Street epidemic included a spot-map of the district showing the location of each pump and fatal cholera cases-- the first use of a spot-map in epidemiology.--J. Norman, 2006.},
author = {Snow, John},
edition = {2nd},
language = {en},
pages = {216},
publisher = {John Churchill},
title = {{On the Mode of Communication of Cholera}},
url = {http://books.google.com/books?id=-N0\_AAAAcAAJ},
year = {1855}
}
@article{Li2014,
abstract = {Technetium-99 (99Tc), iodine-129 (129I), and cesium-137 (137Cs) are among the key risk-drivers for environmental cleanup. Immobilizing these radionuclides, especially TcO4− and I−, has been challenging. TcO4− and I− bind very weakly to most sediments, such that distribution coefficients (Kd values; radionuclide concentration ratio of solids to liquids) are typically \&lt;2 mL/g; while Cs sorbs somewhat more strongly (Kd ∼ 50 mL/g). The objective of this laboratory study was to evaluate 13 cost-effective sorbents for TcO4−, I−, and Cs+ uptake from contaminated groundwater and sediments. Two organoclays sorbed large amounts of TcO4− (Kd \&gt; 1 × 105 mL/g), I− (Kd ≥ 1 × 104 mL/g), and Cs+ (Kd \&gt; 1 × 103 mL/g) and also demonstrated a largely irreversible binding of the radionuclides. Activated carbon GAC 830 was effective at sorbing TcO4− (Kd \&gt; 1 × 105 mL/g) and I− (Kd = 6.9 × 103 mL/g), while a surfactant modified chabazite was effective at sorbing TcO4− (Kd \&gt; 2.5 × 104 mL/g) and Cs+ (Kd \&gt; 6.5 × 103 mL/g). Several sorbents were effective for only one radionuclide, e.g., modified zeolite Y had TcO4−Kd \&gt; 2.3 × 105 mL/g, AgS had I− Kd = 2.5 × 104 mL/g, and illite, chabazite, surfactant modified clinoptilolite, and thiol-SAMMS had Cs+Kd \&gt; 103 mL/g. These low-cost and high capacity sorbents may provide a sustainable solution for environmental remediation.},
author = {Li, Dien and Kaplan, Daniel I. and Knox, Anna S. and Crapse, Kimberly P. and Diprete, David P.},
doi = {10.1016/j.jenvrad.2014.05.010},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/XXMNMMP9/Li et al. - 2014 - Aqueous 99Tc, 129I and 137Cs removal from contamin.pdf:pdf},
issn = {0265-931X},
journal = {Journal of Environmental Radioactivity},
keywords = {Cesium,Iodine,Organoclays,Sorbents,Technetium},
mendeley-tags = {Cesium,Iodine,Organoclays,Sorbents,Technetium},
month = oct,
pages = {56--63},
title = {{Aqueous 99Tc, 129I and 137Cs removal from contaminated groundwater and sediments using highly effective low-cost sorbents}},
url = {http://www.sciencedirect.com/science/article/pii/S0265931X14001507 http://www.sciencedirect.com/science/article/pii/S0265931X14001507/pdfft?md5=2bc89b6e7dd44c9b6d659bdb22035d17\&pid=1-s2.0-S0265931X14001507-main.pdf},
volume = {136},
year = {2014}
}
@article{Schoups2006,
author = {Schoups, G. and Hopmans, J. W.},
doi = {10.2136/vzj2005.0130},
issn = {1539-1663},
journal = {Vadose Zone Journal},
language = {en},
number = {3},
pages = {951},
title = {{Evaluation of Model Complexity and Input Uncertainty of Field-Scale Water Flow and Salt Transport}},
url = {https://dl.sciencesocieties.org/publications/vzj/abstracts/5/3/951},
volume = {5},
year = {2006}
}
@article{Mills2011,
author = {Mills, Peter},
doi = {10.1080/01431161.2010.507795},
issn = {0143-1161, 1366-5901},
journal = {International Journal of Remote Sensing},
month = nov,
number = {21},
pages = {6109--6132},
title = {{Efficient statistical classification of satellite measurements}},
url = {http://www.tandfonline.com/doi/abs/10.1080/01431161.2010.507795},
volume = {32},
year = {2011}
}
@article{Tonkin2009,
abstract = {We describe a subspace Monte Carlo (SSMC) technique that reduces the burden of calibration-constrained Monte Carlo when undertaken with highly parameterized models. When Monte Carlo methods are used to evaluate the uncertainty in model outputs, ensuring that parameter realizations reproduce the calibration data requires many model runs to condition each realization. In the new SSMC approach, the model is first calibrated using a subspace regularization method, ideally the hybrid Tikhonov-TSVD “superparameter” approach described by Tonkin and Doherty (2005). Sensitivities calculated with the calibrated model are used to define the calibration null-space, which is spanned by parameter combinations that have no effect on simulated equivalents to available observations. Next, a stochastic parameter generator is used to produce parameter realizations, and for each a difference is formed between the stochastic parameters and the calibrated parameters. This difference is projected onto the calibration null-space and added to the calibrated parameters. If the model is no longer calibrated, parameter combinations that span the calibration solution space are reestimated while retaining the null-space projected parameter differences as additive values. The recalibration can often be undertaken using existing sensitivities, so that conditioning requires only a small number of model runs. Using synthetic and real-world model applications we demonstrate that the SSMC approach is general (it is not limited to any particular model or any particular parameterization scheme) and that it can rapidly produce a large number of conditioned parameter sets.},
author = {Tonkin, Matthew and Doherty, John},
doi = {10.1029/2007WR006678},
issn = {1944-7973},
journal = {Water Resources Research},
keywords = {Monte Carlo,calibration,parameter estimation,uncertainty analysis},
language = {en},
mendeley-tags = {Monte Carlo,calibration,parameter estimation,uncertainty analysis},
number = {12},
pages = {n/a--n/a},
title = {{Calibration-constrained Monte Carlo analysis of highly parameterized models using subspace techniques}},
url = {http://onlinelibrary.wiley.com/doi/10.1029/2007WR006678/abstract http://onlinelibrary.wiley.com/store/10.1029/2007WR006678/asset/wrcr11640.pdf?v=1\&t=hfgcwafb\&s=339c119289516dd9c0966a3e326a76f221af6ae5},
volume = {45},
year = {2009}
}
@article{Bloschl2008,
author = {Bl\"{o}schl, G\"{u}nter and Reszler, Christian and Komma, J\"{u}rgen},
journal = {Environmental Modelling \& Software},
number = {4},
pages = {464--478},
title = {{A spatially distributed flash flood forecasting model}},
url = {http://www.sciencedirect.com/science/article/pii/S1364815207001247 http://www.hydrate.tesaf.unipd.it/WareHouse/PresentationAndPapers/Bl\"{o}schl EMS08 Flash Flood model.pdf},
volume = {23},
year = {2008}
}
@article{McLeod2000,
abstract = {In 1854, Dr. John Snow identified the Broad Street pump as the source of an intense cholera outbreak by plotting the location of cholera deaths on a dot-map. He had the pump handle removed and the outbreak ended\ldots or so one version of the story goes. In medical geography, the story of Snow and the Broad Street cholera outbreak is a common example of the discipline in action. While authors in other health-related disciplines focus on Snow's “shoe-leather epidemiology”, his development of a water-borne theory of cholera transmission, and/or his pioneering role in anaesthesia, it is the dot-map that makes him a hero in medical geography. The story forms part of our disciplinary identity. Geographers have helped to shape the Snow narrative: the map has become part of the myth. Many of the published accounts of Snow are accompanied by versions of the map, but which map did Snow use? What happens to the meaning of our story when the determinative use of the map is challenged? In his book On the Mode of Communication of Cholera (2nd ed., John Churchill, London, 1855), Snow did not write that he used a map to identify the source of the outbreak. The map that accompanies his text shows cholera deaths in Golden Square (the subdistrict of London's Soho district where the outbreak occurred) from August 19 to September 30, a period much longer than the intense outbreak. What happens to the meaning of the myth when the causal connection between the pump's disengagement and the end of the outbreak is examined? Snow's data and text do not support this link but show that the number of cholera deaths was abating before the handle was removed. With the drama of the pump handle being questioned and the map, our artifact, occupying a more illustrative than central role, what is our sense of Snow?},
author = {McLeod, Kari S},
doi = {10.1016/S0277-9536(99)00345-7},
issn = {0277-9536},
journal = {Social Science \& Medicine},
keywords = {Broad Street cholera outbreak,Disciplinary identity,Disease mapping,John Snow,Medical geography,Memorialization,Myth},
mendeley-tags = {Broad Street cholera outbreak,Disciplinary identity,Disease mapping,John Snow,Medical geography,Memorialization,Myth},
month = apr,
number = {7–8},
pages = {923--935},
shorttitle = {Our sense of Snow},
title = {{Our sense of Snow: the myth of John Snow in medical geography}},
url = {http://www.sciencedirect.com/science/article/pii/S0277953699003457 http://www.sciencedirect.com/science?\_ob=MiamiImageURL\&\_cid=271821\&\_user=4420\&\_pii=S0277953699003457\&\_check=y\&\_origin=article\&\_zone=toolbar\&\_coverDate=01-Apr-2000\&view=c\&originContentFamily=serial\&wchp=dGLzVlB-zSkzk\&md5=33bcdfc58cb61cf13ebdd7fb5fdf5ed6\&pid=1-s2.0-S0277953699003457-main.pdf},
volume = {50},
year = {2000}
}
@article{Nash1970a,
abstract = {The principles governing the application of the conceptual model technique to river flow forecasting are discussed. The necessity for a systematic approach to the development and testing of the model is explained and some preliminary ideas suggested.},
author = {Nash, J.E. and Sutcliffe, J.V.},
doi = {10.1016/0022-1694(70)90255-6},
issn = {0022-1694},
journal = {Journal of Hydrology},
month = apr,
number = {3},
pages = {282--290},
title = {{River flow forecasting through conceptual models part I — A discussion of principles}},
url = {http://www.sciencedirect.com/science/article/pii/0022169470902556 http://pdn.sciencedirect.com/science?\_ob=MiamiImageURL\&\_cid=271842\&\_user=4420\&\_pii=0022169470902556\&\_check=y\&\_origin=article\&\_zone=toolbar\&\_coverDate=1970--30\&view=c\&originContentFamily=serial\&wchp=dGLbVlB-zSkzS\&md5=dbe0a52180a8b34b2c9447e443053439\&pid=1-s2.0-0022169470902556-main.pdf},
volume = {10},
year = {1970}
}
@article{Western1999a,
author = {Western, Andrew W. and Bl\"{o}schl, G\"{u}nter},
journal = {Journal of Hydrology},
number = {3},
pages = {203--224},
title = {{On the spatial scaling of soil moisture}},
url = {http://www.sciencedirect.com/science/article/pii/S0022169498002327 http://www.idrologia.polito.it/~alviglio/TUWsite/1999\_Western\_JH.pdf},
volume = {217},
year = {1999}
}
@article{Gray2005,
abstract = {This is a thought piece on data-intensive science requirements for databases and science centers. It argues that peta-scale datasets will be housed by science centers that provide substantial storage and processing for scientists who access the data via smart notebooks. Next-generation science instruments and simulations will generate these peta-scale datasets. The need to publish and share data and the need for generic analysis and visualization tools will finally create a convergence on common metadata standards. Database systems will be judged by their support of these metadata standards and by their ability to manage and access peta-scale datasets. The procedural stream-of-bytes-file-centric approach to data analysis is both too cumbersome and too serial for such large datasets. Non-procedural query and analysis of schematized self-describing data is both easier to use and allows much more parallelism.},
author = {Gray, Jim and Liu, David T. and Nieto-Santisteban, Maria and Szalay, Alexander S. and DeWitt, David and Heber, Gerd},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/TPZ7ZCGG/Gray et al. - 2005 - Scientific Data Management in the Coming Decade.pdf:pdf},
journal = {arXiv:cs/0502008},
keywords = {Computer Science - Computational Engineering- Fina,Computer Science - Databases},
mendeley-tags = {Computer Science - Computational Engineering- Fina,Computer Science - Databases},
month = feb,
title = {{Scientific Data Management in the Coming Decade}},
url = {http://arxiv.org/abs/cs/0502008 http://www.arxiv.org/pdf/cs/0502008.pdf},
year = {2005}
}
@article{Downing-Kunz2013,
abstract = {Abstract
Quantifying sediment supply from estuarine tributaries is an important component of developing a sediment budget, and common techniques for estimating supply are based on gages located above tidal influence. However, tidal interactions near tributary mouths can affect the magnitude and direction of sediment supply to the open waters of the estuary. We investigated suspended-sediment dynamics in the tidal reach of Corte Madera Creek, an estuarine tributary of San Francisco Bay, using moored acoustic and optical instruments. Flux of both water and suspended-sediment were calculated from observed water velocity and turbidity for two periods in each of wet and dry seasons during 2010. During wet periods, net suspended-sediment flux was seaward; tidally filtered flux was dominated by the advective component. In contrast, during dry periods, net flux was landward; tidally filtered flux was dominated by the dispersive component. The mechanisms generating this landward flux varied; during summer we attributed wind–wave resuspension in the estuary and subsequent transport on flood tides, whereas during autumn we attributed increased spring tide flood velocity magnitude leading to local resuspension. A quadrant analysis similar to that employed in turbulence studies was developed to summarize flux time series by quantifying the relative importance of sediment transport events. These events are categorized by the direction of velocity (flood vs. ebb) and the magnitude of concentration relative to tidally averaged conditions (relatively turbid vs. relatively clear). During wet periods, suspended-sediment flux was greatest in magnitude during relatively turbid ebbs, whereas during dry periods it was greatest in magnitude during relatively turbid floods. A conceptual model was developed to generalize seasonal differences in suspended-sediment dynamics; model application to this study demonstrated the importance of few, relatively large events on net suspended-sediment flux. These results suggest that other estuarine tributaries may alternate seasonally as sediment sinks or sources, leading to the conclusion that calculations of estuary sediment supply from local tributaries that do not account for tidal reaches may be overestimates.},
author = {Downing-Kunz, Maureen A. and Schoellhamer, David H.},
doi = {10.1016/j.margeo.2013.03.005},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/DHA4ZNBJ/Downing-Kunz and Schoellhamer - 2013 - Seasonal variations in suspended-sediment dynamics.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/MMT9WC8G/Downing-Kunz and Schoellhamer - 2013 - Seasonal variations in suspended-sediment dynamics.html:html},
issn = {0025-3227},
journal = {Marine Geology},
keywords = {San Francisco Bay,estuarine tributary,seasonal variation,sediment flux,sediment transport,suspended sediment},
mendeley-tags = {San Francisco Bay,estuarine tributary,seasonal variation,sediment flux,sediment transport,suspended sediment},
month = nov,
pages = {314--326},
title = {{Seasonal variations in suspended-sediment dynamics in the tidal reach of an estuarine tributary}},
url = {http://www.sciencedirect.com/science/article/pii/S0025322713000352 http://www.sciencedirect.com/science/article/pii/S0025322713000352/pdfft?md5=a63b22aa709699dc1a14e57b70ae643b\&pid=1-s2.0-S0025322713000352-main.pdf},
volume = {345},
year = {2013}
}
@incollection{Scott2011,
abstract = {Paper is probably the most commonly recycled material in use today and has been reused in the papermaking process since the industrialization of the process in the early nineteen century. Although over 60\% of all paper produced in the United States is recovered, paper still makes up over 30\% of the municipal solid waste stream. Because of its high recovery rate, recovered paper is as important a raw material for papermaking as is chemically pulped virgin fiber. Recovered paper comes from a number of different sources, including postconsumer paper, which is recycled after it has served its useful purpose. Because of the wide variety of paper that is recovered, a number of organizations have standardized recovered paper grades in terms of the quality and cleanliness of the material. Paper recycling will continue long into the future as it is a key raw material in the papermaking process.
Recovered paper, or waste paper, can come from a number of different sources, including internally at the paper mill. A number of different terms are used to indicate when in the life cycle of the paper that it is returned for recycling. Recovered paper collection is done in a number of different ways, depending on the type of paper being collected and the source of the paper. In general, preconsumer recycled paper is easier to collect as it tends to be concentrated in specific manufacturing locations and also tends to be much more homogeneous. These collections, often of the form of cuttings, trimmings and over issues, are typically baled and packaged directly at the collection site with little additional processing needed. Paper recycling is a key raw material for the papermaking process, representing a significant portion of the fiber used. However, because of the degradation of the fibers through the papermaking and recycling process, the limit to the amount of paper being recycled is slowly being approached. In addition, there are a number of grades of paper that are currently not recycled and will not be in the foreseeable future. This is particularly true for such personal care products such as toweling and tissue. Future improvements in recycling will need to deal mainly with the fiber quality issues.},
address = {Boston},
author = {Scott, Gary M.},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/KKNWI8RR/Scott - 2011 - Chapter 10 - Recovered Paper.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {137--149},
publisher = {Academic Press},
title = {{Chapter 10 - Recovered Paper}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100105 http://www.sciencedirect.com/science/article/pii/B9780123814753100105/pdfft?md5=a8c60352d4af12a5f39feddb9e87c425\&pid=3-s2.0-B9780123814753100105-main.pdf},
year = {2011}
}
@incollection{Blight2011,
abstract = {The type and quantity of refuse generated by a community depends on its culture and the per capita income. Wealthy communities form throw away societies, whereas poor communities have less to throw away and are more ingenious in reusing, recycling and refurbishing articles that a wealthier community would discard. The simple but inadequate waste dumps of yesterday are still among people in most of the developing world, whereas the developed world is using the vastly improved sanitary landfill of today while planning and experimenting with and tentatively applying the still more improved landfill technology of tomorrow. The generation rate of municipal solid waste (MSW) is an important consideration in the selection of a suitably large disposal site and in the design of landfills, whether the economy is developed, developing or mixed. The sanitary landfill and the MSW of the future should have much reduced organic contents, and landfills should therefore generate less landfill gas (LFG) and (possibly) a less polluting leachate. Unfortunately, some residues will always remain, (e.g. the ash from RDF fuelled power stations) and hence the landfill will probably always remain. It is a challenge to the citizens to make the landfills of tomorrow much better, safer and less polluting than those of today.},
address = {Boston},
author = {Blight, Geoffrey},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
isbn = {978-0-12-381475-3},
pages = {469--485},
publisher = {Academic Press},
title = {{Chapter 30 - Landfills – Yesterday, Today and Tomorrow}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100300 http://www.sciencedirect.com/science/article/pii/B9780123814753100300/pdfft?md5=b1a33eaa068c12b8143152d118931be1\&pid=3-s2.0-B9780123814753100300-main.pdf},
year = {2011}
}
@article{Beven2002b,
author = {Beven, Keith J.},
doi = {10.1098/rspa.2002.0986},
issn = {1364-5021},
journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
month = oct,
number = {2026},
pages = {2465--2484},
title = {{Towards a coherent philosophy for modelling the environment}},
url = {http://rspa.royalsocietypublishing.org/cgi/doi/10.1098/rspa.2002.0986},
volume = {458},
year = {2002}
}
@article{Forster2000a,
abstract = {What is model selection? What are the goals of model selection? What are the methods of model selection and how do they work? Which methods perform better than others and in what circumstances? These questions rest on a number of key concepts in a relatively underdeveloped field. The aim of this paper is to explain some background concepts, to highlight some of the results in this special issue, and to add my own. The standard methods of model selection include classical hypothesis testing, maximum likelihood, Bayes method, minimum description length, cross-validation, and Akaike's information criterion. They all provide an implementation of Occam's razor, in which parsimony or simplicity is balanced against goodness-of-fit. These methods primarily take account of the sampling errors in parameter estimation, although their relative success at this task depends on the circumstances. However, the aim of model selection should also include the ability of a model to generalize to predictions in a different domain. Errors of extrapolation, or generalization, are different from errors of parameter estimation. So, it seems that simplicity and parsimony may be an additional factor in managing these errors, in which case the standard methods of model selection are incomplete implementations of Occam's razor. Copyright 2000 Academic Press.},
author = {Forster, Mr},
doi = {10.1006/jmps.1999.1284},
issn = {0022-2496},
journal = {Journal of mathematical psychology},
month = mar,
number = {1},
pages = {205--231},
pmid = {10733865},
title = {{Key Concepts in Model Selection: Performance and Generalizability.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10733865},
volume = {44},
year = {2000}
}
@article{Guzman2014,
abstract = {The analysis of the diffusion of radioisotopes in stagnant water in saturated porous media is important to validate the performance of barrier systems used in radioactive repositories. In this work a methodology is developed to determine the radioisotope concentration in a two-reservoir configuration: a saturated porous medium with stagnant water is surrounded by two reservoirs. The concentrations are obtained for all the radioisotopes of the decay chain using the concept of overvalued concentration. A methodology, based on the variable separation method, is proposed for the solution of the transport equation. The novelty of the proposed methodology involves the factorization of the overvalued concentration in two factors: one that describes the diffusion without decay and another one that describes the decay without diffusion. It is possible with the proposed methodology to determine the required time to obtain equal injective and diffusive concentrations in reservoirs. In fact, this time is inversely proportional to the diffusion coefficient. In addition, the proposed methodology allows finding the required time to get a linear and constant space distribution of the concentration in porous mediums. This time is inversely proportional to the diffusion coefficient. In order to validate the proposed methodology, the distributions in the radioisotope concentrations are compared with other experimental and numerical works.},
author = {Guzm\'{a}n, Juan and Alvarez-Ramirez, Jose and Escarela-P\'{e}rez, Rafael and Vargas, Ra\'{u}l Alejandro},
doi = {10.1016/j.jenvrad.2014.03.015},
issn = {0265-931X},
journal = {Journal of Environmental Radioactivity},
keywords = {Decay,Diffusion,Dispersion,Medium,Porous,Radioisotope},
mendeley-tags = {Decay,Diffusion,Dispersion,Medium,Porous,Radioisotope},
month = sep,
pages = {100--107},
title = {{Diffusion and decay chain of radioisotopes in stagnant water in saturated porous media}},
url = {http://www.sciencedirect.com/science/article/pii/S0265931X14001003 http://www.sciencedirect.com/science/article/pii/S0265931X14001003/pdfft?md5=b526f9a2fe392234e6072e41a00338e0\&pid=1-s2.0-S0265931X14001003-main.pdf},
volume = {135},
year = {2014}
}
@article{Klammler,
abstract = {The problem of permeable reactive barrier (PRB) capture and release behavior is investigated by means of an approximate analytical approach exploring the invariance of steady-state solutions of the advection-dispersion equation to conformal mapping. PRB configurations considered are doubly-symmetric funnel-and-gate as well as less frequent drain-and-gate systems. The effect of aquifer heterogeneity on contaminant plume spreading is hereby incorporated through an effective transverse macro-dispersion coefficient, which has to be known. Results are normalized and graphically represented in terms of a relative capture efficiency M of contaminant mass or groundwater passing a control plane (transect) at a sufficient distance up-stream of a PRB as to comply with underlying assumptions. Factors of safety FS are given as the ratios of required capture width under advective-dispersive and purely advective transport for achieving equal capture efficiency M. It is found that M also applies to the release behavior down-stream of a PRB, i.e., it describes the spreading and dilution of PRB treated groundwater possibly containing incompletely remediated contamination and/or remediation reaction products. Hypothetical examples are given to demonstrate results.},
author = {Klammler, Harald and Hatfield, Kirk and Mohamed, Mohamed M. and Perminova, Irina V. and Perlmutter, Mike},
doi = {10.1016/j.advwatres.2014.03.010},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/7MK4EHQ3/Klammler et al. - Capture and release zones of permeable reactive ba.pdf:pdf},
issn = {0309-1708},
journal = {Advances in Water Resources},
keywords = {Capture efficiency,Conformal mapping,Factor of safety,PRB,Plume,Remediation,Schwarz-Christoffel,contaminant},
mendeley-tags = {Capture efficiency,Conformal mapping,Factor of safety,PRB,Plume,Remediation,Schwarz-Christoffel,contaminant},
title = {{Capture and release zones of permeable reactive barriers under the influence of advective-dispersive transport in the aquifer}},
url = {http://www.sciencedirect.com/science/article/pii/S030917081400061X http://www.sciencedirect.com/science/article/pii/S030917081400061X/pdfft?md5=eda3dabca97c136d3523c59a47460152\&pid=1-s2.0-S030917081400061X-main.pdf}
}
@article{Merz2003,
author = {Merz, Ralf and Bl\"{o}schl, G\"{u}nter},
journal = {Water Resources Research},
number = {12},
pages = {1340},
title = {{A process typology of regional floods}},
url = {http://www.agu.org/pubs/crossref/2003/2002WR001952.shtml},
volume = {39},
year = {2003}
}
@article{Deng,
abstract = {Solute transport in multi-layered porous media is of great importance in environmental engineering problems. Its important feature lies in the explicit existence of interface conditions. The previous analytical solutions require explicitly considering the interface conditions in the evaluation of coefficients or in the eigenvalue system. In the present study, an implicit treatment of interface conditions is presented to eliminate the interface conditions from the original system. The generalized integral transform technique is performed with respect to the transformed system to obtain the analytical solution. Compared to the pervious solution strategy, the present eigenfunctions are much simpler. The present analytical solution and eigenvalue system are expressed for the generalized boundary conditions by introducing two boundary factors in the boundary conditions, which applies to arbitrary assembly of boundary conditions without modification and can reduce the effort of programming. The developed analytical solution is validated against two experiments and one analytical solution. Good agreement is shown between the experimental data and analytical as well as numerical solutions.},
author = {Deng, Baoqing and Li, Jiajia and Zhang, Bing and Li, Ninan},
doi = {10.1016/j.jhydrol.2014.05.072},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/H9WZVK2U/Deng et al. - Integral Transform solution for solute transport i.pdf:pdf},
issn = {0022-1694},
journal = {Journal of Hydrology},
keywords = {Exact solution,GITT,Interface condition,Multi-layered media},
mendeley-tags = {Exact solution,GITT,Interface condition,Multi-layered media},
title = {{Integral Transform solution for solute transport in multi-layered porous media with the implicit treatment of the interface conditions and arbitrary boundary conditions}},
url = {http://www.sciencedirect.com/science/article/pii/S0022169414004570 http://www.sciencedirect.com/science/article/pii/S0022169414004570/pdfft?md5=c03b08aad92c5f8077719d63ab826e6c\&pid=1-s2.0-S0022169414004570-main.pdf}
}
@article{Meixner2002,
author = {Meixner, Thomas},
doi = {10.2136/vzj2002.0202},
issn = {1539-1663},
journal = {Vadose Zone Journal},
number = {1},
pages = {202},
title = {{Spatial Patterns in Catchment Hydrology}},
url = {https://www.soils.org/publications/vzj/abstracts/1/1/202},
volume = {1},
year = {2002}
}
@article{Grayson2002,
author = {Grayson, Rodger B. and Bl\"{o}schl, G\"{u}nter and Western, Andrew W. and McMahon, Thomas A.},
journal = {Advances in Water Resources},
number = {8},
pages = {1313--1334},
title = {{Advances in the use of observed spatial patterns of catchment hydrological response}},
url = {http://www.sciencedirect.com/science/article/pii/S030917080200060X http://www.idrologia.polito.it/~alviglio/TUWsite/2002\_Grayson\_AWR.pdf},
volume = {25},
year = {2002}
}
@article{Western2001,
author = {Western, Andrew W. and Bl\"{o}schl, G\"{u}nter and Grayson, Rodger B.},
doi = {10.1029/2000WR900241},
issn = {0043-1397},
journal = {Water Resources Research},
number = {1},
pages = {83},
title = {{Toward capturing hydrologically significant connectivity in spatial patterns}},
url = {http://www.agu.org/pubs/crossref/2001/2000WR900241.shtml},
volume = {37},
year = {2001}
}
@book{Gleick1993,
abstract = {Among the most compelling environmental issues of today and tomorrow are those concerning the world's fresh water resources. Peter H. Gleick's important new volume, Water in Crisis, addresses the timely and sometimes controversial aspects of world water use. At stake are water quality, quantity, and possible future conflicts over shared international water resources. Nine essays by leading specialists from fields as diverse as hydrology, zoology, and law, among others, cover such issues as the status of developments in international water law; hydroelectric power; the possible effects of climatic change on water resources; and the state of fresh water fisheries. Particular chapters explore access to clean drinking water and sanitation; the use of water for energy and food production; the quality of rivers, lakes, and inland seas; and the condition of natural aquatic ecosystems. A joint project of the Pacific Institute and the Stockholm Environment Institute, this book is a comprehensive guide to the world's fresh water resources. Hydrologists, engineers, policy makers, professionals in the environmental sciences, as well as lay readers will find Water in Crisis a dynamic resource and information-packed reference. More than 200 tables of fresh water data supplement this important volume.},
author = {Gleick, Peter H. and {Pacific Institute for Studies in Development Environment and Security} and Institute, Stockholm Environment},
isbn = {9780195076288},
keywords = {Science / Earth Sciences / Hydrology,Science / Environmental Science},
language = {en},
mendeley-tags = {Science / Earth Sciences / Hydrology,Science / Environmental Science},
pages = {508},
publisher = {Oxford University Press},
shorttitle = {Water in Crisis},
title = {{Water in Crisis: A Guide to the World's Fresh Water Resources}},
url = {http://books.google.com/books?id=NigDkxQOkSAC},
year = {1993}
}
@article{Menn1981,
abstract = {Most chemical pesticides in use today were discovered along conventional lines of research, primarily via empirical synthesis and screening followed by structure-activity relation optimization. The very rapid rise in the cost of research, the decreasing success rate for a commercial pesticide from this approach, and the ever-increasing regulatory requirements for registration suggest that greater emphasis should be placed on more rational methods for discovering new chemical pesticides. Rational leads can be discovered from several research approaches, including the synthetic modifications of natural product models, the development of metabolic disrupters or enhancers of some process in the target pests, and the development of innovative effective bioassays to discover subtle agents such as behaviour modifiers and chitin synthesis blockers. In our research programmes, we have extensively investigated juvenile hormone agonists and antagonists. These two areas probably best exemplify the biorational aspects of the discovery of highly selective insecticidal agents. One of our current goals is to develop chemical antagonists of juvenile hormone in lepidopterous larvae, which will result in biochemical and/or morphogenetic disturbances in the insect similar to those elicited by surgical removal of the corpora allata.},
author = {Menn, J. J. and Henrick, C. A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/K6WSFZR8/Menn and Henrick - 1981 - Rational and Biorational Design of Pesticides.pdf:pdf},
issn = {0080-4622},
journal = {Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences},
keywords = {Folder - ch1},
mendeley-tags = {Folder - ch1},
month = sep,
number = {1076},
pages = {57--71},
title = {{Rational and Biorational Design of Pesticides}},
url = {http://www.jstor.org/stable/2395578 http://www.jstor.org/stable/pdfplus/2395578.pdf?acceptTC=true},
volume = {295},
year = {1981}
}
@article{Smith2003,
author = {Smith, Richard L. and Kolenikov, Stanislav and Cox, Lawrence H.},
doi = {10.1029/2002JD002914},
issn = {01480227},
journal = {Journal of Geophysical Research: Atmospheres},
month = dec,
number = {D24},
pages = {n/a--n/a},
shorttitle = {Spatiotemporal modeling of PM <sub>2.5</sub> data },
title = {{Spatiotemporal modeling of PM <sub>2.5</sub> data with missing values: MODELING OF PM <sub>2.5</sub> DATA WITH MISSING VALUES}},
url = {http://www.unc.edu/~rls/s890/s890.html},
volume = {108},
year = {2003}
}
@article{Bloschl2009,
author = {Bl\"{o}schl, G\"{u}nter and Montanari, Alberto},
journal = {Hydrological Processes},
number = {3},
pages = {374--381},
title = {{Climate change impacts—Throwing the dice?}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/hyp.7574/abstract http://www.waterresources.at/DK/fileadmin/publications/bloeschl/2010\_Bloeschl\_HP.pdf},
volume = {24},
year = {2009}
}
@article{Schoups2008,
abstract = {A common concern in hydrologic modeling is overparameterization of complex models given limited and noisy data. This leads to problems of parameter nonuniqueness and equifinality, which may negatively affect prediction uncertainties. A systematic way of controlling model complexity is therefore needed. We compare three model complexity control methods for hydrologic prediction, namely, cross validation (CV), Akaike's information criterion (AIC), and structural risk minimization (SRM). Results show that simulation of water flow using non-physically-based models (polynomials in this case) leads to increasingly better calibration fits as the model complexity (polynomial order) increases. However, prediction uncertainty worsens for complex non-physically-based models because of overfitting of noisy data. Incorporation of physically based constraints into the model (e.g., storage-discharge relationship) effectively bounds prediction uncertainty, even as the number of parameters increases. The conclusion is that overparameterization and equifinality do not lead to a continued increase in prediction uncertainty, as long as models are constrained by such physical principles. Complexity control of hydrologic models reduces parameter equifinality and identifies the simplest model that adequately explains the data, thereby providing a means of hydrologic generalization and classification. SRM is a promising technique for this purpose, as it (1) provides analytic upper bounds on prediction uncertainty, hence avoiding the computational burden of CV, and (2) extends the applicability of classic methods such as AIC to finite data. The main hurdle in applying SRM is the need for an a priori estimation of the complexity of the hydrologic model, as measured by its Vapnik-Chernovenkis (VC) dimension. Further research is needed in this area.},
author = {Schoups, G. and van de Giesen, N. C. and Savenije, H. H. G.},
doi = {10.1029/2008WR006836},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/55XW4P8M/Schoups et al. - 2008 - Model complexity control for hydrologic prediction.pdf:pdf},
issn = {1944-7973},
journal = {Water Resources Research},
keywords = {1846 Model calibration,1847 Modeling,1873 Uncertainty assessment,model calibration,parameter equifinality,prediction uncertainty},
language = {en},
mendeley-tags = {1846 Model calibration,1847 Modeling,1873 Uncertainty assessment,model calibration,parameter equifinality,prediction uncertainty},
month = dec,
number = {12},
pages = {W00B03},
title = {{Model complexity control for hydrologic prediction}},
url = {http://onlinelibrary.wiley.com/doi/10.1029/2008WR006836/abstract http://onlinelibrary.wiley.com/store/10.1029/2008WR006836/asset/wrcr11722.pdf?v=1\&t=hv1cizuo\&s=476e03069fd27a7b6036e1472cf83e01b24c4660},
volume = {44},
year = {2008}
}
@incollection{Simeonov2009,
abstract = {Environmental epidemiology studies are important tools in chemical risk assessment. There is a need for well-designed epidemiological large-scale study at international basis. The purpose of the risk characterization is to determine the need for action to aid regulatory agencies in risk management (justification for regulatory measure, acceptance of negligible risk, acceptable risk), as well as to inform the population for self-protection. The importance of epidemiological studies for risk characterization to prenatal exposure is important step in the hazard characterisation. Evaluation of health risk and offspring development has priority in the process of environmental chemical pollution risk assessment.},
author = {Simeonov, Lubomir},
editor = {Simeonov, Lubomir I. and Hassanien, Mahmoud A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/DDWAPWPK/Simeonov - 2009 - Environmental Epidemiology as a Method for Risk As.pdf:pdf},
isbn = {978-90-481-2334-6, 978-90-481-2335-3},
keywords = {Analytical Chemistry,Pesticides,Soil Science \& Conservation,Terrestrial Pollution,air,chemical exposure,environment,epidemiological studies,metals,soil,water},
mendeley-tags = {Analytical Chemistry,Pesticides,Soil Science \& Conservation,Terrestrial Pollution,air,chemical exposure,environment,epidemiological studies,metals,soil,water},
month = jan,
pages = {227--232},
publisher = {Springer Netherlands},
series = {NATO Science for Peace and Security Series C: Environmental Security},
title = {{Environmental Epidemiology as a Method for Risk Assessment of Chemical Pollution}},
url = {http://link.springer.com/chapter/10.1007/978-90-481-2335-3\_15 http://link.springer.com/content/pdf/10.1007\%2F978-90-481-2335-3\_15.pdf},
year = {2009}
}
@article{VanGenuchten1985,
abstract = {Problems of solute transport involving sequential first-order decay reactions frequently occur in soil systems. Examples are the migration of radionuclides, in which the chain members form a first-order decay reaction, and the simultaneous movement of various interacting nitrogen species. This study presents analytical solutions that describe the simultaneous convective-dispersive transport of up to four species involved in such a consecutive chain reaction. Evaluation of the analytical solutions is not straightforward but requires, among other things, the calculation of complex complementary error functions. A FORTRAN IV computer program (CHAIN) that can be used to evaluate the analytical solutions is described. Application of this program to problems of solute transport is illustrated with two examples, one dealing with radionuclide transport and one with nitrification.},
author = {{Van Genuchten}, M.Th.},
doi = {10.1016/0098-3004(85)90003-2},
issn = {0098-3004},
journal = {Computers \& Geosciences},
keywords = {Convective-dispersive solute transport,First-order decay reactions,Nitrogen transport,Radionuclide transport,Transport modeling},
mendeley-tags = {Convective-dispersive solute transport,First-order decay reactions,Nitrogen transport,Radionuclide transport,Transport modeling},
number = {2},
pages = {129--147},
title = {{Convective-dispersive transport of solutes involved in sequential first-order decay reactions}},
url = {http://www.sciencedirect.com/science/article/pii/0098300485900032 http://pdn.sciencedirect.com/science?\_ob=MiamiImageURL\&\_cid=271720\&\_user=4420\&\_pii=0098300485900032\&\_check=y\&\_origin=article\&\_zone=toolbar\&\_coverDate=31-Dec-1985\&view=c\&originContentFamily=serial\&wchp=dGLbVBA-zSkzV\&md5=dfb702c1225b58003add386f99ae8cf2\&pid=1-s2.0-0098300485900032-main.pdf},
volume = {11},
year = {1985}
}
@incollection{Letcher2011,
address = {Boston},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/GMGPCCX7/Letcher and Vallero - 2011 - Prologue.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {xiv--xvi},
publisher = {Academic Press},
title = {{Prologue}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100361 http://www.sciencedirect.com/science/article/pii/B9780123814753100361/pdfft?md5=becf2679b41d1229fe36f238af6f80a0\&pid=3-s2.0-B9780123814753100361-main.pdf},
year = {2011}
}
@article{McCallum2014,
abstract = {Residence time distributions (RTDs) have been used extensively for quantifying flow and transport in subsurface hydrology. In geochemical approaches, environmental tracer concentrations are used in conjunction with simple lumped parameter models (LPMs). Conversely, numerical simulation techniques require large amounts of parameterization and estimated RTDs are certainly limited by associated uncertainties. In this study, we apply a nonparametric deconvolution approach to estimate RTDs using environmental tracer concentrations. The model is based only on the assumption that flow is steady enough that the observed concentrations are well approximated by linear superposition of the input concentrations with the RTD; that is, the convolution integral holds. Even with large amounts of environmental tracer concentration data, the entire shape of an RTD remains highly nonunique. However, accurate estimates of mean ages and in some cases prediction of young portions of the RTD may be possible. The most useful type of data was found to be the use of a time series of tritium. This was due to the sharp variations in atmospheric concentrations and a short half-life. Conversely, the use of CFC compounds with smoothly varying atmospheric concentrations was more prone to nonuniqueness. This work highlights the benefits and limitations of using environmental tracer data to estimate whole RTDs with either LPMs or through numerical simulation. However, the ability of the nonparametric approach developed here to correct for mixing biases in mean ages appears promising.},
author = {McCallum, James L. and Engdahl, Nicholas B. and Ginn, Timothy R. and Cook, Peter. G.},
doi = {10.1002/2013WR014974},
issn = {1944-7973},
journal = {Water Resources Research},
keywords = {1009 Geochemical modeling,1829 Groundwater hydrology,1832 Groundwater transport,environmental tracers,residence time distributions},
language = {en},
mendeley-tags = {1009 Geochemical modeling,1829 Groundwater hydrology,1832 Groundwater transport,environmental tracers,residence time distributions},
month = mar,
number = {3},
pages = {2022--2038},
shorttitle = {Nonparametric estimation of groundwater residence },
title = {{Nonparametric estimation of groundwater residence time distributions: What can environmental tracer data tell us about groundwater residence time?}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/2013WR014974/abstract},
volume = {50},
year = {2014}
}
@incollection{Bartl2011,
abstract = {The use of fibers and fiber containing goods is widespread. The main end-applications comprise apparel as well as home furnishing. Because fibers can be found in a great variety of products, it is to be expected that fibers end up in diverse waste streams. Waste is increasingly being seen as (secondary) raw material, and zero waste represents the current ideal in waste management. Fibers and fiber containing products have followed the same trend towards sustainability. Because fiber production and textile processing are sophisticated and demands large amounts of energy, reuse and recycling are highly recommended, not only for ecological reasons but also for economic reasons. Unfortunately, because fiber reprocessing is difficult and complex, a large portion of fibrous waste still ends up in landfill sites or, largely based on legislative forces, in waste incinerators. A variety of methods do exist for treating waste and end-of-life textiles. Legislation plays an important role in the treatment of waste. From an economical point of view, textile waste exhibits an exceptional position. Zero waste is an extensively used keyword today. It refers to the reuse and recycling of waste and the avoidance of landfilling and combustion. Finally, environmental and ethical attitudes can significantly influence waste treatment.},
address = {Boston},
author = {Bartl, Andreas},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/2M5QV3HS/Bartl - 2011 - Chapter 12 - Textile Waste.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {167--179},
publisher = {Academic Press},
title = {{Chapter 12 - Textile Waste}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100129 http://www.sciencedirect.com/science/article/pii/B9780123814753100129/pdfft?md5=2219f32ab031c944b400e565b17d8d21\&pid=3-s2.0-B9780123814753100129-main.pdf},
year = {2011}
}
@article{Steinhauser2014,
abstract = {In environmental monitoring campaigns for anthropogenic radionuclides released in the course of the Fukushima nuclear accident (2011), most focus had been on gamma-emitting radionuclides. More than 99\% of the released activity was due to radionuclides of the elements Kr, Te, I, Xe and Cs. However, little work had been done on the monitoring of radionuclides other than 131I, 132Te, 134Cs, 136Cs and 137Cs. Radionuclides such as those of less volatile elements (e.g. 89Sr, 90Sr, 103Ru, 106Ru, plutonium), pure beta-emitters (3H, 14C, 35S), gaseous radionuclides (85Kr, 133Xe, 135Xe) or radionuclides with very long half-lives (e.g. 36Cl, 99Tc, 129I, some actinides such as 236U) have been understudied by comparison. In this review, we summarize previous monitoring work on these ?orphan? radionuclides in various environmental media and outline further challenges for future monitoring campaigns. Some of the understudied radionuclides are of radiological concern, others are promising tracers for environmental, geochemical processes such as oceanic mixing. Unfortunately, the shorter-lived nuclides of radioxenon, 103Ru, 89Sr and 35S will no longer exhibit detectable activities in the environment. Activity concentrations of other radionuclides such as tritium, 14C, or 85Kr will become blurred in the significant background of previous releases (nuclear explosions and previous accidents). Isotope ratios such as 240Pu/239Pu will allow for the identification of Fukushima plutonium despite the plutonium background.},
author = {Steinhauser, Georg},
doi = {10.1021/es405654c},
issn = {0013-936X},
journal = {Environmental Science \& Technology},
month = apr,
shorttitle = {Fukushima’s Forgotten Radionuclides},
title = {{Fukushima’s Forgotten Radionuclides: A Review of the Understudied Radioactive Emissions}},
url = {http://dx.doi.org/10.1021/es405654c http://pubs.acs.org/doi/pdfplus/10.1021/es405654c},
year = {2014}
}
@article{Cutting2000,
abstract = {Traditionally, models are compared on the basis of their accuracy, their scope, and their simplicity. Simplicity is often represented by parameter counts; the fewer the parameters, the simpler the model. Arguments are presented here suggesting that simplicity has little place in discussions of modeling; instead, the concept of flexibility should be substituted. When comparing two models one should be wary of the possibility of their differential flexibility. Several methods for assessing relative flexibility are possible, as represented in this special issue of the Journal of Mathematical Psychology. Here, the method of cross-validation is applied in the comparison of two models, a linear integration model (LIM) and the fuzzy-logical model of perception (FLMP), in the fitting of 44 data sets concerning the perception of layout seen among three panels with the presence or absence of four sources of information for depth. Prior to cross-validation the two models performed about equally well; after cross-validation LIM was statistically superior to FLMP, but the overall pattern of fits remained nearly the same for both models. Copyright 2000 Academic Press.},
author = {Cutting, Je},
doi = {10.1006/jmps.1999.1274},
issn = {0022-2496},
journal = {Journal of mathematical psychology},
month = mar,
number = {1},
pages = {3--19},
pmid = {10733855},
title = {{Accuracy, Scope, and Flexibility of Models.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10733855},
volume = {44},
year = {2000}
}
@incollection{EWesBethel2009,
annote = {doi:10.1201/9781420069815-c9},
author = {{EWes Bethel} and Prabhat and {Hank Childs} and {Ajith Mascarenhas} and {Valerio Pascucci}},
booktitle = {Scien},
isbn = {978-1-4200-6980-8},
month = dec,
publisher = {Chapman and Hall/CRC},
series = {Chapman \& Hall/CRC Computational Science},
title = {{Scientific Data Management Challenges in High-Performance Visual Data Analysis}},
url = {http://dx.doi.org/10.1201/9781420069815-c9},
year = {2009}
}
@article{Huang,
abstract = {Despite the long standing interest in modeling the fate and environmental impacts of radionuclides, simulations addressing the fate and transport of rare earth elements (REEs) and thorium (Th) have received comparably little attention. This study presents an architecture that enables reactive transport modeling and parameter sensitivity analysis on cloud computing platforms. We adapted an existing groundwater modeling framework to perform some of the computationally most expensive steps within a cloud environment based on Microsoft Windows Azure. The cloud computing architecture was evaluated and validated through the development of a schematic, cross sectional model along a transect across a tailings impoundment at a REEs mine tailing site in northwest China. The model framework employs a suite of flow, solute transport and reactive transport simulation tools, i.e., MODFLOW, MT3DMS, and PHT3D. On the basis of our model simulations, the collection-trench for the impoundment constructed above the ground surface appears to collect a substantial portion of the leachate fluxes, but the reminder will bypass the trench and migrate downstream. Those bypassed leachate fluxes will subsequently interact with downstream fluviolacustrine aquifers and eventually discharge into the Yellow River south of the study site under the idealized simulation environment. Further investigations of the hydraulic parameters of the aquifer system and the impoundment dam, and other geochemical characteristics are needed to elucidate the fate and transport of thorium and improve the reliability of the numerical model. Although the discussion and analysis of this study is tailored to thorium reactive transport modeling of a REEs tailings impoundment, such a framework can also be applied to deploy different types of scientific modeling applications on Azure Cloud.},
author = {Huang, Xiang and Cao, Guoliang and Liu, Jie and Prommer, Henning and Zheng, Chunmiao},
doi = {10.1016/j.gexplo.2014.03.006},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/SP3BTPP7/Huang et al. - Reactive Transport Modeling of Thorium in a Cloud .pdf:pdf},
issn = {0375-6742},
journal = {Journal of Geochemical Exploration},
keywords = {Baotou,Bayan Obo,Cloud Computing,Reactive Transport Modeling,Tailings Impoundment,Thorium,Yellow River},
mendeley-tags = {Baotou,Bayan Obo,Cloud Computing,Reactive Transport Modeling,Tailings Impoundment,Thorium,Yellow River},
title = {{Reactive Transport Modeling of Thorium in a Cloud Computing Environment}},
url = {http://www.sciencedirect.com/science/article/pii/S0375674214001009 http://www.sciencedirect.com/science/article/pii/S0375674214001009/pdfft?md5=2c0d21b36f92a6e3427f0539051253ba\&pid=1-s2.0-S0375674214001009-main.pdf}
}
@article{Loague1990a,
author = {Loague, Keith},
doi = {10.1016/0022-1694(90)90161-P},
issn = {0022-1694},
journal = {Journal of Hydrology},
month = dec,
number = {1–4},
pages = {405--407},
title = {{Changing ideas in hydrology — The case of physically based models — Comment}},
url = {http://www.sciencedirect.com/science/article/pii/002216949090161P http://pdn.sciencedirect.com/science?\_ob=MiamiImageURL\&\_cid=271842\&\_user=4420\&\_pii=002216949090161P\&\_check=y\&\_origin=article\&\_zone=toolbar\&\_coverDate=1990--01\&view=c\&originContentFamily=serial\&wchp=dGLbVlt-zSkWb\&md5=90fe1cf2328e69b633400038e54f2e58\&pid=1-s2.0-002216949090161P-main.pdf},
volume = {120},
year = {1990}
}
@article{Enzenhoefer2014,
abstract = {Wellhead-protection zones are commonly delineated on the basis of advective travel-time analysis without considering any aspects of model uncertainty. In the past decade, research efforts have produced quantifiable risk-based safety margins for protection zones. These margins are based on well-vulnerability criteria (e.g., travel times, exposure times, peak concentrations) and take model and parameter uncertainty into account. There are three main reasons why practitioners still refrain from applying these new techniques. (1) They fear the additional areal demand of probabilistic safety margins; (2) probabilistic approaches are allegedly complex, not readily available and require huge computing resources, and (3) uncertainty bounds are fuzzy, whereas final decisions are binary. The primary goal of this paper is to show that these reservations are unjustified. We present a straightforward, computationally affordable framework that offers risk-informed decision support for robust and transparent wellhead delineation under uncertainty. We show that reliability levels can be increased by exchanging delineated low-risk areas for previously nondelineated high-risk areas. We also show that further improvements may often be available with only little additional delineated area. As proof of our concept, we illustrate our key points with the example of a pumped karstic well catchment, located in Germany.},
author = {Enzenhoefer, R. and Bunk, T. and Nowak, W.},
doi = {10.1111/gwat.12161},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/6IK8DR7Q/abstract.html:html},
issn = {1745-6584},
journal = {Groundwater},
language = {en},
pages = {n/a--n/a},
shorttitle = {Nine Steps to Risk-Informed Wellhead Protection an},
title = {{Nine Steps to Risk-Informed Wellhead Protection and Management: A Case Study}},
url = {http://onlinelibrary.wiley.com/doi/10.1111/gwat.12161/abstract http://onlinelibrary.wiley.com/doi/10.1111/gwat.12161/abstract?deniedAccessCustomisedMessage=\&userIsAuthenticated=false},
year = {2014}
}
@article{Gupta2009a,
author = {Gupta, Hoshin V. and Kling, Harald and Yilmaz, Koray K. and Martinez, Guillermo F.},
doi = {10.1016/j.jhydrol.2009.08.003},
issn = {00221694},
journal = {Journal of Hydrology},
keywords = {Criteria decomposition,Mean squared error,Model performance evaluation,Multiple criteria,Nash–Sutcliffe efficiency,calibration},
mendeley-tags = {Criteria decomposition,Mean squared error,Model performance evaluation,Multiple criteria,Nash–Sutcliffe efficiency,calibration},
month = oct,
number = {1-2},
pages = {80--91},
shorttitle = {Decomposition of the mean squared error and NSE pe},
title = {{Decomposition of the mean squared error and NSE performance criteria: Implications for improving hydrological modelling}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0022169409004843 http://pdn.sciencedirect.com/science?\_ob=MiamiImageURL\&\_cid=271842\&\_user=4420\&\_pii=S0022169409004843\&\_check=y\&\_origin=article\&\_zone=toolbar\&\_coverDate=2009--20\&view=c\&originContentFamily=serial\&wchp=dGLbVlS-zSkWb\&md5=b1684394c7b9a5ce557858e14e9b796c\&pid=1-s2.0-S0022169409004843-main.pdf http://www.sciencedirect.com/science/article/pii/S0022169409004843},
volume = {377},
year = {2009}
}
@article{Skaggs1994,
abstract = {Finding the history of a groundwater contaminant plume from measurements of its current spatial distribution is an ill-posed problem and, consequently, its solution is extremely sensitive to errors in the input data. In this paper, Tikhonov regularization (Tikhonov and Arsenin, 1977) is used in numerical experiments to recover the release history of a plume that has originated from a known, single site. The recovered release history is then used to reconstruct the plume evolution history. The method is found to be insensitive to round off errors, but its accuracy is affected by plume measurement errors, the extent to which the plume has dissipated, and, to a lesser degree, the accuracy of the transport parameter estimates. A regularization approach may be effective at finding a plume history when there are adequate data.},
author = {Skaggs, Todd H. and Kabala, Z. J.},
doi = {10.1029/93WR02656},
issn = {1944-7973},
journal = {Water Resources Research},
language = {en},
number = {1},
pages = {71--79},
title = {{Recovering the release history of a groundwater contaminant}},
url = {http://onlinelibrary.wiley.com/doi/10.1029/93WR02656/abstract http://onlinelibrary.wiley.com/store/10.1029/93WR02656/asset/wrcr6355.pdf?v=1\&t=hhjww3cf\&s=ad76aecaa7484075b454103252e3170510d8b40f},
volume = {30},
year = {1994}
}
@incollection{Letcher2011a,
address = {Boston},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/RDPG72W2/Letcher and Vallero - 2011 - Preface.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {vi--xiii},
publisher = {Academic Press},
title = {{Preface}},
url = {http://www.sciencedirect.com/science/article/pii/B978012381475310035X http://www.sciencedirect.com/science/article/pii/B978012381475310035X/pdfft?md5=9f03f410f053853a79dac07efddc3b91\&pid=3-s2.0-B978012381475310035X-main.pdf},
year = {2011}
}
@article{Bae2004,
author = {Bae, Ha-Rok and Grandhi, Ramana V. and Canfield, Robert A.},
journal = {Computers \& Structures},
number = {13},
pages = {1101--1112},
title = {{Epistemic uncertainty quantification techniques including evidence theory for large-scale structures}},
url = {http://www.sciencedirect.com/science/article/pii/S0045794904000860},
volume = {82},
year = {2004}
}
@article{McCabe1976,
abstract = {This paper describes a graph-theoretic complexity measure and illustrates how it can be used to manage and control program complexity. The paper first explains how the graph-theory concepts apply and gives an intuitive explanation of the graph concepts in programming terms. The control graphs of several actual Fortran programs are then presented to illustrate the correlation between intuitive complexity and the graph-theoretic complexity. Several properties of the graph-theoretic complexity are then proved which show, for example, that complexity is independent of physical size (adding or subtracting functional statements leaves complexity unchanged) and complexity depends only on the decision structure of a program.},
author = {McCabe, T.J.},
doi = {10.1109/TSE.1976.233837},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/ICGKD7V9/McCabe - 1976 - A Complexity Measure.pdf:pdf},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Basis,Fluid flow measurement,Linear programming,National security,Software engineering,Software maintenance,Software measurement,Software systems,Software testing,System testing,complexity measure,control flow,decomposition,graph theory,independence,linear,modularization,programming,reduction,software,testing},
mendeley-tags = {Basis,Fluid flow measurement,Linear programming,National security,Software engineering,Software maintenance,Software measurement,Software systems,Software testing,System testing,complexity measure,control flow,decomposition,graph theory,independence,linear,modularization,programming,reduction,software,testing},
month = dec,
number = {4},
pages = {308--320},
title = {{A Complexity Measure}},
url = {http://ieeexplore.ieee.org/ielx5/32/35895/01702388.pdf?tp=\&arnumber=1702388\&isnumber=35895},
volume = {SE-2},
year = {1976}
}
@incollection{Shannon2011,
abstract = {This chapter provides an overview of regulations and issues relating to the generation, storage, treatment, and disposal of regulated medical waste (RMW), generally referred to as healthcare waste (HCW) in the United States, the United Kingdom, in Europe, and elsewhere. It illustrates a comprehensive definition of what is generally considered to be RMW/HCW, to provide a brief history of the catalysts that prompted an international regulatory response to the potential hazards associated with this waste stream, and to discuss the development of regulations and rules relating to RMW/HCW. Currently established frameworks and standards relating to the characterization, packaging, treatment, and disposal of RMW/HCW from an international perspective demonstrate a range of disparities according to the cited literature, and they are generally dependent on several factors—existing socioeconomic issues and government provisions, the level and quality of education and resources provided to the public, the provision and use of appropriate treatment technologies for viable and effective disposition of this waste stream, and regulatory initiatives and enforcement provisions available to curtail the inappropriate handling, treatment, and disposal of items within this waste stream. Many industrialized nations have developed regulations that adequately and effectively provide safe and environmentally viable means for the treatment and disposal of RMW/HCW, but financial and regulatory burdens remain significant obstacles for nations lacking necessary resources.},
address = {Boston},
author = {Shannon, Andrew L. and Woolridge, Anne},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/EZI94KQG/Shannon and Woolridge - 2011 - Chapter 23 - Medical Waste.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {329--339},
publisher = {Academic Press},
title = {{Chapter 23 - Medical Waste}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100233 http://www.sciencedirect.com/science/article/pii/B9780123814753100233/pdfft?md5=3ddfb273a872d77b96cc80ca746c2c16\&pid=3-s2.0-B9780123814753100233-main.pdf},
year = {2011}
}
@incollection{ArieShoshani2009a,
annote = {doi:10.1201/9781420069815-c3},
author = {{Arie Shoshani} and {Flavia Donno} and {Junmin Gu} and {Jason Hick} and {Maarten Litmaath} and {Alex Sim}},
booktitle = {Scien},
isbn = {978-1-4200-6980-8},
month = dec,
publisher = {Chapman and Hall/CRC},
series = {Chapman \& Hall/CRC Computational Science},
title = {{Dynamic Storage Management}},
url = {http://dx.doi.org/10.1201/9781420069815-c3},
year = {2009}
}
@article{Lawless2014,
abstract = {Global agreement exists for the policy of the geological disposal of spent nuclear fuel and high-level radioactive wastes, provided that there is public consent. To gain consent, social scientists recommend the less competitive approach of consensus rather than the majority rule (MR) of democracies. But, we hypothesize, competition for public consent from MR best improves the quality and stability of choice.},
author = {Lawless, W.F. and Akiyoshi, Mito and Angjellari-Dajci, Fiorentina and Whitton, John},
doi = {10.1080/00207233.2014.881165},
issn = {0020-7233},
journal = {International Journal of Environmental Studies},
number = {1},
pages = {41--62},
title = {{Public consent for the geologic disposal of highly radioactive wastes and spent nuclear fuel}},
url = {http://www.tandfonline.com/doi/abs/10.1080/00207233.2014.881165},
volume = {71},
year = {2014}
}
@article{Yen1956a,
abstract = {The purpose of this investigation is to examine four special nonuniform sampling processes in detail, and to deduce some interesting properties of bandwidth-limited signals. The main results are contained in four generalized sampling theorems. These theorems not only contain the nature of determination (unique-specification, over-specification, and underspecification) of signals but also include explicit reconstruction formulas. From the reconstruction formulas, the complexity and accuracy of the nonuniform sampling processes discussed can be estimated. In addition, these theorems lead to observations regarding the allowable shapes, the "prediction," and the "energy" of bandwidth-limited signals in general. A "minimum-energy" signal is introduced which has certain advantages as compared to the ordinary "time-limited" signals when a finite number of sample values are given. Finally, a statement due to Cauchy on the sampling of bandwidth-limited signals is generalized to include a wider class of nonuniform sample point distributions and modified to give more exact information regarding the nature of determination of signals.},
author = {Yen, J.},
doi = {10.1109/TCT.1956.1086325},
issn = {0096-2007},
journal = {IRE Transactions on Circuit Theory},
keywords = {Bridges,Frequency conversion,Mathematics,Nonuniform sampling,Physics,Sampling methods,Signal sampling,Telegraphy,interpolation,signal processing},
mendeley-tags = {Bridges,Frequency conversion,Mathematics,Nonuniform sampling,Physics,Sampling methods,Signal sampling,Telegraphy,interpolation,signal processing},
number = {4},
pages = {251--257},
title = {{On Nonuniform Sampling of Bandwidth-Limited Signals}},
url = {http://ieeexplore.ieee.org/ielx5/8148/23600/01086325.pdf?tp=\&arnumber=1086325\&isnumber=23600 http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=1086325\&sortType=asc\_p\_Sequence\&filter=AND(p\_IS\_Number:23600)},
volume = {3},
year = {1956}
}
@article{Bedau2010,
author = {Bedau, Mark},
journal = {Principia: an international journal of epistemology},
number = {1},
pages = {5--50},
title = {{Downward causation and the autonomy of weak emergence}},
url = {http://150.162.1.115/index.php/principia/article/view/17003 http://150.162.1.115/index.php/principia/article/download/17003/15556},
volume = {6},
year = {2010}
}
@article{Szecsody,
abstract = {Pertechnetate was slowly reduced in a natural, untreated arid sediment under anaerobic conditions (0.02 nmol g−1 h−1), which could occur in low permeability zones in the field, most of which was quickly oxidized. A small portion of the surface Tc may be incorporated into slowly dissolving surface phases, so was not readily oxidized/remobilized into pore water. In contrast, pertechnetate reduction in an anaerobic sediment containing adsorbed ferrous iron as the reductant was rapid (15–600 nmol g−1 h−1), and nearly all (96–98\%) was rapidly oxidized/remobilized (2.6–6.8 nmol g−1 h−1) within hours. Tc reduction in an anaerobic sediment containing 0.5–10 mM sulfide showed a relatively slow reduction rate (0.01–0.03 nmol g−1 h−1) that was similar to observations in the natural sediment. Pertechnetate infiltration into sediment with a highly alkaline water resulted in rapid reduction (0.07–0.2 nmol g−1 h−1) from ferrous iron released during biotite or magnetite dissolution. Oxidation of NaOH-treated sediments resulted in slow Tc oxidation (∼0.05 nmol g−1 h−1) of a small fraction of the surface Tc (13–23\%). The Tc remaining on the surface was TcIV (by XANES), and autoradiography and elemental maps of Tc (by electron microprobe) showed Tc was present associated with specific minerals, rather than being evenly distributed on the surface. Dissolution of quartz, montmorillonite, muscovite, and kaolinite also occurred in the alkaline water, resulting in significant aqueous silica and aluminum. Over time, aluminosilicates, cancrinite, zeolite and sodalite were precipitating. These precipitates may be coating surface Tc(IV) phases, limiting reoxidation.},
author = {Szecsody, Jim E. and Jansik, Danielle P. and McKinley, James P. and Hess, Nancy J.},
doi = {10.1016/j.jenvrad.2014.02.003},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/PN462M2U/Szecsody et al. - Influence of alkaline co-contaminants on technetiu.pdf:pdf},
issn = {0265-931X},
journal = {Journal of Environmental Radioactivity},
keywords = {Alkaline dissolution/precipitation,Pertechnetate reduction,Subsurface contamination,Technetium},
mendeley-tags = {Alkaline dissolution/precipitation,Pertechnetate reduction,Subsurface contamination,Technetium},
title = {{Influence of alkaline co-contaminants on technetium mobility in vadose zone sediments}},
url = {http://www.sciencedirect.com/science/article/pii/S0265931X14000356 http://www.sciencedirect.com/science/article/pii/S0265931X14000356/pdfft?md5=a23bc8f72eec5dc654c141e06858c159\&pid=1-s2.0-S0265931X14000356-main.pdf}
}
@article{Hu2008,
abstract = {Many long-lived radionuclides are present in groundwater at the Nevada Test Site (NTS) as a result of 828 underground nuclear weapons tests conducted between 1951 and 1992. In conjunction with a comprehensive geochemical review of radionuclides (3H, 14C, 36Cl, 99Tc and 129I) that are presumably mobile in the subsurface, we synthesized a body of radionuclide activity data measured from groundwater samples collected at 18 monitoring wells, to qualitatively assess their migration at the NTS over distances of hundreds of meters and over timescales of decades. Tritium and 36Cl showed little evidence of retardation, while the transport of 14C may have been retarded by its isotopic exchange with carbonate minerals in the aquifer. Observed local reducing conditions (either natural or test-induced) will impact the mobility of certain redox-sensitive radionuclides (especially 99Tc) that were otherwise soluble and readily transported under oxidizing conditions. Conversely, strongly oxidizing conditions may impact the mobility of 129I which is mobile under reducing conditions. The effect of iodine speciation on its transport deserves further attention. Indication of delayed transport of some "mobile" radionuclides (especially 99Tc) in the groundwater at the NTS suggested the importance of redox conditions of the natural system in controlling the fate and transport of radionuclides, which has implications in the enhanced performance of the potential Yucca Mountain repository, located adjacent to the NTS, to store high-level nuclear wastes as well as management of radionuclide contamination in legacy nuclear operations facilities.},
author = {Hu, Q H and Rose, T P and Zavarin, M and Smith, D K and Moran, J E and Zhao, P H},
doi = {10.1016/j.jenvrad.2008.06.007},
issn = {0265-931X},
journal = {Journal of environmental radioactivity},
keywords = {Carbon Radioisotopes,Carbon Radioisotopes: analysis,Chlorine,Chlorine: analysis,Fresh Water,Fresh Water: analysis,Iodine Radioisotopes,Iodine Radioisotopes: analysis,Nevada,Radioactive,Radioactive: analysis,Radioisotopes,Radioisotopes: analysis,Technetium,Technetium: analysis,Tritium,Tritium: analysis,Water Movements,Water Pollutants},
month = oct,
number = {10},
pages = {1617--30},
pmid = {18662844},
title = {{Assessing field-scale migration of radionuclides at the Nevada Test Site: "mobile" species.}},
url = {http://dx.doi.org/10.1016/j.jenvrad.2008.06.007},
volume = {99},
year = {2008}
}
@book{Taylor1997,
abstract = {This text by John Taylor introduces the study of uncertainties to lower division science students. Assuming no prior knowledge, the author introduces error analysis through the use of familiar examples ranging from carpentry to well-known historic experiments. Pertinent worked examples, simple exercises throughout the text, and numerous chapter-ending problems combine to make the book ideal for use in physics, chemistry, and engineering lab courses.},
address = {Sausalito, Calif.},
author = {Taylor, John R},
isbn = {0935702423  9780935702422  093570275X  9780935702750},
language = {English},
publisher = {University Science Books},
shorttitle = {An introduction to error analysis},
title = {{An introduction to error analysis: the study of uncertainties in physical measurements}},
url = {http://www.amazon.com/Introduction-Error-Analysis-Uncertainties-Measurements/dp/093570275X/ref=sr\_1\_1?s=books\&ie=UTF8\&qid=1397317240\&sr=1-1\&keywords=9780935702750},
year = {1997}
}
@article{Berman1972,
author = {Berman, Morris},
doi = {10.1353/jsh/5.4.521},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/RSJE2AAC/Berman - 1972 - An essay review of A.E. Musson and Eric Robinson, .pdf:pdf},
issn = {0022-4529, 1527-1897},
journal = {Journal of Social History},
language = {en},
month = jun,
number = {4},
pages = {521--527},
shorttitle = {An essay review of A.E. Musson and Eric Robinson, },
title = {{An essay review of A.E. Musson and Eric Robinson, Science and Technology in the Industrial Revolution (Toronto: University of Toronto Press, 1969. viii + 534 pp. \$9.50)}},
url = {http://jsh.oxfordjournals.org/content/5/4/521 http://jsh.oxfordjournals.org/content/5/4/521.full.pdf},
volume = {5},
year = {1972}
}
@article{Western1999,
author = {Western, Andrew W. and Grayson, Rodger B. and Bl\"{o}schl, G\"{u}nter and Willgoose, Garry R. and McMahon, Thomas a.},
doi = {10.1029/1998WR900065},
issn = {0043-1397},
journal = {Water Resources Research},
number = {3},
pages = {797},
title = {{Observed spatial organization of soil moisture and its relation to terrain indices}},
url = {http://www.agu.org/pubs/crossref/1999/1998WR900065.shtml},
volume = {35},
year = {1999}
}
@article{Palau2014,
abstract = {The use of compound specific multi-isotope approach (C and Cl) in the characterization of a chlorinated ethenes contaminated fractured aquifer allows the identification of several sources and contaminant plumes, as well as the occurrence of biodegradation and mixing processes. The study site is located in Spain with contamination resulting in groundwater concentrations of up to 50 mg/L of trichloroethene (TCE), the most abundant chlorinated ethene, and 7 mg/L of tetrachloroethene (PCE). The potential sources of contamination including abandoned barrels, an underground tank, and a disposal lagoon, showed a wide range in $\delta$13C values from − 15.6 to − 40.5‰ for TCE and from − 18.5 to − 32.4‰ for PCE, allowing the use of isotope fingerprinting for tracing of the origin and migration of these contaminants in the aquifer. In contrast, there is no difference between the $\delta$37Cl values for TCE in the contaminant sources, ranging from + 0.53 to + 0.66‰. Variations of $\delta$37Cl and $\delta$13C in the different contaminant plumes were used to investigate the role of biodegradation in groundwater. Moreover, the isotopic data were incorporated into a reactive transport model for determination of whether the isotope pattern observed downstream from the tank's source could be explained by the simultaneous effect of mixing and biodegradation. The results demonstrate that a multi-isotope approach is a valuable tool for characterization of complex sites such as fractured bedrock aquifer contaminated by multiple sources, providing important information which can be used by consultants and site managers to prioritize and design more successful remediation strategies.},
author = {Palau, Jordi and Marchesi, Massimo and Chambon, Julie C. C. and Aravena, Ramon and Canals, \`{A}ngels and Binning, Philip J. and Bjerg, Poul L. and Otero, Neus and Soler, Albert},
doi = {10.1016/j.scitotenv.2013.12.059},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/PRAKTNZU/S0048969713015325.html:html;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/VVQMKJ94/Palau et al. - 2014 - Multi-isotope (carbon and chlorine) analysis for f.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/ZBCZRKUS/S0048969713015325.html:html;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/3BP9HUDA/Palau et al. - 2014 - Multi-isotope (carbon and chlorine) analysis for f.pdf:pdf},
issn = {0048-9697},
journal = {Science of The Total Environment},
keywords = {Chlorinated solvents,Compound-specific isotope analysis,Environmental forensics,Groundwater contamination},
mendeley-tags = {Chlorinated solvents,Compound-specific isotope analysis,Environmental forensics,Groundwater contamination},
month = mar,
pages = {61--70},
title = {{Multi-isotope (carbon and chlorine) analysis for fingerprinting and site characterization at a fractured bedrock aquifer contaminated by chlorinated ethenes}},
url = {http://www.sciencedirect.com/science/article/pii/S0048969713015325 http://www.sciencedirect.com/science/article/pii/S0048969713015325/pdfft?md5=f35c5de1e9e4cd675b22bb0145c60911\&pid=1-s2.0-S0048969713015325-main.pdf},
volume = {475},
year = {2014}
}
@book{Shoshani,
abstract = {Dealing with the volume, complexity, and diversity of data currently being generated by scientific experiments and simulations often causes scientists to waste\ldots},
author = {Shoshani, Arie and Rotem, Doron},
title = {{Scientific Data Management}},
url = {http://www.crcpress.com/product/isbn/9781420069808}
}
@article{Chang,
abstract = {Radioiodine biogeochemistry was investigated by developing an integrated comprehensive model describing multiple physiochemical and enzyme catalyzed reactions based on detailed iodine speciation data obtained previously from laboratory experiments using organic-rich and organic-poor soils from the Savannah River Site, South Carolina. The model accounted for iodine speciation, inter-conversion kinetics (I-, IO3−, organo-I, colloidal-I), reversible partitioning to soil organic matter (SOM) and mineral surfaces, irreversible covalent bonding to SOM, and abiotic and biotic (enzymatic/catalyst-type) reactions. Modeling results strongly supported the assertion that iodine-SOM interactions dominate iodine geochemistry; the iodine uptake coefficient for SOM was an order-of-magnitude greater than that for mineral surface. The proposed model simulated well the iodine partitioning among the soil, colloid, and solution phases. The previously proposed process of soil reduction of IO3− to I− was strongly supported through model simulations. The model revealed that during the first 14 days of contact most iodine in soil was comprised of I− or IO3− associated with mineral surfaces and reversibly bound to SOM. After 14 days, the continued uptake of iodine by soil was attributed primarily to the irreversible bonding of organo-I to SOM. Finally, the model was successfully validated using an independent experimental data set. This biogeochemical modeling study underscores the importance of capturing the dynamic nature of iodine speciation transformations and the importance of treating SOM as a sink (irreversible covalent bonding) and a source (colloidal- and organo-iodine mobile species) for subsurface iodine.},
author = {Chang, Hyun-shik and Xu, Chen and Schwehr, Kathy A. and Zhang, Saijin and Kaplan, Daniel I. and Seaman, John C. and Yeager, Chris and Santschi, Peter H.},
doi = {10.1016/j.jece.2014.03.009},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/NGXECIJ4/Chang et al. - Model of radioiodine speciation and partitioning i.pdf:pdf},
issn = {2213-3437},
journal = {Journal of Environmental Chemical Engineering},
keywords = {Colloids,Iodine,Kinetics,Modeling,Soil organic matter,Speciation},
mendeley-tags = {Colloids,Iodine,Kinetics,Modeling,Soil organic matter,Speciation},
title = {{Model of radioiodine speciation and partitioning in organic-rich and organic-poor soils from the savannah river site}},
url = {http://www.sciencedirect.com/science/article/pii/S2213343714000578 http://www.sciencedirect.com/science/article/pii/S2213343714000578/pdfft?md5=674f01a10a3232e20502d6857014105c\&pid=1-s2.0-S2213343714000578-main.pdf}
}
@article{Bossew2012,
abstract = {Radionuclides emitted from the Fukushima I nuclear power plant have been detected in air all over Europe. Concentrations remained far below levels which could have caused radiological concern: probably the committed thyroid dose due to inhalation remained below about 1 $\mu$Sv (for 10 y children), within the investigated region. They provided, however, a spatio-temporal signal which could be used to develop and test tools to provide additional information on the large-scale situation (Europe-wide, in this case) during a nuclear emergency.
In this part we discuss the spatial distribution of the contaminated air masses over Europe. Using 131I as an example, we present a method to construct maps of the time-cumulated 131I concentration in air and of the peak concentrations. Procedures to deal with the statistical limitations of a data set stemming from different monitoring schemes are discussed. As over all results, the mean (over the investigated region) cumulated concentration of particular 131I is estimated about 9 mBq d/m3, with observed maximum of about 23 mBq d/m3. The probability that much higher concentrations occurred at unsampled locations, than have been observed anywhere, is assessed low, e.g. about 2.5\% for the cumulated 131I(part.) concentration to exceed 30 mBq d/m3.
Our method can be used in nuclear emergencies for providing spatial analyses if radionuclide concentrations of health concern are detected by atmospheric monitoring stations. We suggest considering such methods of data harmonization if synoptic assessment based on heterogeneous datasets is attempted.},
author = {Bossew, P. and Kirchner, G. and {De Cort}, M. and de Vries, G. and Nishev, A. and de Felice, L.},
doi = {10.1016/j.jenvrad.2011.11.019},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/BNIKZXJS/Bossew et al. - 2012 - Radioactivity from Fukushima Dai-ichi in air over .pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/UK375R44/Bossew et al. - 2012 - Radioactivity from Fukushima Dai-ichi in air over .pdf:pdf},
issn = {0265-931X},
journal = {Journal of Environmental Radioactivity},
keywords = {Activity concentration in air,Data harmonization,Fukushima accident,Spatio-temporal analysis},
mendeley-tags = {Activity concentration in air,Data harmonization,Fukushima accident,Spatio-temporal analysis},
month = dec,
pages = {22--34},
shorttitle = {Radioactivity from Fukushima Dai-ichi in air over },
title = {{Radioactivity from Fukushima Dai-ichi in air over Europe; part 1: spatio-temporal analysis}},
url = {http://www.sciencedirect.com/science/article/pii/S0265931X11002931 http://www.sciencedirect.com/science/article/pii/S0265931X11002931/pdfft?md5=63d9f853b5318c2356bb3945debafcb9\&pid=1-s2.0-S0265931X11002931-main.pdf},
volume = {114},
year = {2012}
}
@article{Kumar,
abstract = {Abstract
We study the time dependent interaction between hydrogeological and exposure parameters in daily dose predictions due to exposure of humans to groundwater contamination. Dose predictions are treated stochastically to account for an incomplete hydrogeological and geochemical field characterization, and an incomplete knowledge of the physiological response. We used a nested Monte Carlo framework to account for uncertainty and variability arising from both hydrogeological and exposure variables. Our interest is in the temporal dynamics of the total dose and their effects on parametric uncertainty reduction. We illustrate the approach to a HCH (lindane) pollution problem at the Ebro River, Spain. The temporal distribution of lindane in the river water can have a strong impact in the evaluation of risk. The total dose displays a non-linear effect on different population cohorts, indicating the need to account for population variability. We then expand the concept of Comparative Information Yield Curves developed earlier to evaluate parametric uncertainty reduction under temporally variable exposure dose. Results show that the importance of parametric uncertainty reduction varies according to the temporal dynamics of the lindane plume. The approach could be used for any chemical to aid decision makers to better allocate resources towards reducing uncertainty.},
author = {Kumar, Vikas and de Barros, Felipe P.J. and Schuhmacher, Marta and Fern\`{a}ndez-Garcia, Daniel and Sanchez-Vila, Xavier},
doi = {10.1016/j.jhazmat.2013.08.036},
issn = {0304-3894},
journal = {Journal of Hazardous Materials},
keywords = {Comparative Information Yield Curves.,Temporally variable exposure dose,groundwater contamination temporal dynamics,lindane- Monte Carlo,parameter sensitivity},
mendeley-tags = {Comparative Information Yield Curves.,Temporally variable exposure dose,groundwater contamination temporal dynamics,lindane- Monte Carlo,parameter sensitivity},
title = {{Dynamic interactions between hydrogeological and exposure parameters in daily dose prediction under uncertainty and temporal variability}},
url = {http://www.sciencedirect.com/science/article/pii/S030438941300602X http://www.sciencedirect.com/science/article/pii/S030438941300602X/pdf?md5=b267f3dbabf95e4b1b45cb44fceebcfc\&pid=1-s2.0-S030438941300602X-main.pdf}
}
@article{Beven1997,
author = {Beven, Keith J.},
journal = {Hydrological Processes},
number = {9},
pages = {1069--1085},
shorttitle = {TOPMODEL},
title = {{TOPMODEL: a critique}},
url = {http://biodav.atmos.colostate.edu/kraus/Papers/TOPMODEL/topmodel\_beven.pdf},
volume = {11},
year = {1997}
}
@incollection{Letcher2011b,
address = {Boston},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/P7U4QXKJ/Letcher and Vallero - 2011 - Epilogue.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {541--543},
publisher = {Academic Press},
title = {{Epilogue}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100385 http://www.sciencedirect.com/science/article/pii/B9780123814753100385/pdfft?md5=51e3b21a929e57e8c8316fab6875bc93\&pid=3-s2.0-B9780123814753100385-main.pdf},
year = {2011}
}
@article{Cuthbert2014,
abstract = {While in catchment and hillslope hydrology a more nuanced approach is now taken to streamflow recession analysis, in the context of major aquifers it is commonly still assumed that the groundwater head recession rate will take exponential form, an idea originally proposed in the 19th Century. However it is shown here that, in early times, the groundwater head recession in a major aquifer should take an almost straight line form with a rate approximately equal to the long-term recharge rate divided by the aquifer storage coefficient. The length of this phase can be estimated from an analytical expression derived in the paper which depends on the aquifer diffusivity, length scale, and the position of the monitoring point. A transitional phase then leads to an exponential phase after some critical time which is independent of the position of the monitoring point. Major aquifers in a state of periodic quasi-steady state are expected to have rates of groundwater flux recession which deviate little from the average rate of groundwater recharge. Where quasi-exponential groundwater declines are observed in nature, their form may be diagnostic of particular types of aquifer properties and/or boundary effects, such as proximity to drainage boundaries, variations in transmissivity with hydraulic head, storage changes due to pumping, nonequilibrium flow at a range of spatial and temporal scales, and variations in specific yield with depth. Recession analysis has applicability to a range of groundwater problems and is powerful way of gaining insight into the hydrologic functioning of an aquifer.},
author = {Cuthbert, M. O.},
doi = {10.1002/2013WR014060},
issn = {1944-7973},
journal = {Water Resources Research},
keywords = {1828 Groundwater hydraulics,1829 Groundwater hydrology,1830 Groundwater/surface water interaction,groundwater hydraulics,groundwater recession},
language = {en},
mendeley-tags = {1828 Groundwater hydraulics,1829 Groundwater hydrology,1830 Groundwater/surface water interaction,groundwater hydraulics,groundwater recession},
month = mar,
number = {3},
pages = {2407--2424},
title = {{Straight thinking about groundwater recession}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/2013WR014060/abstract},
volume = {50},
year = {2014}
}
@incollection{Periathamby2011,
abstract = {Municipal Solid Waste (MSW) management is dynamic, especially in evolving technology and policy changes. This chapter incorporates the basic issues, such as waste generation and composition, treatment and disposal, including illegal dumping, as well as, the challenges and issues of MSW management. Current topics of relevance, included in the chapter, are waste management and climate change, which explains the need to reduce greenhouse gas (GHG) emission from this sector. Also important is marine pollution by MSW and its impact on marine life around small island nations. Lastly, an explicit discussion on the policy and regulations is elucidated to explore the main causes of the MSW management challenges, particularly in developing and transitory nations.
Municipal solid waste (MSW) is an inevitable by-product of human activity. It includes all wastes generated within a municipality. However, the definitions differ from country to country. In some developing nations, industrial waste and fecal material, though normally not considered as part of MSW, are often found in MSW and, thus, disposed together in normal landfills. MSW refers to all wastes generated, collected, transported, and disposed of within the jurisdiction of a municipal authority. In most cases, it comprises mainly food waste, and rubbish from residential areas, street sweepings, commercial and institutional nonhazardous wastes as well as (in some countries) construction and demolition waste. MSW management incorporates several interrelated aspects, which needs complete cooperation and collaboration for efficient delivery. It comprises aspects of waste generation, waste composition, collection, recycling (if any), pretreatment and treatment, and finally, disposal. These management aspects thus require input from legal, economic, governmental, political, administrative, and environmental players. Thus, it requires the involvement of multiprofessional drivers, and at times, the failure of one component is sufficient to cause the whole management to collapse. The management structure and function is site-specific and depends on socioeconomic, behavioral, cultural, institutional, and political frameworks. These stakeholders need to interact and cooperate for the management system to achieve its target.},
address = {Boston},
author = {Periathamby, Agamuthu},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/Z7M5UNGB/Periathamby - 2011 - Chapter 8 - Municipal Waste Management.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {109--125},
publisher = {Academic Press},
title = {{Chapter 8 - Municipal Waste Management}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100087 http://www.sciencedirect.com/science/article/pii/B9780123814753100087/pdfft?md5=f6bd04d415f0008f842bfb178a220f45\&pid=3-s2.0-B9780123814753100087-main.pdf},
year = {2011}
}
@book{LeMaitre2010,
author = {{Le Ma\^{\i}tre}, Olivier P. and Knio, Omar M.},
publisher = {Springer},
shorttitle = {Spectral methods for uncertainty quantification},
title = {{Spectral methods for uncertainty quantification: with applications to computational fluid dynamics}},
url = {http://books.google.com/books?hl=en\&lr=\&id=lOFCquL6SxYC\&oi=fnd\&pg=PA1\&dq=Uncertainty+Quantification:+Theory,+Implementation,+and+Applications\&ots=v8sSkoY-b1\&sig=8z5SujgImZrFJ0X68qlc3ulfLkw},
year = {2010}
}
@article{Taylor2013,
abstract = {As the world's largest distributed store of fresh water, ground water plays a central part in sustaining ecosystems and enabling human adaptation to climate variability and change. The strategic importance of ground water for global water and food security will probably intensify under climate change as more frequent and intense climate extremes (droughts and floods) increase variability in precipitation, soil moisture and surface water. Here we critically review recent research assessing the impacts of climate on ground water through natural and human-induced processes as well as through groundwater-driven feedbacks on the climate system. Furthermore, we examine the possible opportunities and challenges of using and sustaining groundwater resources in climate adaptation strategies, and highlight the lack of groundwater observations, which, at present, limits our understanding of the dynamic relationship between ground water and climate.},
author = {Taylor, Richard G. and Scanlon, Bridget and D\"{o}ll, Petra and Rodell, Matt and van Beek, Rens and Wada, Yoshihide and Longuevergne, Laurent and Leblanc, Marc and Famiglietti, James S. and Edmunds, Mike and Konikow, Leonard and Green, Timothy R. and Chen, Jianyao and Taniguchi, Makoto and Bierkens, Marc F. P. and MacDonald, Alan and Fan, Ying and Maxwell, Reed M. and Yechieli, Yossi and Gurdak, Jason J. and Allen, Diana M. and Shamsudduha, Mohammad and Hiscock, Kevin and Yeh, Pat J.-F. and Holman, Ian and Treidel, Holger},
doi = {10.1038/nclimate1744},
file = {:Users/arthur/Google Drive/References/reference\_articles/by topic/Groundwater/Taylor\_etal\_2012\_nclimate1744.pdf:pdf},
issn = {1758-678X},
journal = {Nature Climate Change},
keywords = {Adaptation,Earth sciences,Impacts,hydrology},
language = {en},
mendeley-tags = {Adaptation,Earth sciences,Impacts,hydrology},
month = apr,
number = {4},
pages = {322--329},
title = {{Ground water and climate change}},
url = {http://www.nature.com/nclimate/journal/v3/n4/full/nclimate1744.html},
volume = {3},
year = {2013}
}
@article{Zehe2009,
author = {Zehe, Erwin and Sivapalan, Murugesu},
doi = {10.5194/hess-13-1273-2009},
issn = {1607-7938},
journal = {Hydrology and Earth System Sciences},
month = jul,
number = {7},
pages = {1273--1297},
title = {{Threshold behaviour in hydrological systems as (human) geo-ecosystems: manifestations, controls, implications}},
url = {http://www.hydrol-earth-syst-sci.net/13/1273/2009/},
volume = {13},
year = {2009}
}
@article{Brody2000,
author = {Brody, Howard and Rip, Michael Russell and Vinten-Johansen, Peter and Paneth, Nigel and Rachman, Stephen},
doi = {10.1016/S0140-6736(00)02442-9},
issn = {0140-6736},
journal = {The Lancet},
month = jul,
number = {9223},
pages = {64--68},
shorttitle = {Map-making and myth-making in Broad Street},
title = {{Map-making and myth-making in Broad Street: the London cholera epidemic, 1854}},
url = {http://www.sciencedirect.com/science/article/pii/S0140673600024429 http://www.sciencedirect.com/science?\_ob=MiamiImageURL\&\_cid=271074\&\_user=4420\&\_pii=S0140673600024429\&\_check=y\&\_origin=article\&\_zone=toolbar\&\_coverDate=01-Jul-2000\&view=c\&originContentFamily=serial\&wchp=dGLbVlS-zSkWA\&md5=ea30fd3f1ae59a57dc5857e5a97ffeb0\&pid=1-s2.0-S0140673600024429-main.pdf},
volume = {356},
year = {2000}
}
@article{McDonald2010,
abstract = {Aquatic biogeochemical models are widely used as tools for understanding aquatic ecosystems and predicting their response to various stimuli (e.g., nutrient loading, toxic substances, climate change). Due to the complexity of these systems, such models are often elaborate and include a large number of estimated parameters. However, correspondingly large data sets are rarely available for calibration purposes, leading to models that may be overfit and possess reduced predictive capabilities. We apply, for the first time, information-theoretic model-selection techniques to a set of spatially explicit (1D) algal dynamics models of varying parameter dimension. We demonstrate that increases in complexity tend to produce a better model fit to calibration data, but beyond a certain degree of complexity the benefits of adding parameters are diminished (the risk of overfitting becomes greater). The particular approach taken here is computationally expensive, but several suggestions are made as to how multimodel methods may practically be extended to more sophisticated models.},
author = {McDonald, Cory P. and Urban, Noel R.},
doi = {10.1016/j.ecolmodel.2009.10.021},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/WAGMGNQS/McDonald and Urban - 2010 - Using a model selection criterion to identify appr.pdf:pdf},
issn = {0304-3800},
journal = {Ecological Modelling},
keywords = {Akaike’s Information Criterion (AIC),DYRESM-CAEDYM,Model selection,Trout Lake,model complexity},
mendeley-tags = {Akaike’s Information Criterion (AIC),DYRESM-CAEDYM,Model selection,Trout Lake,model complexity},
month = feb,
number = {3},
pages = {428--432},
title = {{Using a model selection criterion to identify appropriate complexity in aquatic biogeochemical models}},
url = {http://www.sciencedirect.com/science/article/pii/S0304380009007078 http://www.sciencedirect.com/science/article/pii/S0304380009007078/pdfft?md5=9387cca94e7cf8a0dcbffbb578107112\&pid=1-s2.0-S0304380009007078-main.pdf},
volume = {221},
year = {2010}
}
@article{McDonnell2007a,
author = {McDonnell, J. J. and Sivapalan, Murugesu and Vach\'{e}, K. and Dunn, S. and Grant, G. and Haggerty, R. and Hinz, C. and Hooper, R. and Kirchner, J. and Roderick, M. L. and Selker, J. and Weiler, M.},
doi = {10.1029/2006WR005467},
issn = {00431397},
journal = {Water Resources Research},
month = jul,
number = {7},
pages = {n/a--n/a},
title = {{Moving beyond heterogeneity and process complexity: A new vision for watershed hydrology}},
url = {http://doi.wiley.com/10.1029/2006WR005467},
volume = {43},
year = {2007}
}
@article{Morton1993,
author = {Morton, Adam},
doi = {10.1093/bjps/44.4.659},
issn = {0007-0882},
journal = {The British Journal for the Philosophy of Science},
number = {4},
pages = {659--674},
title = {{Mathematical Models: Questions of Trustworthiness}},
url = {http://bjps.oxfordjournals.org/cgi/doi/10.1093/bjps/44.4.659},
volume = {44},
year = {1993}
}
@article{Gzyla,
abstract = {The paper presents a new multi-step approach aiming at source identification and release history estimation. The new approach consists of three steps: performing integral pumping tests, identifying sources, and recovering the release history by means of a geostatistical approach. The present paper shows the results obtained from the application of the approach within a complex case study in Poland in which several areal sources were identified. The investigated site is situated in the vicinity of a former chemical plant in southern Poland in the city of Jaworzno in the valley of the Wąwolnica River; the plant has been in operation since the First World War producing various chemicals. From an environmental point of view the most relevant activity was production of pesticides, especially lindane. The application of the multi-step approach enabled a significant increase in the knowledge of contamination at the site. Some suspected contamination sources have been proven to have minor effect on the overall contamination. Other suspected sources have been proven to have key significance. Some areas not taken into consideration previously have now been identified as key sources. The method also enabled estimation of the magnitude of the sources and, a list of the priority reclamation actions will be drawn as a result. The multi-step approach has proven to be effective and may be applied to other complicated contamination cases. Moreover, the paper shows the capability of the geostatistical approach to manage a complex real case study.},
author = {Gzyl, G. and Zanini, A. and Frączek, R. and Kura, K.},
doi = {10.1016/j.jconhyd.2013.11.006},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/EXJ2P88G/S0169772213001769.html:html;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/NX3HBKMU/Gzyl et al. - Contaminant source and release history identificat.pdf:pdf},
issn = {0169-7722},
journal = {Journal of Contaminant Hydrology},
keywords = {Contamination,FOKS,Geostatistics,Groundwater,Integral Pumping Test},
mendeley-tags = {Contamination,FOKS,Geostatistics,Groundwater,Integral Pumping Test},
shorttitle = {Contaminant source and release history identificat},
title = {{Contaminant source and release history identification in groundwater: A multi-step approach}},
url = {http://www.sciencedirect.com/science/article/pii/S0169772213001769 http://www.sciencedirect.com/science/article/pii/S0169772213001769/pdfft?md5=de73f0dd3cdf689fb3eb5b41acf4c599\&pid=1-s2.0-S0169772213001769-main.pdf}
}
@article{Beven2013,
abstract = {This paper reviews the use of the Generalized Likelihood Uncertainty Estimation (GLUE) methodology in the 20 years since the paper by Beven and Binley in Hydrological Processes in (1992), which is now one of the most highly cited papers in hydrology. The original conception, the on-going controversy it has generated, the nature of different sources of uncertainty and the meaning of the GLUE prediction uncertainty bounds are discussed. The hydrological, rather than statistical, arguments about the nature of model and data errors and uncertainties that are the basis for GLUE are emphasized. The application of the Institute of Hydrology distributed model to the Gwy catchment at Plynlimon presented in the original paper is revisited, using a larger sample of models, a wider range of likelihood evaluations and new visualization techniques. It is concluded that there are good reasons to reject this model for that data set. This is a positive result in a research environment in that it requires improved models or data to be made available. In practice, there may be ethical issues of using outputs from models for which there is evidence for model rejection in decision making. Finally, some suggestions for what is needed in the next 20 years are provided. © 2013 The Authors. Hydrological Processes published by John Wiley \& Sons, Ltd.},
author = {Beven, Keith and Binley, Andrew},
doi = {10.1002/hyp.10082},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/CA3DHUFQ/Beven and Binley - 2013 - GLUE 20 years on.pdf:pdf},
issn = {1099-1085},
journal = {Hydrological Processes},
keywords = {Plynlimon,epistemic error,equifinality,rainfall–runoff models,uncertainty estimation},
language = {en},
mendeley-tags = {Plynlimon,epistemic error,equifinality,rainfall–runoff models,uncertainty estimation},
month = oct,
pages = {n/a--n/a},
shorttitle = {GLUE},
title = {{GLUE: 20 years on}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/hyp.10082/abstract http://onlinelibrary.wiley.com/store/10.1002/hyp.10082/asset/hyp10082.pdf?v=1\&t=hw91n71e\&s=b13f43f193d4a71cfccb8c33992030ea49e436ea},
year = {2013}
}
@article{KerrySmith1980,
abstract = {The purpose of this paper is to consider the implicatons of model complexity for the quality of the information provided by models of production activities that account for the processes involved in residuals generation and treatment. Using each of the three primary technologies for iron and steel-making industry and models of varying detail for each, the paper compares the estimated levels of residuals generated and treatment costs for both atmospheric and waterborne effluents. The findings suggest that there are strategic details in model construction which have fundamental implications for the design of environmental policies. Moreover, preliminary estimates of the costs of model construction and operation suggest that policymakers may not be able to afford complexity for its own sake. Rather these costs will require the development of methods to isolate the strategic details in each technology that are potentially important to environmental policies.},
author = {{Kerry Smith}, V and Vaughan, William J},
doi = {10.1016/0095-0696(80)90002-9},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/BTW2WHHI/Kerry Smith and Vaughan - 1980 - The implications of model complexity for environme.pdf:pdf},
issn = {0095-0696},
journal = {Journal of Environmental Economics and Management},
month = sep,
number = {3},
pages = {184--208},
title = {{The implications of model complexity for environmental management}},
url = {http://www.sciencedirect.com/science/article/pii/0095069680900029 http://www.sciencedirect.com/science/article/pii/0095069680900029/pdf?md5=6c8c346cd6bdad59ab646c1f3d6e68cb\&pid=1-s2.0-0095069680900029-main.pdf},
volume = {7},
year = {1980}
}
@article{Holm1978,
abstract = {The search for 242mAm in environmental samples has involved detection of its daughter 242Cm. These samples were contaminated by transuranium nuclides either from a nuclear fuel reprocessing plant or from a thermonuclear test fallout. A logical consequence was then to analyse global fallout contaminated samples for 242Cm and 244Cm to establish the present distribution and global contamination of our environment by these transuranium elements. The authors have chosen the lichen Cladonia alpestris, which is an excellent bioindicator for atmospheric fallout; results are presented.},
annote = {Cited By (since 1996):9},
author = {Holm, E. and Persson, B.R.R.},
issn = {0028-0836},
journal = {Nature},
language = {English},
number = {5660},
pages = {289--290},
title = {{Global fallout of curium}},
volume = {273},
year = {1978}
}
@article{Liu2007a,
author = {Liu, Yuqiong and Gupta, Hoshin V.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/6XR5B5HA/Liu and Gupta - 2007 - Uncertainty in hydrologic modeling Toward an inte.pdf:pdf},
journal = {Water Resources Research},
number = {7},
shorttitle = {Uncertainty in hydrologic modeling},
title = {{Uncertainty in hydrologic modeling: Toward an integrated data assimilation framework}},
url = {http://www.agu.org/pubs/crossref/2007/2006WR005756.shtml http://amazon.nws.noaa.gov/articles/HRL\_Pubs\_PDF\_May12\_2009/New\_Scans\_January\_2010/Gupta\_DA\_review\_WRR\_2007.pdf},
volume = {43},
year = {2007}
}
@article{Goodrich1994a,
author = {Goodrich, David C. and Woolhiser, David A.},
doi = {10.1029/93WR03156},
issn = {1944-7973},
journal = {Water Resources Research},
language = {en},
number = {3},
pages = {845--847},
shorttitle = {Comment on “Physically based hydrologic modeling},
title = {{Comment on “Physically based hydrologic modeling: 1, A terrain-based model for investigative purposes” by R. B. Grayson, I. D. Moore, and T. A. McMahon}},
url = {http://onlinelibrary.wiley.com/doi/10.1029/93WR03156/abstract http://onlinelibrary.wiley.com/store/10.1029/93WR03156/asset/wrcr6423.pdf?v=1\&t=hfezdsgj\&s=74881879cfd2b458f12adc00b377b7f2ff40f8a0 http://onlinelibrary.wiley.com/store/10.1029/93WR03156/asset/wrcr6423.pdf?v=1\&t=hfezgm5v\&s=23307db4783782f905b8c51f966b3575f725c51a},
volume = {30},
year = {1994}
}
@article{ICRP2007a,
author = {ICRP},
doi = {10.1016/j.icrp.2007.10.005},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/RDQKQI2F/ICRP - 2007 - Chapters 3 and 4.pdf:pdf},
issn = {0146-6453},
journal = {Annals of the ICRP},
month = apr,
number = {2–4},
pages = {49--79},
series = {P103: The 2007 Recommendations of the International Commission on Radiological Protection},
title = {{Chapters 3 and 4}},
url = {http://www.sciencedirect.com/science/article/pii/S0146645307000334 http://www.sciencedirect.com/science/article/pii/S0146645307000334/pdfft?md5=1ee7dc45a4e4fad5a0c092d64abf635a\&pid=1-s2.0-S0146645307000334-main.pdf},
volume = {37},
year = {2007}
}
@article{Wagener2007,
author = {Wagener, Thorsten and Sivapalan, Murugesu and Troch, Peter A. and Woods, Ross A.},
doi = {10.1111/j.1749-8198.2007.00039.x},
issn = {1749-8198},
journal = {Geography Compass},
month = jul,
number = {4},
pages = {901--931},
title = {{Catchment Classification and Hydrologic Similarity}},
url = {http://doi.wiley.com/10.1111/j.1749-8198.2007.00039.x},
volume = {1},
year = {2007}
}
@article{Kazumba2008,
author = {Kazumba, Shija and Oron, Gideon and Honjo, Yusuke and Kamiya, Kohji},
doi = {10.1016/j.jhydrol.2008.06.021},
issn = {00221694},
journal = {Journal of Hydrology},
keywords = {regional groundwater},
month = sep,
number = {1-2},
pages = {131--140},
title = {{Lumped model for regional groundwater flow analysis}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0022169408003119},
volume = {359},
year = {2008}
}
@incollection{Letcher2011d,
address = {Boston},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/M89TWD5D/Letcher and Vallero - 2011 - Index.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {545--565},
publisher = {Academic Press},
title = {{Index}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100397 http://www.sciencedirect.com/science/article/pii/B9780123814753100397/pdfft?md5=a6605cd8957556d6edc926956b05a90c\&pid=3-s2.0-B9780123814753100397-main.pdf},
year = {2011}
}
@incollection{Vallero2011f,
abstract = {This chapter focuses on how land can be harmed by human activities, such as construction, agriculture, and transportation. These and other human activities lead to the release of chemical contaminants, but they also result in landscape damage, such as soil erosion, habitat destruction, and loss of resources, such as wetlands and coastal ecosystems. Plans must include measures to complement the natural and cultural environment and to avoid destruction or adverse alteration of the land. This means that good practice should always consider approaches to minimize impacts of construction, development, and facility operation on the surrounding watershed, by preventing water pollution and actions that disrupt natural drainage patterns. In addition, land use planning must directly address habitat destruction by recommending ways that any development conserve land that serves as habitat for native flora and fauna, both on- and off-site, and directly and indirectly. Another special consideration for land development is the presence of threatened or endangered species and the potential that their habitats may be affected by developing a site. Wasting land by losing it through erosion, diminishing its beneficial uses, and contaminating it is wholly unacceptable. Protecting land relies on sound application of not only the physical and natural sciences but also the social sciences. Where people choose to live is based on environmental quality and sociological and psychological factors. Land use planners, engineers, and waste managers each have vital roles in preventing and addressing land pollution.},
address = {Boston},
author = {Vallero, Daniel J. and Vallero, Daniel A.},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/DG2N697B/Vallero and Vallero - 2011 - Chapter 29 - Land Pollution.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {445--466},
publisher = {Academic Press},
title = {{Chapter 29 - Land Pollution}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100294 http://www.sciencedirect.com/science/article/pii/B9780123814753100294/pdfft?md5=a96e51f036b9f5b11c37a5ed98b9d81c\&pid=3-s2.0-B9780123814753100294-main.pdf},
year = {2011}
}
@article{Haas1996,
abstract = {For the estimation of moments from pulse-tracer experiments, prior workers have used trapezoidal rule integration as well as a generalized moment of inertia approach. In this technical note, these two methods are compared, and it is shown that the latter method produces biased estimators of the mean, particularly the variance of the residence time distribution, while the trapezoidal rule is substantially less biased under usual conditions. Therefore, the trapezoidal rule should be applied for the analysis of such data.},
author = {Haas, C.},
doi = {10.1061/(ASCE)0733-9372(1996)122:12(1121)},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/4STZENX2/Haas - 1996 - Moment Analysis of Tracer Experiments.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/PJGM9437/Haas - 1996 - Moment Analysis of Tracer Experiments.html:html},
issn = {0733-9372},
journal = {Journal of Environmental Engineering},
number = {12},
pages = {1121--1130},
title = {{Moment Analysis of Tracer Experiments}},
url = {http://ascelibrary.org/doi/abs/10.1061/\%28ASCE\%290733-9372\%281996\%29122\%3A12\%281121\%29 http://ascelibrary.org/doi/pdf/10.1061/\%28ASCE\%290733-9372\%281996\%29122\%3A12\%281121\%29},
volume = {122},
year = {1996}
}
@article{Warrick2013,
abstract = {Summary
Time-dependencies of suspended-sediment discharge from six coastal watersheds of northern California – Smith River, Klamath River, Trinity River, Redwood Creek, Mad River, and Eel River – were evaluated using monitoring data from 1955 to 2010. Suspended-sediment concentrations revealed time-dependent hysteresis and multi-year trends. The multi-year trends had two primary patterns relative to river discharge: (i) increases in concentration resulting from both land clearing from logging and the flood of record during December 1964 (water year 1965), and (ii) continual decreases in concentration during the decades following this flood. Data from the Eel River revealed that changes in suspended-sediment concentrations occurred for all grain-size fractions, but were most pronounced for the sand fraction. Because of these changes, the use of bulk discharge-concentration relationships (i.e., “sediment rating curves”) without time-dependencies in these relationships resulted in substantial errors in sediment load estimates, including 2.5-fold over-prediction of Eel River sediment loads since 1979. We conclude that sediment discharge and sediment discharge relationships (such as sediment rating curves) from these coastal rivers have varied substantially with time in response to land use and climate. Thus, the use of historical river sediment data and sediment rating curves without considerations for time-dependent trends may result in significant errors in sediment yield estimates from the globally-important steep, small watersheds.},
author = {Warrick, J.A. and Madej, M.A. and Go\~{n}i, M.A. and Wheatcroft, R.A.},
doi = {10.1016/j.jhydrol.2013.02.041},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/E4KJQHEP/Warrick et al. - 2013 - Trends in the suspended-sediment yields of coastal.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/JVNWJJFU/Warrick et al. - 2013 - Trends in the suspended-sediment yields of coastal.html:html},
issn = {0022-1694},
journal = {Journal of Hydrology},
keywords = {Northern California,River,Suspended-sediment discharge,Time series analysis},
mendeley-tags = {Northern California,River,Suspended-sediment discharge,Time series analysis},
month = may,
pages = {108--123},
title = {{Trends in the suspended-sediment yields of coastal rivers of northern California, 1955–2010}},
url = {http://www.sciencedirect.com/science/article/pii/S0022169413001649 http://www.sciencedirect.com/science/article/pii/S0022169413001649/pdfft?md5=1fcd9e7a9e2479f5f7c4c7b2dafb02ab\&pid=1-s2.0-S0022169413001649-main.pdf},
volume = {489},
year = {2013}
}
@article{Iorgulescu2004,
author = {Iorgulescu, I. and Beven, Keith J.},
journal = {Water resources research},
number = {8},
pages = {W08403},
shorttitle = {Nonparametric direct mapping of rainfall-runoff re},
title = {{Nonparametric direct mapping of rainfall-runoff relationships: An alternative approach to data analysis and modeling?}},
url = {http://www.agu.org/pubs/crossref/2004/2004WR003094.shtml http://www.geo.oregonstate.edu/classes/ecosys\_info/readings/2004WR003094.pdf},
volume = {40},
year = {2004}
}
@article{Barlow1977,
abstract = {Two-dimensional modelling for regional geophysical interpretation requires gravity data along profiles that are many tens of kilometres in length. The only data presently available for most of onshore Australia are from reconnaissance surveys using helicopter transport; for nearly all of the continental margins the only data are from surface ship traverses. Those data are sufficient to produce regional gravity maps that show major gravity features, gradients and trends.},
author = {Barlow, B.},
doi = {10.1071/EG977139},
issn = {0812-3985},
journal = {Exploration Geophysics},
month = dec,
number = {4},
pages = {139--143},
title = {{Data limitations on model complexity; 2-D gravity modelling with desk-top calculators}},
url = {http://library.seg.org/doi/abs/10.1071/EG977139},
volume = {8},
year = {1977}
}
@incollection{Shulman2011a,
abstract = {Tyres are an essential part of the economy of every country that relies on vehicular and air transport to move people and goods. The management of post-consumer tyres is greatly influenced by environmental legislation at International, European Union (EU), and State levels. Each has had an important impact on recycling—and recyclers—from sourcing raw materials, to product development and marketing, and the disposal of recycling residues. The starting point for tyre recycling is the same as other industries—the sourcing of a continuous flow of raw materials. Historically, post-consumer tyres have been collected separately and sorted into two sectors—the part worn market (second-hand) and retreading. However, as retreading dwindled, reuse/export stagnated, material recycling and energy recovery operations began to absorb the tyres. In many countries with large retreading industries, the infrastructure for collecting, sorting and transporting tyres became the means of servicing. Generally, prior to delivery to a treatment facility, the tyres are sorted by category, including car, truck and others, and then by size. Tyre recycling treatments range from the simplest mechanical cutting devices to sophisticated, complex multi-phase chemical, mechanochemical and thermal processes, which overcome many of the principal obstacles inherent in the recycling of thermoset rubbers.},
address = {Boston},
author = {Shulman, Valerie L.},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/UAZ33C34/Shulman - 2011 - Chapter 21 - Tyre Recycling.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {297--320},
publisher = {Academic Press},
title = {{Chapter 21 - Tyre Recycling}},
url = {http://www.sciencedirect.com/science/article/pii/B978012381475310021X http://www.sciencedirect.com/science/article/pii/B978012381475310021X/pdfft?md5=81f884f36a48c8a70593f40fc4b122e4\&pid=3-s2.0-B978012381475310021X-main.pdf},
year = {2011}
}
@article{Howarth1979,
abstract = {In the context of analysis of variance, Box and Cox (1964) developed a generalized technique for power transformation of frequency distributions to normality. It is here applied to geochemical data, based on the nonlinear optimization of skewness and kurtosis. The transform appears to be particularly well suited to the preprocessing of geochemical data prior to multivariate analysis.},
author = {Howarth, R. J. and Earle, S. a. M.},
doi = {10.1007/BF01043245},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/7IAUJ3G4/Howarth and Earle - 1979 - Application of a generalized power transformation .pdf:pdf},
issn = {0020-5958, 1573-8868},
journal = {Journal of the International Association for Mathematical Geology},
keywords = {FORTRAN,Geotechnical Engineering,Hydrogeology,Math. Applications in Geosciences,Statistics for Engineering- Physics- Computer Scie,algorithm,data transformation,frequency distributions,geochemistry},
language = {en},
mendeley-tags = {FORTRAN,Geotechnical Engineering,Hydrogeology,Math. Applications in Geosciences,Statistics for Engineering- Physics- Computer Scie,algorithm,data transformation,frequency distributions,geochemistry},
month = feb,
number = {1},
pages = {45--62},
title = {{Application of a generalized power transformation to geochemical data}},
url = {http://link.springer.com/article/10.1007/BF01043245 http://link.springer.com/content/pdf/10.1007\%2FBF01043245.pdf},
volume = {11},
year = {1979}
}
@article{Abraham1988,
abstract = {Abstract.  Two characterizations, the aberrant observation and innovation models, for outliers in time series are considered. A procedure based on the well-known score-test is discussed for detection of outliers and distinguishing between the outlier types. Significance levels of the tests are also obtained and the method is illustrated with simulated examples.},
author = {Abraham, Bovas and Yatawara, Nihal},
doi = {10.1111/j.1467-9892.1988.tb00458.x},
issn = {1467-9892},
journal = {Journal of Time Series Analysis},
keywords = {Aberrant observation,aberrant innovation,likelihood,outliers,score test,time series},
language = {en},
mendeley-tags = {Aberrant observation,aberrant innovation,likelihood,outliers,score test,time series},
month = mar,
number = {2},
pages = {109--119},
title = {{A Score Test for Detection of Time Series Outliers}},
url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-9892.1988.tb00458.x/abstract},
volume = {9},
year = {1988}
}
@book{Drosg2009,
abstract = {Dealing with Uncertainties is an innovative monograph that lays special emphasis on the deductive approach to uncertainties and on the shape of uncertainty distributions. This perspective has the potential for dealing with the uncertainty of a single data point and with sets of data that have different weights. It is shown that the inductive approach that is commonly used to estimate uncertainties is in fact not suitable for these two cases. The approach that is used to understand the nature of uncertainties is novel in that it is completely decoupled from measurements. Uncertainties which are the consequence of modern science provide a measure of confidence both in scientific data and in information in everyday life. Uncorrelated uncertainties and correlated uncertainties are fully covered and the weakness of using statistical weights in regression analysis is discussed. The text is abundantly illustrated with examples and includes more than 150 problems to help the reader master the subject.},
author = {Drosg, Manfred},
isbn = {9783642013843},
keywords = {Science / Physics / Mathematical \& Computational,Technology \& Engineering / Measurement},
language = {en},
mendeley-tags = {Science / Physics / Mathematical \& Computational,Technology \& Engineering / Measurement},
month = jul,
pages = {243},
publisher = {Springer},
shorttitle = {Dealing with Uncertainties},
title = {{Dealing with Uncertainties: A Guide to Error Analysis}},
url = {http://books.google.com/books?id=GhGAlryfy6cC},
year = {2009}
}
@article{Bates2008,
abstract = {This technical paper contains eight sections concerning the impacts of climate change on hydrological processes and regimes, and on the availability, quality, use and management of freshwater resources. It takes into account current and projected regional key vulnerabilities, prospects for adaptation, and the relationships between climate change mitigation and water. Following the introductory section, the next section is based primarily on the assessments of Working Group I, and looks at the science of climate change, both observed and projected, as it relates to hydrological variables. Section 3 presents a general overview of observed and projected water-related impacts of climate change, Working Group II assessments. Section 4 looks at systems and sectors in detail, and Section 5 takes a regional approach. Section 6, based on Working Group III assessments, covers water-related aspects of mitigation. Section 7 looks at the implications for policy and sustainable development, followed by the final section (Section 8) on gaps in knowledge and suggestions for future work.},
author = {Bates, B. and Kundzewicz, Z. W. and Wu, S. and Palutikof, J.},
journal = {IPCC Technical Paper VI},
language = {English},
pages = {x + 200 pp.},
title = {{Climate change and water.}},
year = {2008}
}
@article{John2000,
abstract = {The operation of a three compartment phosphate model of microalgal growth (phosphate interaction model, PIM), containing internal P pools for polyphosphate (PolyP), soluble inorganic P (SIP) and structural and other organic P (SOP), is compared with that of a conventional quota model which contains only a single internal nutrient pool. PIM enables a simulation of the decoupling of phosphate transport and assimilation and is thus more suitable for studies of short-term transient events and of transport kinetics. For general use, however, the quota model appears satisfactory provided that it has been parameterised using a full data set including cells grown under P-replete conditions in which PolyP can accumulate. This may not be the case for studies undertaken using steady-state P-limited chemostats, which will thus underestimate the value of the maximum value of the P:C quota. From the simulations it appears unwarranted to use a more complex model of P than the three pool PIM. Simulations using PIM indicate that, in addition to the well documented advantage in accumulating P over that required for immediate use, the accumulation of PolyP enables a better decoupling of transport from assimilation and hence the maintenance of high transport rates for longer. This would be of importance to organisms living in a transient nutrient regime and it may be important to simulate competition for P using such a model in ecosystem simulations.},
author = {John, Eurgain H. and Flynn, Kevin J.},
doi = {10.1016/S0304-3800(99)00178-7},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/ZRT23UA7/John and Flynn - 2000 - Modelling phosphate transport and assimilation in .pdf:pdf},
issn = {0304-3800},
journal = {Ecological Modelling},
keywords = {Growth dynamics,Model,Phosphate,Polyphosphate},
mendeley-tags = {Growth dynamics,Model,Phosphate,Polyphosphate},
month = jan,
number = {2–3},
pages = {145--157},
title = {{Modelling phosphate transport and assimilation in microalgae; how much complexity is warranted?}},
url = {http://www.sciencedirect.com/science/article/pii/S0304380099001787 http://www.sciencedirect.com/science/article/pii/S0304380099001787/pdfft?md5=53cdf148fe1ce0c95998d813ed44dd7e\&pid=1-s2.0-S0304380099001787-main.pdf},
volume = {125},
year = {2000}
}
@article{Matveev,
abstract = {A model, which describes contaminant transport in statistically homogeneous, disordered medium with sharply contrasting properties, is analyzed. At intermediate times, when there is no equilibrium between mobile and immobile contaminant fractions, the transport is described by a set of regimes of anomalous diffusion kind. At asymptotically large time, when equilibrium between the contaminant in mobile and immobile domains takes place, the classical regime of advection–dispersion occurs with transport constants depending on parameters of the medium. For this case a range of parameter values exist, for which the system behavior is not described by the conventional equilibrium sorption model for homogeneous media.},
author = {Matveev, L. V.},
doi = {10.1016/j.physa.2014.03.017},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/BRQPV6DQ/Matveev - Anomalous nonequilibrium transport simulations usi.pdf:pdf},
issn = {0378-4371},
journal = {Physica A: Statistical Mechanics and its Applications},
title = {{Anomalous nonequilibrium transport simulations using a model of statistically homogeneous fractured-porous medium}},
url = {http://www.sciencedirect.com/science/article/pii/S0378437114002118 http://www.sciencedirect.com/science/article/pii/S0378437114002118/pdfft?md5=2f30d79053848563586c2aafff4e5847\&pid=1-s2.0-S0378437114002118-main.pdf}
}
@article{Gharamti,
abstract = {The accuracy of groundwater flow and transport model predictions highly depends on our knowledge of subsurface physical parameters. Assimilation of contaminant concentration data from shallow dug wells could help improving model behavior, eventually resulting in better forecasts. In this paper, we propose a joint state-parameter estimation scheme which efficiently integrates a low-rank extended Kalman filtering technique, namely the Singular Evolutive Extended Kalman (SEEK) filter, with the prominent complex-step method (CSM). The SEEK filter avoids the prohibitive computational burden of the Extended Kalman filter by updating the forecast along the directions of error growth only, called filter correction directions. CSM is used within the SEEK filter to efficiently compute model derivatives with respect to the state and parameters along the filter correction directions. CSM is derived using complex Taylor expansion and is second order accurate. It is proven to guarantee accurate gradient computations with zero numerical round-off errors, but requires complexifying the numerical code. We perform twin-experiments to test the performance of the CSM-based SEEK for estimating the state and parameters of a subsurface contaminant transport model. We compare the efficiency and the accuracy of the proposed scheme with two standard finite difference-based SEEK filters as well as with the ensemble Kalman filter (EnKF). Assimilation results suggest that the use of the CSM in the context of the SEEK filter may provide up to 80\% more accurate solutions when compared to standard finite difference schemes and is competitive with the EnKF, even providing more accurate results in certain situations. We analyze the results based on two different observation strategies. We also discuss the complexification of the numerical code and show that this could be efficiently implemented in the context of subsurface flow models.},
author = {Gharamti, M. E. and Hoteit, I.},
doi = {10.1016/j.jhydrol.2013.12.004},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/MPVF68CW/S0022169413008913.html:html;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/JMJ6MFD9/Gharamti and Hoteit - Complex Step-based Low-Rank Extended Kalman Filter.pdf:pdf},
issn = {0022-1694},
journal = {Journal of Hydrology},
keywords = {Complex step approximation,Joint state-parameter estimation,Low-rank extended Kalman filtering,Subsurface contaminant transport},
mendeley-tags = {Complex step approximation,Joint state-parameter estimation,Low-rank extended Kalman filtering,Subsurface contaminant transport},
title = {{Complex Step-based Low-Rank Extended Kalman Filtering for State-Parameter Estimation in Subsurface Transport Models}},
url = {http://www.sciencedirect.com/science/article/pii/S0022169413008913 http://www.sciencedirect.com/science/article/pii/S0022169413008913/pdfft?md5=79eae4aa95afa31d0d6b4e70ed103e9b\&pid=1-s2.0-S0022169413008913-main.pdf}
}
@article{Agarwal2004,
author = {Agarwal, Harish and Renaud, John E. and Preston, Evan L. and Padmanabhan, Dhanesh},
journal = {Reliability Engineering \& System Safety},
number = {1},
pages = {281--294},
title = {{Uncertainty quantification using evidence theory in multidisciplinary design optimization}},
url = {http://www.sciencedirect.com/science/article/pii/S0951832004000663},
volume = {85},
year = {2004}
}
@book{Pearson2011,
abstract = {The recent dramatic rise in the number of public datasets available free from the Internet, coupled with the evolution of the Open Source software movement, which makes powerful analysis packages like R freely available, have greatly increased both the range of opportunities for exploratory data analysis and the variety of tools that support this type of analysis. This book will provide a thorough introduction to a useful subset of these analysis tools, illustrating what they are, what they do, and when and how they fail. Specific topics covered include descriptive characterizations like summary statistics (mean, median, standard deviation, MAD scale estimate), graphical techniques like boxplots and nonparametric density estimates, various forms of regression modeling (standard linear regression models, logistic regression, and highly robust techniques like least trimmed squares), and the recognition and treatment of important data anomalies like outliers and missing data. The unique combination of topics presented in this book separate it from any other book of its kind. Intended for use as an introductory textbook for an exploratory data analysis course or as self-study companion for professionals and graduate students, this book assumes familiarity with calculus and linear algebra, though no previous exposure to probability or statistics is required. Both simulation-based and real data examples are included, as are end-of-chapter exercises and both R code and datasets.},
author = {Pearson, Ronald K.},
isbn = {9780195089653},
keywords = {Business \& Economics / Statistics,Engineering,Mathematical statistics,Mathematical statistics/ Textbooks,Mathematics / Probability \& Statistics / General,Medical sciences,Science,Technology \& Engineering / Engineering (General)},
language = {en},
mendeley-tags = {Business \& Economics / Statistics,Engineering,Mathematical statistics,Mathematical statistics/ Textbooks,Mathematics / Probability \& Statistics / General,Medical sciences,Science,Technology \& Engineering / Engineering (General)},
month = jan,
pages = {798},
publisher = {Oxford University Press},
title = {{Exploring data in engineering, the sciences, and medicine}},
url = {http://books.google.com/books?id=nH4pAQAAMAAJ},
year = {2011}
}
@incollection{Michel2005a,
author = {Michel, R. L.},
booktitle = {Isotopes in the Water Cycle: Past, Present and Future of a Developing Science},
editor = {Aggarwal, Pradeep K. and Gat, Joel R. and Froehlich, Klaus F. O.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/976MSQND/Michel et al. - 2005 - Tritium in the Hydrologic Cycle.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/RRDZTH3H/Michel et al. - 2005 - Tritium in the Hydrologic Cycle.html:html},
isbn = {978-1-4020-3010-9, 978-1-4020-3023-9},
keywords = {Climate Change,Environmental Physics,Freshwater \& Marine Ecology,Hydrogeology,Waste Water Technology / Water Pollution Control /},
mendeley-tags = {Climate Change,Environmental Physics,Freshwater \& Marine Ecology,Hydrogeology,Waste Water Technology / Water Pollution Control /},
month = jan,
pages = {53--66},
publisher = {Springer Netherlands},
title = {{Tritium in the Hydrologic Cycle}},
url = {http://link.springer.com/chapter/10.1007/1-4020-3023-1\_5 http://link.springer.com/content/pdf/10.1007\%2F1-4020-3023-1\_5.pdf},
year = {2005}
}
@article{Mishali2007,
abstract = {We address the problem of reconstructing a multi-band signal from its sub-Nyquist point-wise samples. To date, all reconstruction methods proposed for this class of signals assumed knowledge of the band locations. In this paper, we develop a non-linear blind perfect reconstruction scheme for multi-band signals which does not require the band locations. Our approach assumes an existing blind multi-coset sampling method. The sparse structure of multi-band signals in the continuous frequency domain is used to replace the continuous reconstruction with a single finite dimensional problem without the need for discretization. The resulting problem can be formulated within the framework of compressed sensing, and thus can be solved efficiently using known tractable algorithms from this emerging area. We also develop a theoretical lower bound on the average sampling rate required for blind signal reconstruction, which is twice the minimal rate of known-spectrum recovery. Our method ensures perfect reconstruction for a wide class of signals sampled at the minimal rate. Numerical experiments are presented demonstrating blind sampling and reconstruction with minimal sampling rate.},
author = {Mishali, Moshe and Eldar, Yonina C.},
journal = {arXiv:0709.1563},
keywords = {Nonlinear Sciences - Cellular Automata and Lattice,Nonlinear Sciences - Exactly Solvable and Integrab},
mendeley-tags = {Nonlinear Sciences - Cellular Automata and Lattice,Nonlinear Sciences - Exactly Solvable and Integrab},
month = sep,
shorttitle = {Blind Multi-Band Signal Reconstruction},
title = {{Blind Multi-Band Signal Reconstruction: Compressed Sensing for Analog Signals}},
url = {http://arxiv.org/abs/0709.1563 http://www.arxiv.org/pdf/0709.1563.pdf},
year = {2007}
}
@article{Neumaier2012,
abstract = {The concept of DNA “repair centers” and the meaning of radiation-induced foci (RIF) in human cells have remained controversial. RIFs are characterized by the local recruitment of DNA damage sensing proteins such as p53 binding protein (53BP1). Here, we provide strong evidence for the existence of repair centers. We used live imaging and mathematical fitting of RIF kinetics to show that RIF induction rate increases with increasing radiation dose, whereas the rate at which RIFs disappear decreases. We show that multiple DNA double-strand breaks (DSBs) 1 to 2 $\mu$m apart can rapidly cluster into repair centers. Correcting mathematically for the dose dependence of induction/resolution rates, we observe an absolute RIF yield that is surprisingly much smaller at higher doses: 15 RIF/Gy after 2 Gy exposure compared to approximately 64 RIF/Gy after 0.1 Gy. Cumulative RIF counts from time lapse of 53BP1-GFP in human breast cells confirmed these results. The standard model currently in use applies a linear scale, extrapolating cancer risk from high doses to low doses of ionizing radiation. However, our discovery of DSB clustering over such large distances casts considerable doubts on the general assumption that risk to ionizing radiation is proportional to dose, and instead provides a mechanism that could more accurately address risk dose dependency of ionizing radiation.},
author = {Neumaier, Teresa and Swenson, Joel and Pham, Christopher and Polyzos, Aris and Lo, Alvin T. and Yang, PoAn and Dyball, Jane and Asaithamby, Aroumougame and Chen, David J. and Bissell, Mina J. and Thalhammer, Stefan and Costes, Sylvain V.},
doi = {10.1073/pnas.1117849108},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/QRSWCNIQ/Neumaier et al. - 2012 - Evidence for formation of DNA repair centers and d.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Folder - ch1},
mendeley-tags = {Folder - ch1},
month = jan,
number = {2},
pages = {443--448},
title = {{Evidence for formation of DNA repair centers and dose-response nonlinearity in human cells}},
url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3258602/ http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3258602/pdf/pnas.1117849108.pdf},
volume = {109},
year = {2012}
}
@incollection{Letcher2011f,
address = {Boston},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/NQ5886K2/Letcher and Vallero - 2011 - Frontmatter.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {iii},
publisher = {Academic Press},
title = {{Frontmatter}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100336 http://www.sciencedirect.com/science/article/pii/B9780123814753100336/pdfft?md5=e3db34be34f34cee2ba4480149182a10\&pid=3-s2.0-B9780123814753100336-main.pdf},
year = {2011}
}
@article{Schmid1996,
abstract = {Abstract.  In this paper an outlier test for contaminated autoregressive processes is introduced. The test is based on a comparison of each observation with a predictor using past and future values, a so-called two-sided predictor. It is required that an upper bound for the total number of outliers is known. The asymptotic distribution of the test statistic is calculated under the null hypothesis that no outlier is present. The behaviour of the test for finite sample size is investigated by a simulation study. Moreover, the test is compared with several other outlier tests.},
author = {Schmid, W.},
doi = {10.1111/j.1467-9892.1996.tb00290.x},
issn = {1467-9892},
journal = {Journal of Time Series Analysis},
keywords = {Outlier:time series:autoregressive process,multiple outlier problem:extreme sums},
language = {en},
mendeley-tags = {Outlier:time series:autoregressive process,multiple outlier problem:extreme sums},
month = sep,
number = {5},
pages = {497--510},
title = {{An Outlier Test for Time Series Based on a Two-Sided Predictor}},
url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-9892.1996.tb00290.x/abstract},
volume = {17},
year = {1996}
}
@incollection{Vallero2011g,
abstract = {Risk is a common metric for waste management. Societal expectations of acceptable risk are mandated by the standards and specifications of certifying authorities. Articulating the hazard (the agent of harm) is matched against the ways that people or other receptors may come into contact with that hazard, that is, exposure. Thus, risk management includes the policies, laws, and other societal endeavors that limit these two components of risk. From the hazard perspectives, regulatory agencies may decide that a product is too hazardous when it is manufactured, used, or when it becomes a waste product. Thus, the hazard may occur before a waste is generated, such as a component of a manufacturing process. Waste management success is a function of the amount of risk that has been reduced or avoided. Thus, the success of all waste operations is, to some extent, a reflection of the operation's hazards and potential exposures to these hazards. Decisions must be based on scientifically credible information. This information is part of the risk assessment that informs waste management decisions.},
address = {Boston},
author = {Vallero, Daniel A.},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/D6QCQZN5/Vallero - 2011 - Chapter 32 - Risk Assessment, Management, and Acco.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {503--540},
publisher = {Academic Press},
title = {{Chapter 32 - Risk Assessment, Management, and Accountability}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100324 http://www.sciencedirect.com/science/article/pii/B9780123814753100324/pdfft?md5=b06904f88d695b7da5b4b4e953503ca5\&pid=3-s2.0-B9780123814753100324-main.pdf},
year = {2011}
}
@inproceedings{Aggarwal2001,
address = {New York, NY, USA},
author = {Aggarwal, Charu C. and Yu, Philip S.},
doi = {10.1145/375663.375668},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/WSI3FH64/Aggarwal and Yu - 2001 - Outlier Detection for High Dimensional Data.pdf:pdf},
isbn = {1-58113-332-4},
pages = {37--46},
publisher = {ACM},
series = {SIGMOD '01},
title = {{Outlier Detection for High Dimensional Data}},
url = {http://doi.acm.org/10.1145/375663.375668 http://dl.acm.org/ft\_gateway.cfm?id=375668\&type=pdf},
year = {2001}
}
@article{Stigliani1991,
author = {Stigliani, William M. and Doelman, Peter and Salomons, Wim and Schulin, Rainer and Smidt, Gera R. B. and {Van der Zee}, Sjoerd E. A. T. M.},
doi = {10.1080/00139157.1991.9931383},
issn = {0013-9157, 1939-9154},
journal = {Environment: Science and Policy for Sustainable Development},
keywords = {Folder - ch1},
language = {en},
mendeley-tags = {Folder - ch1},
month = may,
number = {4},
pages = {4--30},
shorttitle = {Chemical Time Bombs},
title = {{Chemical Time Bombs: Predicting the Unpredictable}},
url = {http://www.tandfonline.com/doi/abs/10.1080/00139157.1991.9931383},
volume = {33},
year = {1991}
}
@article{Raick2006,
abstract = {Handling model complexity and reliability is a key area of research today. While complex models containing sufficient detail have become possible due to increased computing power, they often lead to too much uncertainty. On the other hand, very simple models often crudely oversimplify the real ecosystem and can not be used for management purposes. Starting from a complex and validated 1D pelagic ecosystem model of the Ligurian Sea (NW Mediterranean Sea), we derived simplified aggregated models in which either the unbalanced algal growth, the functional group diversity or the explicit description of the microbial loop was sacrificed. To overcome the problem of data availability with adequate spatial and temporal resolution, the outputs of the complex model are used as the baseline of perfect knowledge to calibrate the simplified models. Objective criteria of model performance were used to compare the simplified models’ results to the complex model output and to the available data at the DYFAMED station in the central Ligurian Sea. We show that even the simplest (NPZD) model is able to represent the global ecosystem features described by the complex model (e.g. primary and secondary productions, particulate organic matter export flux, etc.). However, a certain degree of sophistication in the formulation of some biogeochemical processes is required to produce realistic behaviors (e.g. the phytoplankton competition, the potential carbon or nitrogen limitation of the zooplankton ingestion, the model trophic closure, etc.). In general, a 9 state-variable model that has the functional group diversity removed, but which retains the bacterial loop and the unbalanced algal growth, performs best.},
author = {Raick, C. and Soetaert, K. and Gr\'{e}goire, M.},
doi = {10.1016/j.pocean.2006.03.001},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/QSD88NX6/Raick et al. - 2006 - Model complexity and performance How far can we s.pdf:pdf},
issn = {0079-6611},
journal = {Progress in Oceanography},
keywords = {Coupled hydrodynamic-ecosystem models,Criteria of model performance,Identifiability analysis,Model complexity reduction,NW Mediterranean Sea,model calibration},
mendeley-tags = {Coupled hydrodynamic-ecosystem models,Criteria of model performance,Identifiability analysis,Model complexity reduction,NW Mediterranean Sea,model calibration},
month = jul,
number = {1},
pages = {27--57},
shorttitle = {Model complexity and performance},
title = {{Model complexity and performance: How far can we simplify?}},
url = {http://www.sciencedirect.com/science/article/pii/S0079661106000188 http://www.sciencedirect.com/science/article/pii/S0079661106000188/pdfft?md5=77d51175f118bcd18c54658155562f50\&pid=1-s2.0-S0079661106000188-main.pdf},
volume = {70},
year = {2006}
}
@incollection{Blight2011a,
abstract = {Mine wastes and their environmentally acceptable storage constitute the largest waste problem on the planet. Mine wastes have been accumulating for thousands of years, and their rate of production has accelerated in step with increases of the human population to an estimated world-wide production rate of 350 × 109ta-1. If collected and spread in a uniform thickness, the waste could cover the 84 000 km2 area of Ireland to a depth of more than 2 metres.
The types and characteristics of mine wastes and the ways in which they are stored are described. Mine waste storages are dangerous structures in terms of associated accidental deaths and continuing environmental hazards. Situations leading to failure, types of failures and methods of preventing their occurrence and minimizing environmental damage are described with illustrative examples.
Mining activities produce larger quantities of waste and have more adverse environmental impacts than waste from any other human activity. This chapter outlines the subject of mine waste storage. Mine waste can be divided into coarse grained wastes that are usually stored in surface dumps, and fine-grained wastes, usually stored in hydraulic-fill structures. Both coarse and fine mine wastes could contain toxic substances, emit radioactive radon gas, or be combustible. Therefore, mine waste storages need to be constructed and protected in such a way that their adverse effects on human health and the natural environment are minimized on a long-term, continuing basis. Fortunately, controls and statutory regulations for the storage of mine waste are being tightened in most countries, and at the same time, the engineering skills needed to construct and maintain storages safely and for long periods of time are also improving. It is very important to realize that once amine waste storage has been created, it constitutes a hazard that requires ongoing maintenance and care for millennia to come.},
address = {Boston},
author = {Blight, Geoffrey},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/FS7KDBWD/Blight - 2011 - Chapter 5 - Mine Waste A Brief Overview of Origin.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {77--88},
publisher = {Academic Press},
shorttitle = {Chapter 5 - Mine Waste},
title = {{Chapter 5 - Mine Waste: A Brief Overview of Origins, Quantities, and Methods of Storage}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100051 http://www.sciencedirect.com/science/article/pii/B9780123814753100051/pdfft?md5=7aed2c3c313fa912b0f0be0085d7f4e0\&pid=3-s2.0-B9780123814753100051-main.pdf},
year = {2011}
}
@article{Shao1993,
abstract = {We consider the problem of selecting a model having the best predictive ability among a class of linear models. The popular leave-one-out cross-validation method, which is asymptotically equivalent to many other model selection methods such as the Akaike information criterion (AIC), the Cp, and the bootstrap, is asymptotically inconsistent in the sense that the probability of selecting the model with the best predictive ability does not converge to 1 as the total number of observations n → ∞. We show that the inconsistency of the leave-one-out cross-validation can be rectified by using a leave-n$\nu$-out cross-validation with n$\nu$, the number of observations reserved for validation, satisfying n$\nu$/n → 1 as n → ∞. This is a somewhat shocking discovery, because n$\nu$/n → 1 is totally opposite to the popular leave-one-out recipe in cross-validation. Motivations, justifications, and discussions of some practical aspects of the use of the leave-n$\nu$-out cross-validation method are provided, and results from a simulation study are presented.},
author = {Shao, Jun},
doi = {10.2307/2290328},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/K86T86ZC/Shao - 1993 - Linear Model Selection by Cross-Validation.pdf:pdf},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
month = jun,
number = {422},
pages = {486--494},
title = {{Linear Model Selection by Cross-Validation}},
url = {http://www.jstor.org/stable/2290328 http://www.jstor.org/stable/pdfplus/2290328.pdf?acceptTC=true},
volume = {88},
year = {1993}
}
@article{Wasserman2000,
abstract = {This paper reviews the Bayesian approach to model selection and model averaging. In this review, I emphasize objective Bayesian methods based on noninformative priors. I will also discuss implementation details, approximations, and relationships to other methods. Copyright 2000 Academic Press.},
author = {Wasserman, L},
doi = {10.1006/jmps.1999.1278},
issn = {0022-2496},
journal = {Journal of mathematical psychology},
keywords = {aic,bayes factors,bic,consistency,default bayes methods,markov chain monte carlo},
month = mar,
number = {1},
pages = {92--107},
pmid = {10733859},
title = {{Bayesian Model Selection and Model Averaging.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10733859},
volume = {44},
year = {2000}
}
@article{Liu2000483,
abstract = {
The generalized integral transform technique (GITT) is applied to solve the one-dimensional advection-dispersion equation (ADE) in heterogeneous porous media coupled with either linear or nonlinear sorption and decay. When both sorption and decay are linear, analytical solutions are obtained using the GITT for one-dimensional ADEs with spatially and temporally variable flow and dispersion coefficient and arbitrary initial and boundary conditions. When either sorption or decay is nonlinear the solutions to ADEs with the GITT are hybrid analytical-numerical. In both linear and nonlinear cases, the forward and inverse integral transforms for the problems described in the paper are apparent and straightforward. Some illustrative examples with linear sorption and decay are presented to demonstrate the application and check the accuracy of the derived analytical solutions. The derived hybrid analytical-numerical solutions are checked against a numerical approach and demonstratively applied to a nonlinear transport example, which simulates a simplified system of iron oxide bioreduction with nonlinear sorption and nonlinear reaction kinetics.},
annote = {        From Duplicate 1 (                           Use of the generalized integral transform method for solving equations of solute transport in porous media                         - Liu, Chongxuan; Szecsody, Jim E; Zachara, John M; Ball, William P )
                
        
        
      },
author = {Liu, Chongxuan and Szecsody, Jim E and Zachara, John M and Ball, William P.},
doi = {DOI: 10.1016/S0309-1708(99)00048-2},
issn = {0309-1708},
journal = {Advances in Water Resources},
month = feb,
number = {5},
pages = {483--492},
title = {{Use of the generalized integral transform method for solving equations of solute transport in porous media}},
url = {http://www.sciencedirect.com/science/article/B6VCF-3YMFH46-4/2/130ca2e462e2846193f0aeb1b4aba34c},
volume = {23},
year = {2000}
}
@article{Brooks1996,
abstract = {he lack of a methodology, or at least detailed guidelines, for choosing the best model in a mathematical or computer modelling study stems from a poor understanding of the precise ways in which the success of the study depends upon the particular model used. As a result, the choice of the best model is regarded as more of an art than a science. In order to improve the model selection process, model performance needs to be clearly defined, and suitable model attributes identified that can be used to predict the performance of the alternative candidate models. This paper distinguishes the different aspects of model performance and considers the extent to which they can be measured. The most common attributes used to compare alternative models are level of detail and complexity although these terms are used in a number of different ways. The meanings of these concepts are therefore discussed and the likely relationships with the model performance elements considered. The related area of simplification is reviewed and the areas in which further work is required are set out.},
author = {Brooks, R. J. and Tobias, A. M.},
doi = {10.1016/0895-7177(96)00103-3},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/4UNV8HWQ/Brooks and Tobias - 1996 - Choosing the best model Level of detail, complexi.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/9WVCKBJ6/Brooks and Tobias - 1996 - Choosing the best model Level of detail, complexi.pdf:pdf},
issn = {0895-7177},
journal = {Mathematical and Computer Modelling},
keywords = {Complexity,Level of detail,Model performance,Modelling methodology,Simplification},
mendeley-tags = {Complexity,Level of detail,Model performance,Modelling methodology,Simplification},
month = aug,
number = {4},
pages = {1--14},
shorttitle = {Choosing the best model},
title = {{Choosing the best model: Level of detail, complexity, and model performance}},
url = {http://www.sciencedirect.com/science/article/pii/0895717796001033 http://www.sciencedirect.com/science/article/pii/0895717796001033/pdf?md5=b06f78e4f3354b0393b24f65969bb8d2\&pid=1-s2.0-0895717796001033-main.pdf},
volume = {24},
year = {1996}
}
@article{Stuart2014,
abstract = {Abstract
Evaluating the occurrence of microorganics helps to understand sources and processes which may be controlling the transport and fate of emerging contaminants (ECs). A study was carried out at the contrasting instrumented environmental observatory sites at Oxford, on the peri-urban floodplain gravel aquifer of the River Thames and Boxford, in the rural valley of the River Lambourn on the chalk aquifer, in Southern England to explore the use of ECs to fingerprint contaminant sources and flow pathways in groundwater. At Oxford compounds were typical of a local waste tip plume (not only plasticisers and solvents but also barbiturates and N,N-diethyl-m-toluamide (DEET)) and of the urban area (plasticisers and mood-enhancing drugs such as carbamazepine). At Boxford the results were different with widespread occurrence of agricultural pesticides, their metabolites and the solvent trichloroethene, as well as plasticisers, caffeine, butylated food additives, DEET, parabens and trace polyaromatic hydrocarbons (PAHs). Groups of compounds used in pharmaceuticals and personal care products of different provenance in the environment could be distinguished, i) historical household and medical waste, ii) long-term household usage persistent in groundwater and iii) current usage and contamination from surface water. Co-contaminant and degradation products can also indicate the likely source of contaminants. A cocktail of contaminants can be used as tracers to provide information on catchment pathways and groundwater/surface water interactions. A prominent feature in this study is the attenuation of many EC compounds in the hyporheic zone.},
author = {Stuart, Marianne E. and Lapworth, Dan J. and Thomas, Jenny and Edwards, Laura},
doi = {10.1016/j.scitotenv.2013.08.042},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/H6UAZNTT/Stuart et al. - 2014 - Fingerprinting groundwater pollution in catchments.html:html;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/VTSU6WKN/Stuart et al. - 2014 - Fingerprinting groundwater pollution in catchments.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/VZ9Q6RU9/Stuart et al. - 2014 - Fingerprinting groundwater pollution in catchments.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/ZX5SD73T/Stuart et al. - 2014 - Fingerprinting groundwater pollution in catchments.html:html},
issn = {0048-9697},
journal = {Science of The Total Environment},
keywords = {Floodplain,Hyporheic zone,Peri-urban,Pesticides,Pharmaceuticals,Plasticisers},
mendeley-tags = {Floodplain,Hyporheic zone,Peri-urban,Pesticides,Pharmaceuticals,Plasticisers},
month = jan,
pages = {564--577},
title = {{Fingerprinting groundwater pollution in catchments with contrasting contaminant sources using microorganic compounds}},
url = {http://www.sciencedirect.com/science/article/pii/S004896971300956X http://www.sciencedirect.com/science/article/pii/S004896971300956X/pdfft?md5=cdbd1d3a424c36d63cbec69b2728a94d\&pid=1-s2.0-S004896971300956X-main.pdf},
volume = {468–469},
year = {2014}
}
@book{SubsurfaceNRC2004,
abstract = {At hundreds of thousands of commercial, industrial, and military sites across the country, subsurface materials including groundwater are contaminated with chemical waste. The last decade has seen growing interest in using aggressive source remediation technologies to remove contaminants from the subsurface, but there is limited understanding of (1) the effectiveness of these technologies and (2) the overall effect of mass removal on groundwater quality. This report reviews the suite of technologies available for source remediation and their ability to reach a variety of cleanup goals, from meeting regulatory standards for groundwater to reducing costs. The report proposes elements ...},
address = {Washington, D.C.},
author = {{National Research Council}},
shorttitle = {Contaminants in the Subsurface},
title = {{Contaminants in the Subsurface: Source Zone Assessment and Remediation Assessment}},
url = {http://www.nap.edu/catalog.php?record\_id=11146},
year = {2004}
}
@article{Bloschl2007,
author = {Bl\"{o}schl, G\"{u}nter and Ardoin-Bardin, Sandra and Bonell, Mike and Dorninger, Manfred and Goodrich, David C. and Gutknecht, Dieter and Matamoros, David and Merz, Bruno and Shand, Paul and Szolgay, Jan},
journal = {Hydrological Processes},
number = {9},
pages = {1241--1247},
title = {{At what scales do climate variability and land cover change impact on flooding and low flows?}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/hyp.6669/abstract http://edoc.gfz-potsdam.de/gfz/get/10139/0/408c6b3a7a38eff6e16fc41b319bcdf6/10139.pdf},
volume = {21},
year = {2007}
}
@book{Smith2013,
author = {Smith, Ralph C.},
publisher = {SIAM},
shorttitle = {Uncertainty Quantification},
title = {{Uncertainty Quantification: Theory, Implementation, and Applications}},
url = {http://books.google.com/books?hl=en\&lr=\&id=4c1GAgAAQBAJ\&oi=fnd\&pg=PR9\&dq=Uncertainty+Quantification:+Theory,+Implementation,+and+Applications\&ots=Fz-R9fFPG3\&sig=eQ721JbiYY6SNICcqgga84qOxdA},
volume = {12},
year = {2013}
}
@article{MacKinnon1985,
abstract = {We examine several modified versions of the heteroskedasticity-consistent covariance matrix estimator of Hinkley (1977) and White (1980). On the basis of sampling experiments which compare the performance of quasi t-statistics, we find that one estimator, based on the jackknife, performs better in small samples than the rest. We also examine the finite-sample properties of using modified critical values based on Edgeworth approximations, as proposed by Rothenberg (1984). In addition, we compare the power of several tests for heteroskedasticity, and find that it may be wise to employ the jackknife heteroskedasticity-consistent covariance matrix even in the absence of detected heteroskedasticity.},
author = {MacKinnon, James G and White, Halbert},
doi = {10.1016/0304-4076(85)90158-7},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/ETPNSX4W/MacKinnon and White - 1985 - Some heteroskedasticity-consistent covariance matr.html:html;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/GFF9R9UF/MacKinnon and White - 1985 - Some heteroskedasticity-consistent covariance matr.html:html;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/HS3DJBN7/MacKinnon and White - 1985 - Some heteroskedasticity-consistent covariance matr.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/KRRBBD4V/MacKinnon and White - 1985 - Some heteroskedasticity-consistent covariance matr.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/RQ8KWU9A/MacKinnon and White - 1985 - Some heteroskedasticity-consistent covariance matr.html:html;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/XKRB8Z2P/MacKinnon and White - 1985 - Some heteroskedasticity-consistent covariance matr.pdf:pdf},
issn = {0304-4076},
journal = {Journal of Econometrics},
month = sep,
number = {3},
pages = {305--325},
title = {{Some heteroskedasticity-consistent covariance matrix estimators with improved finite sample properties}},
url = {http://www.sciencedirect.com/science/article/pii/0304407685901587 http://www.sciencedirect.com/science/article/pii/0304407685901587/pdf?md5=3699e644616ccc750b6906e6d52bb3c6\&pid=1-s2.0-0304407685901587-main.pdf},
volume = {29},
year = {1985}
}
@article{Rinaldo1992,
author = {Rinaldo, Andrea and Rodriguez-Iturbe, Ignacio and Rigon, Riccardo and Bras, Rafael L. and Ijjasz-Vasquez, Ede and Marani, Alessandro},
doi = {10.1029/92WR00801},
issn = {00431397},
journal = {Water Resources Research},
month = sep,
number = {9},
pages = {2183--2195},
title = {{Minimum energy and fractal structures of drainage networks}},
url = {http://doi.wiley.com/10.1029/92WR00801},
volume = {28},
year = {1992}
}
@article{Black2014,
author = {Black, E. and Buesseler, K. O.},
doi = {10.5194/bgd-11-7235-2014},
issn = {1810-6285},
journal = {Biogeosciences Discussions},
language = {en},
month = may,
number = {5},
pages = {7235--7271},
title = {{Spatial variability and the fate of cesium in coastal sediments near Fukushima, Japan}},
url = {http://www.biogeosciences-discuss.net/11/7235/2014/},
volume = {11},
year = {2014}
}
@article{Teng2011,
abstract = {In order to measure groundwater age and design nuclear waste disposal sites, it is important to understand the sorption behavior of tritium on soils. In this study, batch tests were carried out using four soils from China: silty clays from An County and Jiangyou County in Sichuan Province, both of which could be considered candidate sites for Very Low Level Waste disposal; silty sand from Beijing; and loess from Yuci County in Shanxi Province, a typical Chinese loess region. The experimental results indicated that in these soil media, the distribution coefficient of tritium is slightly influenced by adsorption time, water/solid ratio, initial tritium specific activity, pH, and the content of humic and fulvic acids. The average distribution coefficient from all of these influencing factors was about 0.1-0.2 mL/g for the four types of soil samples. This relatively modest sorption of tritium in soils needs to be considered in fate and transport studies of tritium in the environment.},
author = {Teng, Yanguo and Zuo, Rui and Wang, Jinsheng and Hu, Qinhong and Sun, Zongjian and Zeng, Ni},
doi = {10.1016/j.jenvrad.2010.12.002},
issn = {1879-1700},
journal = {Journal of environmental radioactivity},
keywords = {Adsorption,Benzopyrans,Benzopyrans: analysis,China,Humic Substances,Humic Substances: analysis,Hydrogen-Ion Concentration,Radiation Monitoring,Radiation Monitoring: methods,Radioactive Tracers,Soil,Soil: chemistry,Time Factors,Tritium,Tritium: analysis,Water,Water: analysis,X-Ray Diffraction},
month = feb,
number = {2},
pages = {212--6},
pmid = {21194813},
publisher = {Elsevier Ltd},
title = {{Detection of tritium sorption on four soil materials.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21194813},
volume = {102},
year = {2011}
}
@incollection{Butler2011,
abstract = {The global glass production in 2007 was approximately 135 million tonnes, of which container and flat glass glass accounted for 72 and 44 million tonnes respectively. The main environmental impacts from producing glass products are the high energy use in batch melting and resulting gaseous emissions. Whilst glass container re-use and closed loop recycling have their own environmental burdens, they can nevertheless significantly reduce energy use and resultant emissions. A comparison of global consumption and recycling volumes demonstrates a potential reduction of 54 × 106 GJ in energy use and 8.3 × 106 t a-1 CO2 emissions based on an 80\% overall global recycling rate, compared with the rate achieved in 2007. The core challenge in realising this potential is the maintenance and enhancement of recycling infrastructures to produce high quality manufacturing ready cullet, combined with a balanced demand from closed loop production facilities.
This chapter explores the environmental issues arising from glass production and consumption. Glass is in the background of the daily lives of most people. The potential for glass recycling comes largely from the container and flat glass sectors, because of their dominance in terms of mass, and their relatively uniform chemical composition, with soda lime–silica glass accounting for virtually all the container and flat glass produced. The main environmental impacts in glass making are the high-energy use in batch melting, and the resultant gaseous emissions from fuel combustion and the heat reaction of components of the batch mix. The core challenge for environmentally and cost-effective recycling of container glass arises from the dispersed nature of its sources, principally households, and the consequent need for an environmentally and cost-effective infrastructure providing for its color separation, collection, and transportation to processors to produce furnace ready feedstock. In assessing the scope for increasing the amount of glass recycled, there is an overall need to quantify the resultant energy and other environmental burdens to allow valid comparisons to be made with the burdens of using virgin feedstock.},
address = {Boston},
author = {Butler, John H. and Hooper, Paul},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/C6NMKVJD/Butler and Hooper - 2011 - Chapter 11 - Glass Waste.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {151--165},
publisher = {Academic Press},
title = {{Chapter 11 - Glass Waste}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100117 http://www.sciencedirect.com/science/article/pii/B9780123814753100117/pdfft?md5=109b1d30f77f1d911ca70f84e3d5a34f\&pid=3-s2.0-B9780123814753100117-main.pdf},
year = {2011}
}
@article{P.Ellner2002,
abstract = {Testing for nonindependence among the residuals from a regression or time series model is a common approach to evaluating the adequacy of a fitted model. This idea underlies the familiar Durbin–Watson statistic, and previous works illustrate how the spatial autocorrelation among residuals can be used to test a candidate linear model. We propose here that a version of Moran's I statistic for spatial autocorrelation, applied to residuals from a fitted model, is a practical general tool for selecting model complexity under the assumption of iid additive errors. The “space” is defined by the independent variables, and the presence of significant spatial autocorrelation in residuals is evidence that a more complex model is needed to capture all of the structure in the data. An advantage of this approach is its generality, which results from the fact that no properties of the fitted model are used other than consistency. The problem of smoothing parameter selection in nonparametric regression is used to illustrate the performance of model selection based on residual spatial autocorrelation (RSA). In simulation trials comparing RSA with established selection criteria based on minimizing mean square prediction error, smooths selected by RSA exhibit fewer spurious features such as minima and maxima. In some cases, at higher noise levels, RSA smooths achieved a lower average mean square error than smooths selected by GCV. We also briefly describe a possible modification of the method for non-iid errors having short-range correlations, for example, time-series errors or spatial data. Some other potential applications are suggested, including variable selection in regression models.},
author = {P.Ellner, Stephen and Seifu, Yodit},
doi = {10.1198/106186002760180554},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/2EN9K99S/P.Ellner and Seifu - 2002 - Using Spatial Statistics to Select Model Complexit.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/7SUQ2CGX/P.Ellner and Seifu - 2002 - Using Spatial Statistics to Select Model Complexit.pdf:pdf},
issn = {1061-8600},
journal = {Journal of Computational and Graphical Statistics},
number = {2},
pages = {348--369},
title = {{Using Spatial Statistics to Select Model Complexity}},
url = {http://dx.doi.org/10.1198/106186002760180554 http://www.tandfonline.com/doi/pdf/10.1198/106186002760180554},
volume = {11},
year = {2002}
}
@article{Ma2014a,
abstract = {This paper presents the results of a comprehensive model-based analysis of a uranyl [U(VI)] tracer test conducted at the U.S. DOE Hanford 300 Area (300A) IFRC. Despite the highly complex field conditions the numerical three-dimensional multi-component reactive transport model was able to capture most of the spatiotemporal variations of the observed U(VI) concentrations. A multi-model analysis was performed to interrogate the relative importance of various processes and factors for controlling field-scale reactive transport during the uranyl tracer test. The results indicate that multi-rate sorption/desorption, surface complexation reactions, and initial concentrations were the most important processes and factors controlling U(VI) migration. On the other hand, cation exchange reactions, the choice of the surface complexation model, and dual-domain mass transfer processes played less important roles under the prevailing field-test condition. Further analysis of the modeling results demonstrates that these findings are conditioned to the relatively stable groundwater chemistry and the selected length of the field experimental duration (16 days). The model analysis also revealed the crucial role of the intraborehole flow that occurred within the long-screened monitoring wells and thus affected both field measurements and simulated U(VI) concentrations as a combined effect of aquifer heterogeneity and dynamic flow conditions. This study provides the first highly data-constrained uranium transport simulations under highly dynamic flow conditions. It illustrates the value of reactive transport modeling for elucidating the relative importance of individual processes in controlling uranium transport under specific field-scale conditions.},
author = {Ma, Rui and Zheng, Chunmiao and Liu, Chongxuan and Greskowiak, Janek and Prommer, Henning and Zachara, John M.},
doi = {10.1002/2013WR013835},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/JBV4JHX3/abstract.html:html},
issn = {1944-7973},
journal = {Water Resources Research},
keywords = {Hanford 300 Area IFRC site,Reactive Transport Modeling,Uranium,aquifer heterogeneity,field scale model},
language = {en},
mendeley-tags = {Hanford 300 Area IFRC site,Reactive Transport Modeling,Uranium,aquifer heterogeneity,field scale model},
pages = {n/a--n/a},
title = {{Assessment of controlling processes for field-scale uranium reactive transport under highly transient flow conditions}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/2013WR013835/abstract},
year = {2014}
}
@article{Wood1990,
author = {Wood, Eric F. and Sivapalan, Murugesu and Beven, Keith J.},
journal = {Reviews of Geophysics},
number = {1},
pages = {1--18},
title = {{Similarity and scale in catchment storm response}},
volume = {28},
year = {1990}
}
@article{ElGhaoui1997,
author = {{El Ghaoui}, Laurent and Lebret, Herv\'{e}},
journal = {SIAM Journal on Matrix Analysis and Applications},
number = {4},
pages = {1035--1064},
title = {{Robust solutions to least-squares problems with uncertain data}},
url = {http://epubs.siam.org/doi/abs/10.1137/S0895479896298130},
volume = {18},
year = {1997}
}
@article{Sivapalan2003b,
annote = {        From Duplicate 1 (                   Process complexity at hillslope scale, process simplicity at the watershed scale: is there a connection?                 - Sivapalan, Murugesu )
                
        
        
      },
author = {Sivapalan, Murugesu},
doi = {10.1002/hyp.5109},
issn = {0885-6087},
journal = {Hydrological Processes},
month = apr,
number = {5},
pages = {1037--1041},
title = {{Process complexity at hillslope scale, process simplicity at the watershed scale: is there a connection?}},
url = {http://doi.wiley.com/10.1002/hyp.5109},
volume = {17},
year = {2003}
}
@article{Lawrie2007,
abstract = {Ecosystem models help us understand the mechanisms that influence ecosystem health indicators. However, if they are too complex, these mechanisms can be difficult to identify. On the other hand, if they are too simple the mechanisms may be distorted or even absent. Determining an appropriate level of model complexity is therefore desirable. This paper introduces two model simplification methods that are based on the sensitivity of performance measures to model rates and components. The first method identifies rates that have little influence on the performance measures and subsequently eliminates them. The second identifies, for a given performance measure, state variables that can be made constant. The methods can be implemented automatically, so that familiarity with the model is not required a priori. Demonstrating with a biogeochemical model of Port Phillip Bay, Australia, we find that significant reduction in model complexity is possible, including reductions in model order. Also, the process of implementing the methods reveals insights into the system that were not obvious beforehand.},
author = {Lawrie, Jock and Hearne, John},
doi = {10.1016/j.ecolmodel.2007.04.013},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/437M7DTD/Lawrie and Hearne - 2007 - Reducing model complexity via output sensitivity.pdf:pdf},
issn = {0304-3800},
journal = {Ecological Modelling},
keywords = {Complexity,Eliminating rates,Large ecosystem models,Model order reduction,Simplifying state equations},
mendeley-tags = {Complexity,Eliminating rates,Large ecosystem models,Model order reduction,Simplifying state equations},
month = oct,
number = {2–4},
pages = {137--144},
title = {{Reducing model complexity via output sensitivity}},
url = {http://www.sciencedirect.com/science/article/pii/S0304380007002372 http://www.sciencedirect.com/science/article/pii/S0304380007002372/pdfft?md5=dc95d202d406ff938af268664318abe4\&pid=1-s2.0-S0304380007002372-main.pdf},
volume = {207},
year = {2007}
}
@article{Gluzman2006,
abstract = {A method is suggested allowing for the improvement of accuracy of self-similar factor and root approximants, constructed from asymptotic series. The method is based on performing a power transforms of the given asymptotic series, with the power of this transformation being a control function. The latter is defined by a fixed-point condition, which improves the convergence of the sequence of the resulting approximants. The method makes it possible to extrapolate the behaviour of a function, given as an expansion over a small variable, to the region of the large values of this variable. Several examples illustrate the effectiveness of the method},
author = {Gluzman, S. and Yukalov, V. I.},
doi = {10.1007/s10910-005-9003-7},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/IW4SAZNF/Gluzman and Yukalov - 2006 - Self-similar power transforms in extrapolation pro.pdf:pdf},
issn = {0259-9791, 1572-8897},
journal = {Journal of Mathematical Chemistry},
keywords = {40A05,40A25,40A30,40G99,40H05,41A05,Math. Applications in Chemistry,Physical Chemistry,Theoretical and Computational Chemistry,computational methods,extrapolation methods,power series,resummation and renormalization methods,self-similar approximants},
language = {en},
mendeley-tags = {40A05,40A25,40A30,40G99,40H05,41A05,Math. Applications in Chemistry,Physical Chemistry,Theoretical and Computational Chemistry,computational methods,extrapolation methods,power series,resummation and renormalization methods,self-similar approximants},
month = jan,
number = {1},
pages = {47--56},
title = {{Self-similar power transforms in extrapolation problems}},
url = {http://link.springer.com/article/10.1007/s10910-005-9003-7 http://link.springer.com/content/pdf/10.1007\%2Fs10910-005-9003-7.pdf},
volume = {39},
year = {2006}
}
@article{Doherty2011a,
author = {Doherty, John and Christensen, Steen},
doi = {10.1029/2011WR010763},
issn = {00431397},
journal = {Water Resources Research},
keywords = {http://dx.doi.org/10.1029/2011WR010763, doi:10.102},
month = dec,
number = {12},
pages = {n/a--n/a},
title = {{Use of paired simple and complex models to reduce predictive bias and quantify uncertainty}},
url = {http://doi.wiley.com/10.1029/2011WR010763},
volume = {47},
year = {2011}
}
@article{Wehrera,
abstract = {Abstract 
Release of contaminants from non-aqueous phase liquids (NAPLs) is often limited by the dynamic exchange with aqueous solutions governed by a priori unknown kinetic laws. Release experiments require a thorough evaluation of the potential and limitations of kinetic models to reveal release processes. In this study, we investigated the characteristic concentration-time profiles of various models for the release of contaminants from an organic phase into an aqueous solution under no flow conditions. Criteria have been tested that allow for distinction of a first order one domain, a first order two domain, a spherical diffusion model, a spherical diffusion model with a time variable diffusion coefficient, a model for diffusion in a sphere with organic film, and a model for diffusion in a sphere with an aqueous film. The results can serve to evaluate the processes potentially governing release of organic contaminants from non-aqueous liquid phases.},
author = {Wehrer, Markus and Mai, Juliane and Attinger, Sabine and Totsche, Kai U.},
doi = {10.1016/j.envpol.2013.04.029},
issn = {0269-7491},
journal = {Environmental Pollution},
keywords = {Contaminant release,Dual domain,First order kinetics,NAPL,Spherical film diffusion},
mendeley-tags = {Contaminant release,Dual domain,First order kinetics,NAPL,Spherical film diffusion},
title = {{Kinetic control of contaminant release from NAPLs – Information potential of concentration time profiles}},
url = {http://www.sciencedirect.com/science/article/pii/S0269749113002303 http://www.sciencedirect.com/science?\_ob=MiamiImageURL\&\_cid=271833\&\_user=4420\&\_pii=S0269749113002303\&\_check=y\&\_origin=article\&\_zone=toolbar\&\_coverDate=2013-May-18\&view=c\&originContentFamily=serial\&wchp=dGLbVBA-zSkWz\&md5=67e73221fff5f52dcd1403f0d63cd865\&pid=1-s2.0-S0269749113002303-main.pdf}
}
@article{Hodge2004,
abstract = {Outlier detection has been used for centuries to detect and, where appropriate, remove anomalous observations from data. Outliers arise due to mechanical faults, changes in system behaviour, fraudulent behaviour, human error, instrument error or simply through natural deviations in populations. Their detection can identify system faults and fraud before they escalate with potentially catastrophic consequences. It can identify errors and remove their contaminating effect on the data set and as such to purify the data for processing. The original outlier detection methods were arbitrary but now, principled and systematic techniques are used, drawn from the full gamut of Computer Science and Statistics. In this paper, we introduce a survey of contemporary techniques for outlier detection. We identify their respective motivations and distinguish their advantages and disadvantages in a comparative review.},
author = {Hodge, Victoria J. and Austin, Jim},
doi = {10.1007/s10462-004-4304-y},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/NIQ5AWCK/Hodge and Austin - 2004 - A Survey of Outlier Detection Methodologies.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/WD79KB7S/s10462-004-4304-y.html:html},
issn = {0269-2821, 1573-7462},
journal = {Artificial Intelligence Review},
keywords = {Artificial Intelligence (incl. Robotics),Computer Science- general,Nonlinear Dynamics- Complex Systems- Chaos- Neural,anomaly,detection,deviation,noise,novelty,outlier,recognition},
language = {en},
mendeley-tags = {Artificial Intelligence (incl. Robotics),Computer Science- general,Nonlinear Dynamics- Complex Systems- Chaos- Neural,anomaly,detection,deviation,noise,novelty,outlier,recognition},
month = oct,
number = {2},
pages = {85--126},
title = {{A Survey of Outlier Detection Methodologies}},
url = {http://link.springer.com/article/10.1007/s10462-004-4304-y http://link.springer.com/content/pdf/10.1007\%2Fs10462-004-4304-y.pdf},
volume = {22},
year = {2004}
}
@incollection{Letcher2011g,
address = {Boston},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/CWKMABET/Letcher and Vallero - 2011 - Introduction.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/MIJ66DH4/Letcher and Vallero - 2011 - Introduction.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/RVWJGUJW/Letcher and Vallero - 2011 - Introduction.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {467},
publisher = {Academic Press},
title = {{Introduction}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100415 http://www.sciencedirect.com/science/article/pii/B9780123814753100415/pdfft?md5=80d0c518e60d8a65e6e1b76a303a3a7a\&pid=3-s2.0-B9780123814753100415-main.pdf http://www.sciencedirect.com/science/article/pii/B9780123814753100427 http://www.sciencedirect.com/science/article/pii/B9780123814753100427/pdfft?md5=1253e20cf8ae352be1a70c5d34fe65c9\&pid=3-s2.0-B9780123814753100427-main.pdf http://www.sciencedirect.com/science/article/pii/B97},
year = {2011}
}
@article{Sun1998,
abstract = {In this paper we compare MWRCK, a cokriging method, with LSZ, a Bayesian alternative. We test the methods for using the monthly NO3 and SO4 levels observed from 1983 to 1986 at 45 sites over the conterminous United States. Our simulation study suggests the LSZ predictor yields smaller overall mean squared prediction error than the MWRCK method, although these MSPE values are close. Since the LSZ method incorporates model uncertainty, it has an almost correct coverage probability. We find that the MWRCK method yields a low coverage probability. © 1998 John Wiley \& Sons, Ltd.},
author = {Sun, Weimin},
doi = {10.1002/(SICI)1099-095X(199807/08)9:4<445::AID-ENV314>3.0.CO;2-G},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/8ER9QRM7/Sun - 1998 - Comparison of a cokriging method with a Bayesian a.pdf:pdf},
issn = {1099-095X},
journal = {Environmetrics},
keywords = {Bayesian multivariate interpolation,cokriging,cross-validation,kriging,spatial prediction},
language = {en},
mendeley-tags = {Bayesian multivariate interpolation,cokriging,cross-validation,kriging,spatial prediction},
month = jul,
number = {4},
pages = {445--457},
title = {{Comparison of a cokriging method with a Bayesian alternative}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/(SICI)1099-095X(199807/08)9:4<445::AID-ENV314>3.0.CO;2-G/abstract http://onlinelibrary.wiley.com/store/10.1002/(SICI)1099-095X(199807/08)9:4<445::AID-ENV314>3.0.CO;2-G/asset/314\_ftp.pdf?v=1\&t=hva461fx\&s=0eeebe071900a34fcbece2679edfed52aa5c5b3d},
volume = {9},
year = {1998}
}
@incollection{Letcher2011c,
address = {Boston},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/GMGPCCX7/Letcher and Vallero - 2011 - Prologue.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {xiv--xvi},
publisher = {Academic Press},
title = {{Prologue}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100361 http://www.sciencedirect.com/science/article/pii/B9780123814753100361/pdfft?md5=becf2679b41d1229fe36f238af6f80a0\&pid=3-s2.0-B9780123814753100361-main.pdf},
year = {2011}
}
@article{Colten1991,
abstract = {Reconstructing the progression of geographical understanding has an important role in current environmental litigation. Determining damages for past contamination of groundwater by surface discharges of hazardous substances requires knowledge of developments in groundwater hydrology. A review of the scientific literature on the motion of subsurface fluids, public health, and sanitary engineering indicates that by 1940 knowledge was sufficient to argue against surface discharges of harmful fluids. Legal precedent, though inconsistent, proved there was ample awareness of the physical processes and financial liabilities before 1950 to expect careful disposal of liquid wastes to a land surface.},
author = {Colten, Craig E.},
issn = {0016-7428},
journal = {Geographical Review},
month = apr,
number = {2},
pages = {215--228},
title = {{A Historical Perspective on Industrial Wastes and Groundwater Contamination}},
url = {http://www.jstor.org/stable/215985 http://www.jstor.org/stable/pdfplus/215985.pdf?acceptTC=true},
volume = {81},
year = {1991}
}
@article{Beven1989,
abstract = {This paper argues that there are fundamental problems in the application of physically-based models for practical prediction in hydrology. These problems result from limitations of the model equations relative to a heterogeneous reality; the lack of a theory of subgrid scale integration; practical constraints on solution methodologies; and problems of dimensionality in parameter calibration. It is suggested that most current applications of physically-based models use them as lumped conceptual models at the grid scale. Recent papers on physically-based models have misunderstood and misrepresented these limitations. There are practical hydrological problems requiring physically-based predictions, and there will continue to be a need for physically-based models but ideas about their capabilities must change so that future applications attempt to obtain realistic estimates of the uncertainty associated with their predictions, particularly in the case of evaluating future scenarios of the effects of management strategies.},
annote = {        From Duplicate 2 (                   Changing ideas in hydrology — The case of physically-based models                 - Beven, Keith )
                
        
        
      },
author = {Beven, Keith J.},
doi = {10.1016/0022-1694(89)90101-7},
issn = {00221694},
journal = {Journal of Hydrology},
month = jan,
number = {1-2},
pages = {157--172},
title = {{Changing ideas in hydrology -- The case of physically-based models}},
url = {http://dx.doi.org/10.1016/0022-1694(89)90101-7},
volume = {105},
year = {1989}
}
@article{Warren2010,
abstract = {Maxent, one of the most commonly used methods for inferring species distributions and environmental tolerances from occurrence data, allows users to fit models of arbitrary complexity. Model complexity is typically constrained via a process known as L1 regularization, but at present little guidance is available for setting the appropriate level of regularization, and the effects of inappropriately complex or simple models are largely unknown. In this study, we demonstrate the use of information criterion approaches to setting regularization in Maxent, and we compare models selected using information criteria to models selected using other criteria that are common in the literature. We evaluate model performance using occurrence data generated from a known “true” initial Maxent model, using several different metrics for model quality and transferability. We demonstrate that models that are inappropriately complex or inappropriately simple show reduced ability to infer habitat quality, reduced ability to infer the relative importance of variables in constraining species' distributions, and reduced transferability to other time periods. We also demonstrate that information criteria may offer significant advantages over the methods commonly used in the literature.},
author = {Warren, Dan L. and Seifert, Stephanie N.},
doi = {10.1890/10-1171.1},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/6CERJG4A/Warren and Seifert - 2010 - Ecological niche modeling in Maxent the importanc.pdf:pdf},
issn = {1051-0761},
journal = {Ecological Applications},
month = aug,
number = {2},
pages = {335--342},
shorttitle = {Ecological niche modeling in Maxent},
title = {{Ecological niche modeling in Maxent: the importance of model complexity and the performance of model selection criteria}},
url = {http://www.esajournals.org/doi/abs/10.1890/10-1171.1 http://www.esajournals.org/doi/pdf/10.1890/10-1171.1},
volume = {21},
year = {2010}
}
@article{Chkrebtii2013,
abstract = {We develop a fully Bayesian inferential framework to quantify uncertainty in models defined by general systems of analytically intractable differential equations. This approach provides a statistical alternative to deterministic numerical integration for estimation of complex dynamic systems, and probabilistically characterises the solution uncertainty introduced when models are chaotic, ill-conditioned, or contain unmodelled functional uncertainty. Viewing solution estimation as an inference problem allows us to quantify numerical uncertainty using the tools of Bayesian function estimation, which may then be propagated through to uncertainty in the model parameters and subsequent predictions. We incorporate regularity assumptions by modelling system states in a Hilbert space with Gaussian measure, and through iterative model-based sampling we obtain a posterior measure on the space of possible solutions, rather than a single deterministic numerical solution that approximately satisfies model dynamics. We prove some useful properties of this probabilistic solution, propose efficient computational implementation, and demonstrate the methodology on a wide range of challenging forward and inverse problems. Finally, we incorporate the approach into a fully Bayesian framework for state and parameter inference from incomplete observations of the states. Our approach is successfully demonstrated on ordinary and partial differential equation models with chaotic dynamics, ill-conditioned mixed boundary value problems, and an example characterising parameter and state uncertainty in a biochemical signalling pathway which incorporates a nonlinear delay-feedback mechanism.},
annote = {Comment: 29 pages},
author = {Chkrebtii, Oksana and Campbell, David A. and Girolami, Mark A. and Calderhead, Ben},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/MQ8SR96R/Chkrebtii et al. - 2013 - Bayesian Uncertainty Quantification for Differenti.pdf:pdf},
journal = {arXiv:1306.2365 [stat]},
keywords = {Statistics - Methodology},
mendeley-tags = {Statistics - Methodology},
month = jun,
title = {{Bayesian Uncertainty Quantification for Differential Equations}},
url = {http://arxiv.org/abs/1306.2365 http://www.arxiv.org/pdf/1306.2365.pdf},
year = {2013}
}
@article{Srzic2013,
abstract = {In this paper we study the influence of high log-conductivity variance ($\sigma$Y2) and local scale dispersion on the first two concentration moments as well as on higher order moments, skewness and kurtosis, in a two-dimensional heterogeneous aquifer. Three different heterogeneity structures are considered, defined with one and the same global isotropic Gaussian variogram. The three structures differ in terms of spatial connectivity patterns at extreme log-conductivity values. Our numerical approach to simulate contaminant transport through heterogeneous porous media is based on the Lagrangian framework with a reverse tracking formulation. Advection and local scale dispersion are two competing and controlling mechanisms, with a relative ratio defined by the Peclet number (Pe); hydraulic log-conductivity variance $\sigma$Y2 in the simulations is assumed to be 1 or 8. The term local scale dispersion is used as a combined effect of molecular diffusion and mechanical dispersion. Uncertainty of the concentration field is quantified by the second order moment, or the coefficient of variation (CVC) as a function of the sampling position along a centerline, Peclet number and $\sigma$Y2, as well as by higher order moments, i.e., skewness and kurtosis. $\sigma$Y2 shows a strong influence on the concentration statistics while the three different structures have a minor impact in the case of low heterogeneity. The results also indicate that for $\sigma$Y2 equal to eight, the influence of local scale dispersion is significant after five integral scales (IY) from the source for the CN field, while in case of a DN field, the local scale dispersion effect is observed after 20 IY from the source. In the case of unit $\sigma$Y2, local scale dispersion acts very slowly affecting concentration uncertainty at distances higher than 20 IY from the source. Our inspection of Monte-Carlo (MC) concentration skewness and kurtosis with ones obtained from the Beta distribution show the discrepancies for high $\sigma$Y2 and CN log-conductivity structure.},
author = {Srzic, Veljko and Cvetkovic, Vladimir and Andricevic, Roko and Gotovac, Hrvoje},
doi = {10.1002/wrcr.20314},
issn = {1944-7973},
journal = {Water Resources Research},
keywords = {Advection,Concentration uncertainty,Heterogeneity structure,Kurtosis,Local scale dispersion,Skewness},
language = {en},
mendeley-tags = {Advection,Concentration uncertainty,Heterogeneity structure,Kurtosis,Local scale dispersion,Skewness},
pages = {n/a--n/a},
title = {{Impact of aquifer heterogeneity structure and local scale dispersion on solute concentration uncertainty}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/wrcr.20314/abstract http://onlinelibrary.wiley.com/store/10.1002/wrcr.20314/asset/wrcr20314.pdf?v=1\&t=hh8dtl54\&s=59950d9d73b86ac7cf08818c394b4ee5e26f0f50},
year = {2013}
}
@article{Meyer1988,
abstract = {A method is presented for locating wells in a monitoring network under conditions of uncertainty. The method couples the use of a simulation model of contaminant transport and a facility location model. The Monte Carlo technique is used with the simulation model to translate uncertainty in the simulation model parameters into uncertainty in the contaminant concentration distribution. The simulation model determines which well locations would detect a given realization of a contaminant plume with a concentration above a specified limit. The facility location model is then used to select a fixed number of well locations so that a maximum number of such plume realizations are detected. The selected well network maximizes the probability of detection. The method is applied to an example problem. Although the technique is computationally intensive, the results indicate that practical problems are tractable.},
author = {Meyer, Philip D. and Brill, E. Downey},
doi = {10.1029/WR024i008p01277},
issn = {1944-7973},
journal = {Water Resources Research},
language = {en},
number = {8},
pages = {1277--1282},
title = {{A method for locating wells in a groundwater monitoring network under conditions of uncertainty}},
url = {http://onlinelibrary.wiley.com/doi/10.1029/WR024i008p01277/abstract http://onlinelibrary.wiley.com/doi/10.1029/WR024i008p01277/full http://onlinelibrary.wiley.com/store/10.1029/WR024i008p01277/asset/wrcr4612.pdf?v=1\&t=hl1ozkhx\&s=f5390999a682ef69f6e21cedb34eedb62468a45a http://onlinelibrary.wiley.com/store/10.1029/WR024i008p01277/asset/wrcr4612.pdf?v=1\&t=hl1p02gw\&s=64cdde86427ea6c2232d35977ac5cf1f59c14d8d},
volume = {24},
year = {1988}
}
@article{Sivapalan1998,
author = {Sivapalan, Murugesu and Bl\"{o}schl, G\"{u}nter},
journal = {Journal of Hydrology},
number = {1},
pages = {150--167},
shorttitle = {Transformation of point rainfall to areal rainfall},
title = {{Transformation of point rainfall to areal rainfall: Intensity-duration-frequency curves}},
url = {http://www.sciencedirect.com/science/article/pii/S0022169497001170},
volume = {204},
year = {1998}
}
@incollection{Slack2011,
abstract = {Household hazardous waste (HHW) is a term used to describe hazardous wastes entering the municipal waste stream. It represents a variety of waste types classified together based on the possession of hazardous properties. This chapter takes a look at the problems related to the disposal of chemicals and other hazardous substances used in the home. HHW is a small proportion of the municipal waste stream, but the potential risks to the environment and health are disproportionate to its size. Although estimates of the amount of HHW vary from region to region and across national boundaries, it generally comprises 1–4\% of municipal solid waste (MSW). Internationally, most HHW is co-disposed with MSW to municipal waste landfills. Co-disposal of potentially hazardous wastes can lead to an increase in hazard status; not only are these substances potentially dangerous to the environment and health, but they can also induce changes in other waste streams by reacting directly with the waste or by altering the redox environment. Landfill simulations, based on current MSW disposal patterns, reveal the risk to the environment from leakage of potentially hazardous materials from landfills to be small but existent. There is a growing tendency for waste disposal authorities to make provision for the separate collection of many items of HHW. The increased cost of separate HHW collection and disposal must be considered alongside the new environmental and health risks posed by changes to disposal practice and the general trend of reduced hazardous content of most consumer goods.},
address = {Boston},
author = {Slack, Rebecca and Letcher, Trevor M.},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/THMR5IWF/Slack and Letcher - 2011 - Chapter 13 - Chemicals in Waste Household Hazardo.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {181--195},
publisher = {Academic Press},
shorttitle = {Chapter 13 - Chemicals in Waste},
title = {{Chapter 13 - Chemicals in Waste: Household Hazardous Waste}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100130 http://www.sciencedirect.com/science/article/pii/B9780123814753100130/pdfft?md5=3192681b30e770bf0c5d02eb77fb4e39\&pid=3-s2.0-B9780123814753100130-main.pdf},
year = {2011}
}
@techreport{Taylor1994,
author = {Taylor, Barry N. and Kuyatt, Chris E.},
institution = {National Institute of Standards and Technology},
language = {English},
title = {{NIST Technical Note 1297 : Guidelines for Evaluating and Expressing the Uncertainty of NIST Measurement Results}},
url = {http://physics.nist.gov/Pubs/guidelines/TN1297/tn1297s.pdf},
year = {1994}
}
@article{Tamea,
abstract = {Aim of this work is to propose a stochastic description of the leakage between two aquifers separated by a semi-permeable layer with low hydraulic conductivity. The source of uncertainty here considered is the random fluctuation of the phreatic surface of surficial aquifer, originated from random rainfall events. The study focuses on an area surrounding a pumping well penetrating the deep aquifer and impacting its piezometric level, where infiltration from the surficial aquifer can be more harmful. Closed form expressions for the leakage between the surficial and the deep aquifer are used to obtain the long-term probability distribution of leakage flow rate, assuming the shallow phreatic surface dynamics modeled with a Poisson-driven stochastic process. A sensitivity analysis is performed to verify the variability of the probability distribution of leakage within the range of feasible parameter values, then the stochastic model is applied to three field cases where time series of the piezometric levels of the phreatic aquifer are available. Results show that the induced variability of the discharge flowing between aquifers is remarkable and that in general it cannot be neglected despite the low hydraulic conductivity of the semi-permeable layer. The proposed probabilistic model is a useful tool for evaluating the risk associated to contaminant transport into deep aquifers and its fate in relation to groundwater withdrawals.},
author = {Tamea, S. and Butera, I.},
doi = {10.1016/j.jhydrol.2013.12.007},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/AEV2RCC8/S0022169413009049.html:html;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/EJFHEQWN/Tamea and Butera - Stochastic description of infiltration between aqu.pdf:pdf},
issn = {0022-1694},
journal = {Journal of Hydrology},
keywords = {Groundwater,Leakage,Poisson noise,Probability distribution,Pumping well,Recharge},
mendeley-tags = {Groundwater,Leakage,Poisson noise,Probability distribution,Pumping well,Recharge},
title = {{Stochastic description of infiltration between aquifers}},
url = {http://www.sciencedirect.com/science/article/pii/S0022169413009049 http://www.sciencedirect.com/science/article/pii/S0022169413009049/pdfft?md5=5b06cba272d763c6832629129a78aab0\&pid=1-s2.0-S0022169413009049-main.pdf}
}
@article{Morton1993a,
author = {Morton, Adam},
doi = {10.1093/bjps/44.4.659},
issn = {0007-0882, 1464-3537},
journal = {The British Journal for the Philosophy of Science},
number = {4},
pages = {659--674},
shorttitle = {Mathematical Models},
title = {{Mathematical Models: Questions of Trustworthiness}},
url = {http://bjps.oxfordjournals.org/cgi/doi/10.1093/bjps/44.4.659},
volume = {44},
year = {1993}
}
@article{Bloschl1995,
abstract = {A framework is provided for scaling and scale issues in hydrology. The first section gives some basic definitions. This is important as researchers do not seem to have agreed on the meaning of concepts such as scale or upscaling. ‘Process scale’, ‘observation scale’ and ‘modelling (working) scale’ require different definitions. The second section discusses heterogeneity and variability in catchments and touches on the implications of randomness and organization for scaling. The third section addresses the linkages across scales from a modelling point of view. It is argued that up- scaling typically consists of two steps: distributing and aggregating. Conversely, downscaling involves disaggregation and singling out. Different approaches are discussed for linking state variables, parameters, inputs and conceptual- izations across scales. This section also deals with distributed parameter models, which are one way of linking con- ceptualizations across scales. The fourth section addresses the linkages across scales from a more holistic perspective dealing with dimensional analysis and similarity concepts. The main difference to the modelling point of view is that dimensional analysis and similarity concepts deal with complex processes in a much simpler fashion. Examples of dimensional analysis, similarity analysis and functional normalization in catchment hydrology are given. This section also briefly discusses fractals, which are a popular tool for quantifying variability across scales. The fifth section focuses on one particular aspect of this holistic view, discussing stream network analysis. The paper concludes with identifying key issues and gives some directions for future research.},
author = {Bl\"{o}schl, G\"{u}nter and Sivapalan, Murugesu},
doi = {10.1002/hyp.3360090305},
issn = {08856087},
journal = {Hydrological processes},
keywords = {aggregation,dimensional analysis,distributed modelling,effective parameters,fractals,geomorphologic unit hydrograph,scale,scaling,similarity,stream network analysis},
month = apr,
number = {3-4},
pages = {251--290},
shorttitle = {Scale issues in hydrological modelling},
title = {{Scale issues in hydrological modelling: a review}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/hyp.3360090305/abstract http://www.idrologia.polito.it/~alviglio/TUWsite/1995\_Bloeschl\_HP\_a.pdf http://doi.wiley.com/10.1002/hyp.3360090305},
volume = {9},
year = {1995}
}
@incollection{Cheremisinoff2011,
abstract = {There are two broad areas of pollution that pose ongoing negative impacts to the public. These are legacy pollution and ongoing releases. Legacy pollution refers to toxic chemical releases into the environment during a time pre-dating strict environmental enforcement practices. “Standard of Care” is a term of art that is generally defined as the degree of prudence and caution required of an individual who is under a duty of care. Generally, it is thought to concern the degree of caution that a reasonable person should exercise in a given situation so as to avoid causing injury. It is the watchfulness, attention, caution, and prudence that a reasonable person under the same or similar circumstances would exercise. Strict environmental enforcement has made the single most difference in overall improved environmental performance by industry. The fear of fines, penalties, and even imprisonment of owners and operators who violate statutory obligations under pollution control permits have driven industry on the whole to adopt BMPs and to make investments into controls. Finally, good corporate governance includes environmental stewardship as a foundation. From the most general standpoint, Responsible Care means acting in a responsible manner toward public and worker safety, protecting the environment, and respecting the properties and quality of life of others.},
address = {Boston},
author = {Cheremisinoff, Nicholas P.},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/Q27ZX8HS/Cheremisinoff - 2011 - Chapter 31 - Pollution Management and Responsible .pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {487--502},
publisher = {Academic Press},
title = {{Chapter 31 - Pollution Management and Responsible Care}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100312 http://www.sciencedirect.com/science/article/pii/B9780123814753100312/pdfft?md5=3bdbc20ec2ec45a847a4ee1be408ccb7\&pid=3-s2.0-B9780123814753100312-main.pdf},
year = {2011}
}
@article{Ward1989,
abstract = {This paper examines in detail reasons for using constructively simple models in management science interventions. Constructive simplicity is an objective concept describing the form and level of detail in a model. It is distinguished from the subjective concept of transparency, which relates to user-comprehension of a model. Usual arguments for constructive simplicity focus on model-building considerations such as model clarity, flexibility and convenience. Constructively simple models are also an efficient way of learning about decision situations. Client managers may prefer constructive simplicity not only as a convenient way of ensuring transparent models, but also for reasons related to motivation, time constraints, implementation and involvement of third parties. A principal conclusion is that constructive simplicity in modelling is a robust strategy for effective interventions.},
author = {Ward, S. C.},
doi = {10.1057/jors.1989.19},
issn = {0160-5682},
journal = {Journal of the Operational Research Society},
keywords = {methodology,model-building},
language = {en},
mendeley-tags = {methodology,model-building},
month = feb,
number = {2},
pages = {141--153},
title = {{Arguments for Constructively Simple Models}},
url = {http://www.palgrave-journals.com/jors/journal/v40/n2/abs/jors198919a.html},
volume = {40},
year = {1989}
}
@article{Michel2014,
abstract = {Tritium concentrations in river and stream waters from different locations can be compared by normalizing them using the ratio of tritium concentrations in precipitation and surface water (Cp/Cs) in the study area. This study uses these ratios in a hydrological residence time context to make regional- and global-scale comparisons about river basin dynamics. Prior to the advent of nuclear weapons testing, the Cp/Cs ratio was greater than or equal to one everywhere due to the decay of tritium in the watershed after it was deposited by precipitation. After an initial increase in the ratios during the bomb-peak, the ratio dropped to less than one for most surface waters in the following years. This post-bomb change in the ratio is due to the retention of the bomb-pulse water in watersheds on timescales that are long relative to the residence time of tritium in the atmosphere. Ratios were calculated for over 6500 measurements of tritium in river and stream waters compiled by the International Atomic Energy Agency. These measurements span the post-nuclear era (1940's-present) and include many long-term data sets which make it possible to examine residence times of waters in watersheds on a global basis. Plotting Cp/Cs versus time shows that ratios tended to reach a minimum approximately one to two decades after the bomb-peak for most locations. This result suggests that changes affecting quantity and quality of river flows need to be assessed on a multi-decadal timescale. These long lag times have significant implications for assessing climate- or land use-change impacts on a large number of river systems around the world. The continuing value of tritium in studying surface water systems for both the Southern and Northern Hemisphere is also demonstrated. This article is protected by copyright. All rights reserved.},
author = {Michel, Robert L. and Aggarwal, Pradeep and Araguas-Araguas, Luis and Kurttas, Tuerker and Newman, Brent D. and Vitvar, Tomas},
doi = {10.1002/hyp.10174},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/3UG3ZQAN/Michel et al. - 2014 - A simplified approach to analyzing historical and .pdf:pdf},
issn = {1099-1085},
journal = {Hydrological Processes},
keywords = {Tritium,river basin,timescales},
language = {en},
mendeley-tags = {Tritium,river basin,timescales},
pages = {n/a--n/a},
title = {{A simplified approach to analyzing historical and recent tritium data in surface waters}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/hyp.10174/abstract http://onlinelibrary.wiley.com/store/10.1002/hyp.10174/asset/hyp10174.pdf?v=1\&t=hryjxqye\&s=eef1b0351f8605c18033ebd338124421a37f8ba6},
year = {2014}
}
@article{Boggs1992,
abstract = {Results are presented for a large-scale natural gradient tracer experiment conducted in a heterogeneous alluvial aquifer at a site near Columbus, Mississippi. The study was initiated with a 48-hour pulse injection of 10 m3 of groundwater containing bromide and three organic tracers (pentaflourobenzoic acid, o-trifluoromethylbenzoic acid, and 2,6-diflourobenzoic acid). Over a 20-month period, seven comprehensive samplings of the tracer plume were performed at approximately 1- to 4-month intervals using an extensive three-dimensional sampling well network. The dominant feature of the tracer plume that evolved during the study was the highly asymmetric concentration distribution in the longitudinal direction. This asymmetry was produced by accelerating groundwater flow along the plume travel path that, in turn, resulted from an approximate 2-order-of-magnitude increase in the mean hydraulic conductivity between the near-field and far-field regions of the site. The Columbus study is distinct from previous natural gradient experiments because of the extreme heterogeneity of the aquifer, the large-scale spatial variations in groundwater velocity, and the extensive set of hydraulic conductivity measurements for the aquifer.},
author = {Boggs, J. Mark and Young, Steven C. and Beard, Lisa M. and Gelhar, Lynn W. and Rehfeldt, Kenneth R. and Adams, E. Eric},
doi = {10.1029/92WR01756},
issn = {1944-7973},
journal = {Water Resources Research},
language = {en},
number = {12},
pages = {3281--3291},
shorttitle = {Field study of dispersion in a heterogeneous aquif},
title = {{Field study of dispersion in a heterogeneous aquifer: 1. Overview and site description}},
url = {http://onlinelibrary.wiley.com/doi/10.1029/92WR01756/abstract http://onlinelibrary.wiley.com/store/10.1029/92WR01756/asset/wrcr5916.pdf?v=1\&t=hl1p0al5\&s=91476562027ea7fd6c3c562e4dccb71a6c0fdcd7},
volume = {28},
year = {1992}
}
@article{Ameli2014,
abstract = {A semianalytical grid-free series solution method is presented for modeling 3-D steady state free boundary groundwater-surface water exchange in geometrically complex stratified aquifers. Continuous solutions for pressure in the subsurface are determined semianalytically, as is the location of the water table surface. Mass balance is satisfied exactly over the entire domain except along boundaries and interfaces between layers, where errors are shown to be acceptable. The solutions are derived and demonstrated on a number of test cases and the errors are assessed and discussed. This accurate and grid-free scheme can also be a helpful tool for providing insight into lake-aquifer and stream-aquifer interactions. Here it is used to assess the impact of lake sediment geometry and properties on lake-aquifer interactions. Various combinations of lake sediment are considered and the appropriateness of the Dupuit-Forchheimer approximation for simulating lake bottom flux distribution is investigated. In addition, the method is applied to a test problem of surface seepage flows from a complex topographic surface; this test case demonstrated the method's efficacy for simulating physically realistic domains.},
author = {Ameli, Ali A. and Craig, James R.},
doi = {10.1002/2014WR015394},
issn = {1944-7973},
journal = {Water Resources Research},
keywords = {1829 Groundwater hydrology,1830 Groundwater/surface water interaction,1849 Numerical approximations and analysis,1880 Water management,free boundary problem,groundwater-surface water interaction,lake-aquifer interaction,multilayer unconfined aquifer,series solution,three-dimensional semianalytical model},
language = {en},
mendeley-tags = {1829 Groundwater hydrology,1830 Groundwater/surface water interaction,1849 Numerical approximations and analysis,1880 Water management,free boundary problem,groundwater-surface water interaction,lake-aquifer interaction,multilayer unconfined aquifer,series solution,three-dimensional semianalytical model},
month = may,
pages = {n/a--n/a},
title = {{Semianalytical series solutions for three-dimensional groundwater-surface water interaction}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/2014WR015394/abstract},
year = {2014}
}
@article{Merz2004,
author = {Merz, Ralf and Bl\"{o}schl, G\"{u}nter},
doi = {10.1016/j.jhydrol.2003.09.028},
issn = {00221694},
journal = {Journal of Hydrology},
keywords = {catchment attributes,model calibration,parameter uncertainty,patterns of model parameters,regionalisation,ungauged},
month = feb,
number = {1-4},
pages = {95--123},
title = {{Regionalisation of catchment model parameters}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0022169403004013},
volume = {287},
year = {2004}
}
@inproceedings{Agarwal2012,
abstract = {Scientists, site managers and regulators participating in environmental remediation activities usually need to access, create, and manage large amounts of heterogeneous data, including disparate site characterization data, and models that range from conceptual to numerical . The data are necessary to enable the development of conceptual and numerical models, parameter estimation, and multiple simulations. We designed a methodology based on DOE Savannah River Site F - Area and Hanford databases that included well layout, concentration, groundwater level, lithology, meteorological records, contaminant levels, etc. The approach was necessary to effectively manage the staging and views of environmental data to ensure that site characterization and monit oring data are readily available as inputs for parameter estimation, numerical predictions, uncertainty quantification, and risk analysis. This paper describes the methodology and the application of the developed data management system to the Savannah Rive r F - Area site observations. In particular, we present methods for organizing different databases and data types into a common framework that allows the user to browse the data as a single coherent dataset. A nalyses of the Savannah River F - area using the da ta management system illustrate the utility of the system . The paper also demonstrates the utility of interfaces designed to leverage and integrate existing large - scale data management, provenance and indexing technologies from the scientific community and discuss the next steps.},
author = {Agarwal, Deb and Wiedmer, Arthur and Faybishenko, Boris and Hunt, J. and Kushner, G. and Romosan, A. and Shoshani, A. and Whiteside, T.},
booktitle = {XIX International Conference on Computational Methods in Water Resources (CMWR 2012)},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/S6JNWER5/Agarwal et al. - 2012 - A Methodology for Management of Heterogeneous Site.pdf:pdf},
title = {{A Methodology for Management of Heterogeneous Site Characterization and Modeling Data}},
url = {http://cmwr2012.cee.illinois.edu/Papers/Special Sessions/Transforming Water Resource Management with Open-Source Community Tools/Agarwal.Deb.pdf},
year = {2012}
}
@article{Rasmussen2001,
author = {Rasmussen, Steen and Baas, Nils A. and Mayer, Bernd and Nilsson, Martin and Olesen, Michael W.},
journal = {Artificial Life},
number = {4},
pages = {329--353},
title = {{Ansatz for dynamical hierarchies}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/106454601317296988},
volume = {7},
year = {2001}
}
@techreport{Marra2010,
address = {Aiken, SC},
author = {Marra, J.},
institution = {Savannah River National Laboratory},
keywords = {Uranium,and national defense,chain reactions,energy planning,fission,fluorescence,glazes,military technology,neutrons,nuclear fuel cycle and fuel materials,nuclear power,nuclear weapons,nuclei,pitchblende,policy and economy,polonium,radioactivity,radium,uranium minerals,waste management,weaponry,weapons},
language = {English},
mendeley-tags = {Uranium,and national defense,chain reactions,energy planning,fission,fluorescence,glazes,military technology,neutrons,nuclear fuel cycle and fuel materials,nuclear power,nuclear weapons,nuclei,pitchblende,policy and economy,polonium,radioactivity,radium,uranium minerals,waste management,weaponry,weapons},
month = may,
title = {{Chapter 5-Radioactive Waste Management}},
url = {http://www.osti.gov/scitech/biblio/978853},
year = {2010}
}
@article{Rinaldo1992,
abstract = {This paper explores the similarities of digital elevation maps (DEMs) of natural river basins and optimal channel network (OCN) configurations obtained minimizing the total rate of energy expenditure in the system as a whole and in its parts. Striking similarities are observed for natural and optimal networks in their fractal aggregation structure and in certain multifractal structures found to be characteristic of river basins. Our results suggest, upon critical assessment of the reliability of the identification of the attractor of the underlying dynamics implied by our optimality concepts, that fractal structures are indeed possibly a product of least energy dissipation. Power laws emerging in the description of the distribution of aggregated quantities from both DEMs and OCNs suggest a link with the framework of self-organized criticality in the dynamics of natural channel network formation. Also, the geomorphological description of OCNs reveals surprising analogies with well-known empirical or experimental results, A comparison of Peano's basins with OCNs suggests that nature seems to reject the type of strict self-similarity exhibited by Peano's construct in favor of different shapes implying statistical self-similarity not only because of chance acting through random conditions but also because of necessity as reflected by least energy expenditure considerations.},
annote = {        From Duplicate 2 (                   Minimum energy and fractal structures of drainage networks                 - Rinaldo, Andrea; Rodriguez-Iturbe, Ignacio; Rigon, Riccardo; Bras, Rafael L.; Ijjasz-Vasquez, Ede; Marani, Alessandro )
                
        
        
      },
author = {Rinaldo, Andrea and Rodriguez-Iturbe, Ignacio and Rigon, Riccardo and Bras, Rafael L. and Ijjasz-Vasquez, Ede and Marani, Alessandro},
doi = {10.1029/92WR00801},
issn = {00431397},
journal = {Water Resources Research},
language = {en},
month = sep,
number = {9},
pages = {2183--2195},
title = {{Minimum energy and fractal structures of drainage networks}},
url = {http://doi.wiley.com/10.1029/92WR00801 http://onlinelibrary.wiley.com/doi/10.1029/92WR00801/abstract http://onlinelibrary.wiley.com/store/10.1029/92WR00801/asset/wrcr5814.pdf?v=1\&t=hethe6pi\&s=15e1069a572a4219c2111bf400174ff3dadf168a},
volume = {28},
year = {1992}
}
@article{Kurkova2005,
abstract = {Learning from data with generalization capability is studied in the framework of minimization of regularized empirical error functionals over nested families of hypothesis sets with increasing model complexity. For Tikhonov's regularization with kernel stabilizers, minimization over restricted hypothesis sets containing for a fixed integer n only linear combinations of all n -tuples of kernel functions is investigated. Upper bounds are derived on the rate of convergence of suboptimal solutions from such sets to the optimal solution achievable without restrictions on model complexity. The bounds are of the form <img height="18" border="0" style="vertical-align:bottom" width="42" alt="View the MathML source" title="View the MathML source" src="http://origin-ars.els-cdn.com/content/image/1-s2.0-S0885064X04001049-si1.gif">1/n multiplied by a term that depends on the size of the sample of empirical data, the vector of output data, the Gram matrix of the kernel with respect to the input data, and the regularization parameter.},
author = {Kůrkov\'{a}, V\v{e}ra and Sanguineti, Marcello},
doi = {10.1016/j.jco.2004.11.002},
issn = {0885-064X},
journal = {Journal of Complexity},
keywords = {Generalization,Kernel methods,Minimization of regularized empirical errors,Supervised learning,Upper bounds on rates of approximate optimization,model complexity},
mendeley-tags = {Generalization,Kernel methods,Minimization of regularized empirical errors,Supervised learning,Upper bounds on rates of approximate optimization,model complexity},
month = jun,
number = {3},
pages = {350--367},
title = {{Learning with generalization capability by kernel methods of bounded complexity}},
url = {http://www.sciencedirect.com/science/article/pii/S0885064X04001049 http://www.sciencedirect.com/science/article/pii/S0885064X04001049/pdf?md5=4c1d81b1af05cf5f7bcf3afd6cd7c5dc\&pid=1-s2.0-S0885064X04001049-main.pdf},
volume = {21},
year = {2005}
}
@article{Sivapalan1987,
author = {Sivapalan, M. and Beven, Keith J. and Wood, Eric F.},
journal = {Water Resources Research},
number = {12},
pages = {2266--2278},
title = {{On Hydrologic Similarity}},
url = {http://biodav.atmos.colostate.edu/kraus/Papers/TOPMODEL/Sivapalan-hydroSimilarity.pdf},
volume = {23},
year = {1987}
}
@article{Busemeyer2000,
abstract = {The purpose of this article is to formalize the generalization criterion method for model comparison. The method has the potential to provide powerful comparisons of complex and nonnested models that may also differ in terms of numbers of parameters. The generalization criterion differs from the better known cross-validation criterion in the following critical procedure. Although both employ a calibration stage to estimate parameters, cross-validation employs a replication sample from the same design for the validation stage, whereas generalization employs a new design for the critical stage. Two examples of the generalization criterion method are presented that demonstrate its usefulness for selecting a model based on sound scientific principles out of a set that also contains models lacking sound scientific principles that are either overly complex or oversimplified. The main advantage of the generalization criterion is its reliance on extrapolations to new conditions. After all, accurate a priori predictions to new conditions are the hallmark of a good scientific theory. Copyright 2000 Academic Press.},
author = {Busemeyer, Jr and Wang, Ym},
doi = {10.1006/jmps.1999.1282},
issn = {0022-2496},
journal = {Journal of mathematical psychology},
month = mar,
number = {1},
pages = {171--189},
pmid = {10733863},
title = {{Model Comparisons and Model Selections Based on Generalization Criterion Methodology.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10733863},
volume = {44},
year = {2000}
}
@incollection{Vallero2011,
abstract = {The hazardous attributes of the waste are usually based on its inherent physicochemical properties, including its likelihood to ignite, explode, and react with water. The hazardous inherent properties of a waste can also be biological, such as the infectious nature of medical wastes, or a chemical compound that has been shown to elicit acute effects, for example skin irritations and chronic effects, such as cancer; harm to the endocrine, immune, or nervous system; interference with tissue development and reproduction; or mutations, birth defects, or other toxic endpoints. Hazardous waste management involves reducing the amount of hazardous substances produced, treating hazardous wastes to reduce their toxicity, and applying sound engineering controls to reduce or eliminate exposures to these wastes. Waste-treatment technologies include physical treatment, chemical treatment, biological treatment, incineration, and solidification or stabilization treatment. The selection of the most effective technology depends on the characteristics of the wastes being treated. Similarly, the characteristics of the media in need of treatment determine the performance of any contaminant treatment or control. These processes recycle and reuse waste materials, reduce the volume and toxicity of a waste stream, or produce a final residual material that is suitable for disposal.},
address = {Boston},
author = {Vallero, Daniel A.},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/CMQ7KBQB/Vallero - 2011 - Chapter 27 - Hazardous Wastes.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {393--423},
publisher = {Academic Press},
title = {{Chapter 27 - Hazardous Wastes}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100270 http://www.sciencedirect.com/science/article/pii/B9780123814753100270/pdfft?md5=a53c89639abaf2cd551e09c8937b9b13\&pid=3-s2.0-B9780123814753100270-main.pdf},
year = {2011}
}
@article{Hogg2010,
abstract = {We go through the many considerations involved in fitting a model to data, using as an example the fit of a straight line to a set of points in a two-dimensional plane. Standard weighted least-squares fitting is only appropriate when there is a dimension along which the data points have negligible uncertainties, and another along which all the uncertainties can be described by Gaussians of known variance; these conditions are rarely met in practice. We consider cases of general, heterogeneous, and arbitrarily covariant two-dimensional uncertainties, and situations in which there are bad data (large outliers), unknown uncertainties, and unknown but expected intrinsic scatter in the linear relationship being fit. Above all we emphasize the importance of having a "generative model" for the data, even an approximate one. Once there is a generative model, the subsequent fitting is non-arbitrary because the model permits direct computation of the likelihood of the parameters or the posterior probability distribution. Construction of a posterior probability distribution is indispensible if there are "nuisance parameters" to marginalize away.},
annote = {Comment: a chapter from a non-existent book},
author = {Hogg, David W. and Bovy, Jo and Lang, Dustin},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/482HDUCA/Hogg et al. - 2010 - Data analysis recipes Fitting a model to data.pdf:pdf},
journal = {arXiv:1008.4686 [astro-ph, physics:physics]},
keywords = {Astrophysics - Instrumentation and Methods for Ast,Physics - Data Analysis- Statistics and Probabilit},
mendeley-tags = {Astrophysics - Instrumentation and Methods for Ast,Physics - Data Analysis- Statistics and Probabilit},
month = aug,
shorttitle = {Data analysis recipes},
title = {{Data analysis recipes: Fitting a model to data}},
url = {http://arxiv.org/abs/1008.4686 http://www.arxiv.org/pdf/1008.4686.pdf},
year = {2010}
}
@article{Koch1986a,
author = {Koch, Roy W. and Smillie, Gary M.},
doi = {10.1029/WR022i013p02121},
issn = {1944-7973},
journal = {Water Resources Research},
language = {en},
number = {13},
pages = {2121--2122},
title = {{Comment on “River loads underestimated by rating curves” by R. I. Ferguson}},
url = {http://onlinelibrary.wiley.com/doi/10.1029/WR022i013p02121/abstract http://onlinelibrary.wiley.com/store/10.1029/WR022i013p02121/asset/wrcr4171.pdf?v=1\&t=hmfszcbw\&s=6b40ea8fd6a0cbbfb53181e0a179cacf9b89967b},
volume = {22},
year = {1986}
}
@article{Western2004,
author = {Western, Andrew W. and Zhou, Sen-Lin and Grayson, Rodger B. and McMahon, Thomas A. and Bl\"{o}schl, G\"{u}nter and Wilson, David J.},
journal = {Journal of Hydrology},
number = {1},
pages = {113--134},
title = {{Spatial correlation of soil moisture in small catchments and its relationship to dominant spatial hydrological processes}},
url = {http://www.sciencedirect.com/science/article/pii/S0022169403003809 http://www.hydro.tuwien.ac.at/fileadmin/mediapool-hydro/Publikationen/bloeschl/2004\_Western\_JH.pdf},
volume = {286},
year = {2004}
}
@article{Meysman2003,
abstract = {Analysis of three recent diagenetic model codes (OMEXDIA, CANDI and STEADYSED) revealed that codes have a rigid, static and problem-specific character, leaving little autonomy for the application user. The resulting lack of flexibility and extensibility, and the associated need for ground-level reprogramming, constitutes a major barrier for potential model users. Present codes have apparently passed a critical threshold of code complexity, above which code development becomes time-consuming and expensive using the present procedure-oriented techniques. We have explored the advantages of object-oriented technology and the concept of a problem-solving environment to improve the quality of software for reactive transport modelling. A general blueprint for an object-oriented code for modelling early diagenesis is presented. The MEDIA environment consists of a toolbox of building blocks (element, species and process objects), which can be combined freely by the user to construct new models (without the need for recompilation). An object-oriented database stores current objects and accommodates new user-defined building blocks. Altogether, it is advocated that by improving the software quality, one can substantially lower the threshold for using model codes as an integrated data-analysis tool.},
author = {Meysman, Filip J. R. and Middelburg, Jack J. and Herman, Peter M. J. and Heip, Carlo H. R.},
doi = {10.1016/S0098-3004(03)00006-2},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/QRX2AX8K/Meysman et al. - 2003 - Reactive transport in surface sediments. I. Model .pdf:pdf},
issn = {0098-3004},
journal = {Computers \& Geosciences},
keywords = {Early diagenesis,Object-oriented design,Problem-solving environment,Reactive transport modelling,Software quality assurance},
mendeley-tags = {Early diagenesis,Object-oriented design,Problem-solving environment,Reactive transport modelling,Software quality assurance},
month = apr,
number = {3},
pages = {291--300},
series = {Reactive Transport Modeling in the Geosciences},
title = {{Reactive transport in surface sediments. I. Model complexity and software quality}},
url = {http://www.sciencedirect.com/science/article/pii/S0098300403000062 http://www.sciencedirect.com/science/article/pii/S0098300403000062/pdfft?md5=6fbf80ecdb52971111e065321b479360\&pid=1-s2.0-S0098300403000062-main.pdf},
volume = {29},
year = {2003}
}
@article{Sivapalan2003,
author = {Sivapalan, Murugesu and Bl\"{o}schl, G\"{u}nter and Zhang, Lu and Vertessy, Rob},
doi = {10.1002/hyp.1425},
issn = {0885-6087},
journal = {Hydrological Processes},
keywords = {downward approach,hydrology,prediction},
month = aug,
number = {11},
pages = {2101--2111},
title = {{Downward approach to hydrological prediction}},
url = {http://doi.wiley.com/10.1002/hyp.1425},
volume = {17},
year = {2003}
}
@article{Aelion2009a,
abstract = {Bayesian kriging is a useful tool for estimating spatial distributions of metals; however, estimates are generally only verified statistically. In this study surface soil samples were collected on a uniform grid and analyzed for As, Cr, Pb, and Hg. The data were interpolated at individual locations by Bayesian kriging. Estimates were validated using a leave-one-out cross validation (LOOCV) statistical method which compared the measured and LOOCV predicted values. Validation also was carried out using additional field sampling of soil metal concentrations at points between original sampling locations, which were compared to kriging prediction distributions. LOOCV results suggest that Bayesian kriging was a good predictor of metal concentrations. When measured internode metal concentrations and estimated kriged values were compared, the measured values were located within the 5th – 95th percentile prediction distributions in over half of the internode locations. Estimated and measured internode concentrations were most similar for As and Pb. Kriged estimates did not compare as well to measured values for concentrations below the analytical minimum detection limit, or for internode samples that were very close to the original sampling node. Despite inherent variability in metal concentrations in soils, the kriged estimates were validated statistically and by in situ measurement.},
author = {Aelion, C.M. and Davis, H.T. and Liu, Y. and Lawson, A.B. and McDermott, S.},
issn = {0013-936X},
journal = {Environmental science \& technology},
month = jun,
number = {12},
pages = {4432--4438},
title = {{Validation of Bayesian kriging of arsenic, chromium, lead and mercury surface soil concentrations based on internode sampling}},
url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2755059/ http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2755059/pdf/nihms115955.pdf},
volume = {43},
year = {2009}
}
@article{Biggar1976,
abstract = {Solute distributions within a soil profile during the leaching of water-soluble salts applied to the soil surface were measured at six depths to 182.4 cm within 20 subplots of a 150-ha field. Estimates of the pore water velocity based upon measures of solute displacement within each subplot and the entire field were found to be logarithmically normally distributed and in agreement with volumetric measures of water infiltration rates. Such agreement was only possible because it was recognized that the observed values were not normally distributed, and their mean values were calculated accordingly. The number of observations required to yield an estimate of the mean pore water velocity within a prescribed accuracy is shown to depend upon the nature and extent of the spatial variability of the field soil. For the field examined, 100 observations would allow the mean pore water velocity to be estimated within ±50\% of its true value. The functional relation between field-measured values of the apparent diffusion coefficient, also found to be logarithmically normally distributed, and pore water velocity is examined and interpreted in terms of solute distributions likely to be measured at specific sampling sites.},
author = {Biggar, J. W. and Nielsen, D. R.},
doi = {10.1029/WR012i001p00078},
issn = {1944-7973},
journal = {Water Resources Research},
language = {en},
number = {1},
pages = {78--84},
title = {{Spatial variability of the leaching characteristics of a field soil}},
url = {http://onlinelibrary.wiley.com/doi/10.1029/WR012i001p00078/abstract http://onlinelibrary.wiley.com/doi/10.1029/WR012i001p00078/full http://onlinelibrary.wiley.com/store/10.1029/WR012i001p00078/asset/wrcr1893.pdf?v=1\&t=hl1p18xp\&s=392b6c71f30a3173425c3ee34f7c3e8dfa15cbab},
volume = {12},
year = {1976}
}
@article{Hornberger1990,
author = {Hornberger, George M. and Beven, Keith J. and Germann, Peter F.},
journal = {Geoderma},
number = {1},
pages = {249--262},
title = {{Inferences about solute transport in macroporous forest soils from time series models}},
url = {http://www.sciencedirect.com/science/article/pii/0016706190900185},
volume = {46},
year = {1990}
}
@article{McDonnell2007b,
author = {McDonnell, J. J. and Sivapalan, M. and Vach\'{e}, K. and Dunn, S. and Grant, G. and Haggerty, R. and Hinz, C. and Hooper, R. and Kirchner, J. and Roderick, M. L. and Selker, J. and Weiler, M.},
doi = {10.1029/2006WR005467},
issn = {00431397},
journal = {Water Resources Research},
month = jul,
number = {7},
pages = {n/a--n/a},
title = {{Moving beyond heterogeneity and process complexity: A new vision for watershed hydrology}},
url = {http://doi.wiley.com/10.1029/2006WR005467},
volume = {43},
year = {2007}
}
@incollection{Genaidy2011,
abstract = {In today's global economy, the practice of sustainable development is of particular importance to the handling of toxic materials such as lead to encourage industrial organizations and its stakeholders to take an active role in maximizing human and environmental health. Currently, there is limited information on recycling rates for lead-acid batteries (LAB) in the published literature. By the late 1900s, the use of lead was significantly reduced or eliminated in non-battery products in most of the developed and developing countries, including gasoline, paints, solders, and water systems. As the use of lead in non-lead battery products has continued to decline, the demand of lead has continued to grow in starting–lighting–ignition (SLI) and non-SLI LAB applications (such as, motive sources of power for industrial forklifts, mining equipment, airport ground equipment, uninterruptible power systems in telecommunication networks). In the early 2000s, the total demand for lead in all types of lead-acid storage batteries represented around 88\% of apparent lead consumption. Three opportunities for lead recovery and recycling include lead in spent batteries with consumers, mishandled batteries sent to auto wreckers, and lead in spent batteries in municipal waste. In light of increased lead prices, it makes economic and environmental sense to maximize lead recovery and recycling by establishing a strong ecologic interface between various stakeholders and consumers.},
address = {Boston},
author = {Genaidy, Ash and Sequeira, Reynold},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/9BQD72KD/Genaidy and Sequeira - 2011 - Chapter 22 - Battery Waste.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {321--328},
publisher = {Academic Press},
title = {{Chapter 22 - Battery Waste}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100221 http://www.sciencedirect.com/science/article/pii/B9780123814753100221/pdfft?md5=42cb1abe58c8a9aaca993df5fa7f7834\&pid=3-s2.0-B9780123814753100221-main.pdf},
year = {2011}
}
@article{Olanrewaju2009,
abstract = {This review presents a synoptic status of the literature published on radioactive waste management programs around the globe in 2008. The review includes geological disposal and depository characterizations, waste form development and property evaluation, clays as engineered barrier and repository material, mobility and fate in environmental compartments, decommission and decontamination, regulatory policy and safety, and concluding remarks.},
author = {Olanrewaju, Johnson},
doi = {10.2175/106143009X12445568400412},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/PU2XQMGD/Olanrewaju - 2009 - Radioactive Waste Management.pdf:pdf},
journal = {Water Environment Research},
keywords = {Disposal,Radioactive Waste,Repository,Transport,Waste Form},
mendeley-tags = {Disposal,Radioactive Waste,Repository,Transport,Waste Form},
month = sep,
number = {10},
pages = {1836--1844},
title = {{Radioactive Waste Management}},
url = {http://www.ingentaconnect.com/search/download?pub=infobike://wef/wer/2009/00000081/00000010/art00030\&mimetype=application/pdf},
volume = {81},
year = {2009}
}
@article{Tonkin2007,
abstract = {Predictive error variance analysis attempts to determine how wrong predictions made by a calibrated model may be. Predictive error variance analysis is usually undertaken following calibration using a small number of parameters defined through a priori parsimony. In contrast, we introduce a method for investigating the potential error in predictions made by highly parameterized models calibrated using regularized inversion. Vecchia and Cooley (1987) describe a method of predictive error variance analysis that is constrained by calibration data. We extend this approach to include constraints on parameters that lie within the calibration null space. These constraints are determined by dividing parameter space into combinations of parameters for which estimates can be obtained and those for which they cannot. This enables the contribution to predictive error variance from parameterization simplifications required to solve the inverse problem to be quantified, in addition to the contribution from measurement noise. We also describe a novel technique that restricts the analysis to a strategically defined predictive solution subspace, enabling an approximate predictive error variance analysis to be completed efficiently. The method is illustrated using a synthetic and a real-world groundwater flow and transport model.},
author = {Tonkin, Matthew and Doherty, John and Moore, Catherine},
doi = {10.1029/2006WR005348},
issn = {1944-7973},
journal = {Water Resources Research},
keywords = {calibration,predictive error,superparameter,uncertainty},
language = {en},
mendeley-tags = {calibration,predictive error,superparameter,uncertainty},
number = {7},
pages = {n/a--n/a},
title = {{Efficient nonlinear predictive error variance for highly parameterized models}},
url = {http://onlinelibrary.wiley.com/doi/10.1029/2006WR005348/abstract http://onlinelibrary.wiley.com/store/10.1029/2006WR005348/asset/wrcr11022.pdf?v=1\&t=hfgcwssx\&s=9cd4024573bcaa8906b018295168abb8c12d82e5 http://onlinelibrary.wiley.com/store/10.1029/2006WR005348/asset/wrcr11022.pdf?v=1\&t=hfgd01u0\&s=a2011f469cf766ba06f5f81db179be55df8a527d},
volume = {43},
year = {2007}
}
@article{Sivapalan2003a,
author = {Sivapalan, Murugesu},
doi = {10.1002/hyp.5155},
issn = {0885-6087},
journal = {Hydrological Processes},
month = oct,
number = {15},
pages = {3163--3170},
title = {{Prediction in ungauged basins: a grand challenge for theoretical hydrology}},
url = {http://doi.wiley.com/10.1002/hyp.5155},
volume = {17},
year = {2003}
}
@article{DeBarros2014,
abstract = {Quantifying the uncertainty of solute concentration in heterogeneous aquifers is an important step in both human health and ecological risk analysis. The need for a probabilistic representation of transport is justified by the incomplete characterization of the subsurface. We derive the one-point concentration cumulative distribution function (CDF) while taking into account the spatial statistical structure of the hydraulic conductivity, space dimensionality, the injection source size, the P\'{e}clet number and the sampling volume at the monitoring location. The CDF is application-oriented and derived at first-order in the logconductivity variance. We illustrate how several key parameters control the shape of the concentration CDF. The CDF shape is important since it reflects both uncertainty and the dilution state of the plume. The transition from a bimodal to a unimodal CDF is examined and results are further supported by analyzing the concentration coefficient of variation. Results indicate the significance of the statistical anisotropy ratio (i.e., the ratio between the hydraulic conductivity correlation scales) in determining the CDF shape. The importance of the sampling volume in the tails of the concentration CDF and a comparison between the proposed model with the $\beta$-CDF approach (i.e., beta distribution) are also shown. Finally, we illustrate how the framework could be used in applications by evaluating the human health risk CDF. Our results are formally valid for low to moderate heterogeneous aquifers and source sizes small as compared to the hydraulic conductivity correlation length. The proposed approach can serve as a benchmark tool for other methods.},
author = {de Barros, F. P. J. and Fiori, A.},
doi = {10.1002/2013WR015024},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/EZSIAJWT/de Barros and Fiori - 2014 - First order-based cumulative distribution function.pdf:pdf},
issn = {1944-7973},
journal = {Water Resources Research},
keywords = {1829 Groundwater hydrology,1831 Groundwater quality,1832 Groundwater transport,1869 Stochastic hydrology,Concentration PDF,Heterogeneous Flow Fields,Human Health Risk Assessment,Probabilistic Risk Analysis,Stochastic Hydrogeology,Uncertainty Quantification},
language = {en},
mendeley-tags = {1829 Groundwater hydrology,1831 Groundwater quality,1832 Groundwater transport,1869 Stochastic hydrology,Concentration PDF,Heterogeneous Flow Fields,Human Health Risk Assessment,Probabilistic Risk Analysis,Stochastic Hydrogeology,Uncertainty Quantification},
month = apr,
pages = {n/a--n/a},
shorttitle = {First order-based cumulative distribution function},
title = {{First order-based cumulative distribution function for solute concentration in heterogeneous aquifers: Theoretical analysis and implications for human health risk assessment}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/2013WR015024/abstract http://onlinelibrary.wiley.com/store/10.1002/2013WR015024/asset/wrcr20902.pdf?v=1\&t=huhk4xua\&s=5778a3e94b20ee0d022837cf21fe3c9d3872add6},
year = {2014}
}
@article{Breton1993,
abstract = {In this paper we derive an explicit expression for the log likelihood function of a continuous-time autoregressive model. Then, using earlier results relating the autoregressive coefficients to the set of positive parameters called residual variances ratios, we develop an iterative algorithm for computing the maximum likelihood estimator of the model, similar to one in the discrete-time case. A simple noniterative estimation method, which can be used to produce an initial estimate for the algorithm, is also proposed.},
author = {Breton, Alain Le and Pham, Dinh Tuan},
doi = {10.1007/BF01213470},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/WSIGMZK5/Breton and Pham - 1993 - Maximum likelihood estimation for continuous-time .pdf:pdf},
issn = {0932-4194, 1435-568X},
journal = {Mathematics of Control, Signals and Systems},
keywords = {Communications Engineering- Networks,Continuous-time autoregressive model,Control Engineering,Levinson-Durbin algorithm,Maximum likelihood estimation,Ornstein-Uhlenbeck process},
language = {en},
mendeley-tags = {Communications Engineering- Networks,Continuous-time autoregressive model,Control Engineering,Levinson-Durbin algorithm,Maximum likelihood estimation,Ornstein-Uhlenbeck process},
month = mar,
number = {1},
pages = {62--75},
title = {{Maximum likelihood estimation for continuous-time autoregressive models by relaxation on residual variances ratio parameters}},
url = {http://link.springer.com/article/10.1007/BF01213470 http://link.springer.com/content/pdf/10.1007\%2FBF01213470.pdf},
volume = {6},
year = {1993}
}
@article{Jakeman1993,
abstract = {Development of mathematical models relating the precipitation incident upon a catchment to the streamflow emanating from the catchment has been a major focus of surface water hydrology for decades. Generally, values for parameters in such models must be selected so that runoff calculated from the model “matches” recorded runoff from some historical period. Despite the fact that the physics governing the path of a drop of water through a catchment to the stream involves complex relationships, evidence indicates that the information content in a rainfall-runoff record is sufficient to support models of only very limited complexity. This begs the question of what limits the observed data place on the allowable complexity of rainfall-runoff models. Time series techniques are applied for estimating transfer functions to determine how many parameters are appropriate to describe the relationship between precipitation and streamflow in the case where data on only precipitation, air temperature, and streamflow are available. Statistics from an “information matrix” provide the clues necessary for determining allowable model complexity. Time series models are developed for seven catchments with widely varying physical characteristics in different temperate climatic regimes to demonstrate the method. It is found that after modulating the measured rainfall using a nonlinear loss function, the rainfall-runoff response of all catchments is well represented using a linear model. Also, for all catchments a two-component linear model with four parameters is the model of choice. The two components can be interpreted as defining a “quick flow” and “slow flow” response of the given catchment. The method therefore provides a statistically rigorous way to separate hydrographs and parameterize their response behavior. The ability to construct reliable transfer function models for describing the rainfall-runoff process offers a new approach to investigate empirically the controls of physical catchment descriptors, land use change, climate change, etc., on the dynamic response of catchments through the extensive analysis of historical data sets.},
annote = {
        From Duplicate 2 ( 
        
          How much complexity is warranted in a rainfall-runoff model?
        
         - Jakeman, A. J.; Hornberger, G. M. )

        
        

        

        

      },
author = {Jakeman, A. J. and Hornberger, G. M.},
doi = {10.1029/93WR00877},
issn = {1944-7973},
journal = {Water Resources Research},
language = {en},
number = {8},
pages = {2637--2649},
title = {{How much complexity is warranted in a rainfall-runoff model?}},
url = {http://onlinelibrary.wiley.com/doi/10.1029/93WR00877/abstract http://onlinelibrary.wiley.com/doi/10.1029/93WR00877/full http://onlinelibrary.wiley.com/store/10.1029/93WR00877/asset/wrcr6194.pdf?v=1\&t=hfeyb5cj\&s=e1b836357e6384b2754f748e2cf4d9f17c206c0a},
volume = {29},
year = {1993}
}
@article{Harte2013,
abstract = {The distributional pattern of dissolved arsenic concentrations from landfill plumes can provide clues to the source of arsenic contamination. Under simple idealized conditions, arsenic concentrations along flow paths in aquifers proximal to a landfill will decrease under anthropogenic sources but potentially increase under in situ sources. This paper presents several conceptual distributional patterns of arsenic in groundwater based on the arsenic source under idealized conditions. An example of advanced subsurface mapping of dissolved arsenic with geophysical surveys, chemical monitoring, and redox fingerprinting is presented for a landfill site in New Hampshire with a complex flow pattern. Tools to assist in the mapping of arsenic in groundwater ultimately provide information on the source of contamination. Once an understanding of the arsenic contamination is achieved, appropriate remedial strategies can then be formulated. © 2013 Wiley Periodicals, Inc.*},
author = {Harte, Philip T.},
doi = {10.1002/rem.21378},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/GRDZUH5T/abstract.html:html},
issn = {1520-6831},
journal = {Remediation Journal},
language = {en},
number = {1},
pages = {69--75},
title = {{Distributional Patterns of Arsenic Concentrations in Contaminant Plumes Offer Clues to the Source of Arsenic in Groundwater at Landfills}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/rem.21378/abstract},
volume = {24},
year = {2013}
}
@article{Tulodziecki2011,
abstract = {In the mid-1800s, there was much debate about the origin or ‘exciting cause’ of cholera. Despite much confusion surrounding the disease, the so-called miasma theory emerged as the prevalent account about cholera’s cause. Going against this mainstream view, the British physician John Snow inferred several things about cholera’s origin and pathology that no one else inferred. Without observing the vibrio cholerae, however,—data unavailable to Snow and his colleagues—, there was no way of settling the question of what exactly was causing cholera and how, or if, it was passed on. The question then arises as to how Snow arrived at conclusions so systematically different from those of his opponents. In this paper, I want to look at Snow’s reasoning in some detail, and show that there were certain principles, explanatory power in particular, that were epistemologically important to Snow in their own right. I will show that Snow himself takes explanatory power to be an epistemic property, and makes explicit links between explanatory power and confirmation. Systematically juxtaposing Snow’s claims and his opponents’, I will show that Snow was right to tout the explanatory power of his theory, and that his conclusions about the epistemic superiority of his theory over that of the miasmatists’ were justified.},
author = {Tulodziecki, Dana},
doi = {10.1016/j.shpsc.2011.02.001},
issn = {1369-8486},
journal = {Studies in History and Philosophy of Science Part C: Studies in History and Philosophy of Biological and Biomedical Sciences},
keywords = {Cholera,Epistemic properties of scientific theories,Explanatory power,John Snow,Methodology of science,Scientific reasoning,Theoretical virtues,Theory-choice},
mendeley-tags = {Cholera,Epistemic properties of scientific theories,Explanatory power,John Snow,Methodology of science,Scientific reasoning,Theoretical virtues,Theory-choice},
month = sep,
number = {3},
pages = {306--316},
shorttitle = {A case study in explanatory power},
title = {{A case study in explanatory power: John Snow’s conclusions about the pathology and transmission of cholera}},
url = {http://www.sciencedirect.com/science/article/pii/S1369848611000197 http://www.sciencedirect.com/science?\_ob=MiamiImageURL\&\_cid=271970\&\_user=4420\&\_pii=S1369848611000197\&\_check=y\&\_origin=article\&\_zone=toolbar\&\_coverDate=2011-Sep-30\&view=c\&originContentFamily=serial\&wchp=dGLzVlB-zSkWz\&md5=832b225da19c58ae819ca649fdcd3a16\&pid=1-s2.0-S1369848611000197-main.pdf},
volume = {42},
year = {2011}
}
@article{Grayson1997,
author = {Grayson, Rodger B. and Western, Andrew W. and Chiew, Francis HS and Bl\"{o}schl, G\"{u}nter},
journal = {Water Resources Research},
number = {12},
pages = {2897--2908},
shorttitle = {Preferred states in spatial soil moisture patterns},
title = {{Preferred states in spatial soil moisture patterns: Local and nonlocal controls}},
url = {http://www.agu.org/pubs/crossref/1997/97WR02174.shtml http://www.idrologia.polito.it/~alviglio/TUWsite/1997\_Grayson\_WRR.pdf},
volume = {33},
year = {1997}
}
@misc{HabitablePlanet,
author = {{Annenberg Learner Foundation}},
title = {{The Habitable Planet Unit 6 - Risk, Exposure, and Health // Online Textbook}},
url = {http://www.learner.org/courses/envsci/unit/text.php?unit=6\&secNum=3},
urldate = {2014-05-27 06:16:33}
}
@article{Dann2006,
author = {Dann, R. L. and Close, M. E. and Lee, R. and Pang, L.},
doi = {10.2134/jeq2005.0257},
issn = {1537-2537},
journal = {Journal of Environment Quality},
language = {en},
number = {2},
pages = {628},
title = {{Impact of Data Quality and Model Complexity on Prediction of Pesticide Leaching}},
url = {https://dl.sciencesocieties.org/publications/jeq/abstracts/35/2/628},
volume = {35},
year = {2006}
}
@article{Ma2014,
author = {Ma, Hai Yi and Yi, Shu Ping and Ren, Guo Cheng and Hu, Xue Ling},
doi = {10.4028/www.scientific.net/AMR.955-959.1607},
issn = {1662-8985},
journal = {Advanced Materials Research},
month = jun,
pages = {1607--1614},
title = {{Analysis of Uncertainties Affecting Numerical Transport Models for a Potential Radioactive Waste Disposal Site}},
url = {http://www.scientific.net/AMR.955-959.1607},
volume = {955-959},
year = {2014}
}
@article{Klemes1986,
abstract = {The unsatisfactory state of hydrology is, in the final analysis, the result of the dichotomy between the theoretical recognition of hydrology as a science in its own right and the practical impossibility of studying it as a primary discipline but only as an appendage of hydraulic engineering, geography, geology, etc. As a consequence, the perspectives of hydrologists tend to be heavily biased in the direction of their nonhydrologic primary disciplines and their hydrologic backgrounds have wide gaps which breed a large variety of misconceptions. This state of affairs often paralyzes hydrologists' ability to differentiate between hydrology and water management, hydrology and statistics, facts and assumptions, science and convenience, etc., with consequent dangers both to scientific development of hydrology and to its practical utility. The danger increases with the proliferation of computerized “hydrologic” models whose cheaply arranged ability to fit data is presented as proof of their soundness and as a justification for using them for user-attractive but hydrologically indefensible extrapolations. These points are illustrated, among other things, by discussion of flood frequency analysis. The paper concludes with some thoughts concerning minimum standards for the testing of hydrologic simulation models that would ensure at least a modest level of credibility, and with a few suggestions for ingredients of a long-term cure that can prevent hydrology from joining alchemy and astrology in the annals of dilettantism.},
author = {Kleme\v{s}, V.},
doi = {10.1029/WR022i09Sp0177S},
issn = {1944-7973},
journal = {Water Resources Research},
language = {en},
number = {9S},
pages = {177S--188S},
shorttitle = {Dilettantism in hydrology},
title = {{Dilettantism in hydrology: Transition or destiny?}},
url = {http://onlinelibrary.wiley.com/doi/10.1029/WR022i09Sp0177S/abstract http://onlinelibrary.wiley.com/store/10.1029/WR022i09Sp0177S/asset/wrcr4188.pdf?v=1\&t=hfezmwf2\&s=7e17226afb7c9b596a388c62d330c40b016719d0},
volume = {22},
year = {1986}
}
@article{Wainwright2014,
abstract = {A stochastic model is developed to integrate multiscale geophysical and point datasets for characterizing coupled subsurface physiochemical properties over plume-relevant scales, which is desired for parameterizing reactive transport models. We utilize the concept of reactive facies, which is based on the hypothesis that subsurface units can be identified that have distinct reactive-transport-property distributions. To estimate and spatially distribute reactive facies and their associated properties over plume-relevant scales, we need to (1) document the physiochemical controls on plume behavior and the correspondence between geochemical, hydrogeological, and geophysical measurements; and (2) integrate multisource, multiscale datasets in a consistent manner. To tackle these cross-scale challenges, we develop a hierarchical Bayesian model to jointly invert various wellbore and geophysical datasets that have different resolutions and spatial coverage. We use Markov-chain Monte-Carlo sampling methods to draw many samples from the joint posterior distribution and subsequently estimate the marginal posterior distribution of reactive-facies field and their associated reactive transport properties. Synthetic studies demonstrate that our method can successfully integrate different types of datasets. We tested the framework using the datasets collected at the uranium-contaminated Savannah River Site F-Area, including wellbore lithology, cone penetrometer testing, and crosshole and surface seismic data. Results show that the method can estimate the spatial distribution of reactive facies and their associated reactive-transport properties along a 300 m plume centerline traverse with high resolution (1.2 m by 0.305 m).},
author = {Wainwright, Haruko M. and Chen, Jinsong and S.Sassen, Douglas and S.Hubbard, Susan},
doi = {10.1002/2013WR013842},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/A3QQQS8H/Wainwright et al. - 2014 - Bayesian hierarchical approach and geophysical dat.pdf:pdf},
issn = {1944-7973},
journal = {Water Resources Research},
keywords = {0520 Data analysis: algorithms and implementation,1835 Hydrogeophysics,1869 Stochastic hydrology,Bayesian hierarchical model,Geophysical data integration,Markov-chain Monte-Carlo sampling,Reactive Facies,Surface seismic data},
language = {en},
mendeley-tags = {0520 Data analysis: algorithms and implementation,1835 Hydrogeophysics,1869 Stochastic hydrology,Bayesian hierarchical model,Geophysical data integration,Markov-chain Monte-Carlo sampling,Reactive Facies,Surface seismic data},
month = may,
pages = {n/a--n/a},
title = {{Bayesian hierarchical approach and geophysical data sets for estimation of reactive facies over plume scales}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/2013WR013842/abstract http://onlinelibrary.wiley.com/store/10.1002/2013WR013842/asset/wrcr20950.pdf?v=1\&t=hvbldd86\&s=e61eda2698985f020cad402bba277431f29652d5},
year = {2014}
}
@article{Zamani,
abstract = {All numerical codes developed to solve the advection–diffusion-reaction (ADR) equation need to be verified before they are moved to the operational phase. In this paper, we initially provide four new one-dimensional analytical solutions designed to help code verification; these solutions are able to handle the challenges of the scalar transport equation including nonlinearity and spatiotemporal variability of the velocity and dispersion coefficient, and of the source term. Then, we present a solution of Burgers’ equation in a novel setup. Proposed solutions satisfy the continuity of mass for the ambient flow, which is a crucial factor for coupled hydrodynamics-transport solvers. By the end of the paper, we solve hypothetical test problems for each of the solutions numerically, and we use the derived analytical solutions for code verification. Finally, we provide assessments of results accuracy based on well-known model skill metrics.},
author = {Zamani, Kaveh and Bombardelli, Fabi\'{a}n A.},
doi = {10.1007/s10652-013-9325-0},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/TAQDKJP3/s10652-013-9325-0.html:html;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/QSAZ2AGN/Zamani and Bombardelli - Analytical solutions of nonlinear and variable-par.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/SCMUGJQH/s10652-013-9325-0.html:html},
issn = {1567-7419, 1573-1510},
journal = {Environmental Fluid Mechanics},
keywords = {Advection–diffusion-equation (ADE),Advection–diffusion-reaction equation,Analytical solution,Earth Sciences- general,Environmental Physics,Hydrogeology,Hydrology/Water Resources,Mechanics,Model skill assessment,Nonlinear partial differential equation (NPDE),Oceanography,Scalar transport equation,Verification and validation},
language = {en},
mendeley-tags = {Advection–diffusion-equation (ADE),Advection–diffusion-reaction equation,Analytical solution,Earth Sciences- general,Environmental Physics,Hydrogeology,Hydrology/Water Resources,Mechanics,Model skill assessment,Nonlinear partial differential equation (NPDE),Oceanography,Scalar transport equation,Verification and validation},
pages = {1--32},
title = {{Analytical solutions of nonlinear and variable-parameter transport equations for verification of numerical solvers}},
url = {http://link.springer.com/article/10.1007/s10652-013-9325-0 http://link.springer.com/content/pdf/10.1007\%2Fs10652-013-9325-0.pdf}
}
@book{Carson1962,
abstract = {Silent Spring-Rachel Carson-1962},
author = {Carson, Rachel},
keywords = {DDT,Folder - ch1,chemicals},
language = {eng},
mendeley-tags = {DDT,Folder - ch1,chemicals},
title = {{Silent Spring}},
url = {http://archive.org/details/fp\_Silent\_Spring-Rachel\_Carson-1962},
year = {1962}
}
@article{Zhang2010,
abstract = {In the field of wireless sensor networks, those measurements that significantly deviate from the normal pattern of sensed data are considered as outliers. The potential sources of outliers include noise and errors, events, and malicious attacks on the network. Traditional outlier detection techniques are not directly applicable to wireless sensor networks due to the nature of sensor data and specific requirements and limitations of the wireless sensor networks. This survey provides a comprehensive overview of existing outlier detection techniques specifically developed for the wireless sensor networks. Additionally, it presents a technique-based taxonomy and a comparative table to be used as a guideline to select a technique suitable for the application at hand based on characteristics such as data type, outlier type, outlier identity, and outlier degree.},
author = {Zhang, Yang and Meratnia, N. and Havinga, P.},
doi = {10.1109/SURV.2010.021510.00088},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/457ZK6P8/Zhang et al. - 2010 - Outlier Detection Techniques for Wireless Sensor N.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/VPMUM66X/abs\_all.html:html},
issn = {1553-877X},
journal = {IEEE Communications Surveys Tutorials},
keywords = {data type,outlier,outlier degree,outlier detection,outlier detection techniques,outlier identity,outlier type,sensor data,taxonomy,technique-based taxonomy,wireless sensor networks},
mendeley-tags = {data type,outlier,outlier degree,outlier detection,outlier detection techniques,outlier identity,outlier type,sensor data,taxonomy,technique-based taxonomy,wireless sensor networks},
number = {2},
pages = {159--170},
shorttitle = {Outlier Detection Techniques for Wireless Sensor N},
title = {{Outlier Detection Techniques for Wireless Sensor Networks: A Survey}},
url = {http://ieeexplore.ieee.org/ielx5/9739/5463985/05451757.pdf?tp=\&arnumber=5451757\&isnumber=5463985 http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5451757},
volume = {12},
year = {2010}
}
@incollection{Vallero2011b,
abstract = {This chapter provides an overview of the large number of waste regulations, with a particular emphasis on the regulatory environment in the United States and the United Kingdom. Environmental laws and rules address all types of wastes that find their way to the land, air and water. The regulations not only address waste streams, but the safety of products.
Environmental problems faced today differ from those of most of the Earth's history in both kind and degree. Society and its elected and appointed delegates increasingly respond to waste-related problems by writing and enforcing laws. The number of laws enacted to address various aspects of wastes has grown substantially in recent decades. Waste management requires attention to the waste and the characteristics of the place where the waste is found. This place is known as the “environmental medium.” The major environmental media are air, water, soil, sediment, and even biota. To make the regulation of wastes is even more refined, waste management must be viewed systematically. Wastes tend to be transported and can cause problems well beyond the borders of nations. One of the key waste management challenges of the twenty-first century is the ease at which waste problems are simply transferred to countries with less stringent controls. The interconnections of wastes can lead to a “circle of poisons,” the phenomenon where nations may ban a substance, but it continues to be produced and used in other, usually less economically developed, countries. Despite the ban within the borders of certain countries, the feared substance returns. Thus, the rationale for the ban, that is reduced risks to that country's inhabitants, is forgone and people continue to be exposed when they import the products that contain or are contaminated with the banned substances.},
address = {Boston},
author = {Vallero, Daniel A. and Letcher, Trevor M.},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/R32JKE6J/Vallero and Letcher - 2011 - Chapter 3 - Regulation of Wastes.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {23--59},
publisher = {Academic Press},
title = {{Chapter 3 - Regulation of Wastes}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100038 http://www.sciencedirect.com/science/article/pii/B9780123814753100038/pdfft?md5=3d20353eee812629aeb539244540509f\&pid=3-s2.0-B9780123814753100038-main.pdf},
year = {2011}
}
@article{Wrixon2008,
abstract = {This paper provides a review of the 2007 recommendations of the International Commission on Radiological Protection (ICRP). These new recommendations take account of the latest biological and physical information and consolidate the additional guidance provided by ICRP since 1990. The changes to the scientific data are not substantial. ICRP has retained its fundamental hypothesis for the induction of stochastic effects of linearity of dose and effect without threshold and a dose and dose-rate effectiveness factor (DDREF) of 2 to derive nominal risk coefficients for low doses and low dose rates. While the overall detriment from low radiation doses has remained unchanged, ICRP has made adjustments to the values of the radiation and tissue weighting factors. In particular, the tissue weighting factor for breast has increased while that for gonads has decreased. There are some presentational changes to the system of protection. While ICRP has maintained the three fundamental principles—justification, optimisation of protection, and dose limitation—it has attempted to develop a more holistic approach to radiological protection covering all exposure situations—planned, existing and emergency—and all radiation sources, whether of natural or artificial origin. This approach should ensure that attention is focused on those exposures that can reasonably be controlled. It has also strengthened the principle of optimisation of protection with a particular emphasis on the use of constraints for planned exposure situations and reference levels for existing and emergency exposure situations. Dose constraints and reference levels are categorised into three bands which should assist in rationalising the many values of dose restrictions given in earlier ICRP publications. There are no changes to the dose limits. ICRP also indicates its intentions with respect to the development of further guidance on the protection of the environment. The fact that these new recommendations are more a matter of consolidation of previous ICRP recommendations and guidance should provide confidence that the system of protection established by and large in its present form several decades ago has reached a certain level of maturity. As such, no major changes to radiological protection regulations based on the 1990 recommendations should be necessary.},
author = {Wrixon, A. D.},
doi = {10.1088/0952-4746/28/2/R02},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/SG4UDSVD/Wrixon - 2008 - New ICRP recommendations.pdf:pdf},
issn = {0952-4746},
journal = {Journal of Radiological Protection},
keywords = {Folder - ch1},
language = {en},
mendeley-tags = {Folder - ch1},
month = jun,
number = {2},
pages = {161},
title = {{New ICRP recommendations}},
url = {http://iopscience.iop.org/0952-4746/28/2/R02 http://iopscience.iop.org/0952-4746/28/2/R02/pdf/0952-4746\_28\_2\_R02.pdf},
volume = {28},
year = {2008}
}
@article{Golden2000,
abstract = {Model selection criteria (MSC) involves selecting the model with the best estimated goodness-of-fit to the data generating process. Following the method of Vuong (1989), a large sample Model Selection Test (MST), is introduced that can be used in conjunction with most existing MSC procedures to decide if the estimated goodness-of-fit for one model is significantly different from the estimated goodness-of-fit for another model. The MST extends the classical generalized likelihood ratio test, is valid in the presence of model misspecification, and is applicable to situations involving nonnested probability models. Simulation studies designed to illustrate the concept of the MST and its conservative decision rule (relative to the MSC method) are also presented. Copyright 2000 Academic Press.},
author = {Golden, Rm},
doi = {10.1006/jmps.1999.1281},
issn = {0022-2496},
journal = {Journal of mathematical psychology},
month = mar,
number = {1},
pages = {153--170},
pmid = {10733862},
title = {{Statistical Tests for Comparing Possibly Misspecified and Nonnested Models.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10733862},
volume = {44},
year = {2000}
}
@article{Wehrer,
abstract = {Abstract 
Release of contaminants from non-aqueous phase liquids (NAPLs) is often limited by the dynamic exchange with aqueous solutions governed by a priori unknown kinetic laws. Release experiments require a thorough evaluation of the potential and limitations of kinetic models to reveal release processes. In this study, we investigated the characteristic concentration-time profiles of various models for the release of contaminants from an organic phase into an aqueous solution under no flow conditions. Criteria have been tested that allow for distinction of a first order one domain, a first order two domain, a spherical diffusion model, a spherical diffusion model with a time variable diffusion coefficient, a model for diffusion in a sphere with organic film, and a model for diffusion in a sphere with an aqueous film. The results can serve to evaluate the processes potentially governing release of organic contaminants from non-aqueous liquid phases.},
author = {Wehrer, Markus and Mai, Juliane and Attinger, Sabine and Totsche, Kai U.},
doi = {10.1016/j.envpol.2013.04.029},
issn = {0269-7491},
journal = {Environmental Pollution},
keywords = {Contaminant release,Dual domain,First order kinetics,NAPL,Spherical film diffusion},
mendeley-tags = {Contaminant release,Dual domain,First order kinetics,NAPL,Spherical film diffusion},
title = {{Kinetic control of contaminant release from NAPLs – Information potential of concentration time profiles}},
url = {http://www.sciencedirect.com/science/article/pii/S0269749113002303 http://www.sciencedirect.com/science?\_ob=MiamiImageURL\&\_cid=271833\&\_user=4420\&\_pii=S0269749113002303\&\_check=y\&\_origin=article\&\_zone=toolbar\&\_coverDate=2013-May-18\&view=c\&originContentFamily=serial\&wchp=dGLbVBA-zSkWz\&md5=67e73221fff5f52dcd1403f0d63cd865\&pid=1-s2.0-S0269749113002303-main.pdf}
}
@article{Goldberger1962,
abstract = {When interdependence of disturbances is present in a regression model, the pattern of sample residuals contains information which is useful in prediction of post-sample drawings. This information, which is often overlooked, is exploited in the best linear unbiased predictor derived here. The gain in efficiency associated with using this predictor instead of the usual expected value estimator may be substantial.},
author = {Goldberger, Arthur S.},
doi = {10.2307/2281645},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/QV3XPZ84/Goldberger - 1962 - Best Linear Unbiased Prediction in the Generalized.pdf:pdf},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
month = jun,
number = {298},
pages = {369--375},
title = {{Best Linear Unbiased Prediction in the Generalized Linear Regression Model}},
url = {http://www.jstor.org/stable/2281645 http://www.jstor.org/stable/pdfplus/2281645.pdf?acceptTC=true},
volume = {57},
year = {1962}
}
@article{O'Brien2013,
abstract = {Quantifying the proportion of the river hydrograph derived from the different hydrological pathways is essential for understanding the behaviour of a catchment. This paper describes a new approach using the output from Master Recession Curve (MRC) analysis to inform a new algorithm based on the Lyne and Hollick ‘one-parameter’ signal analysis filtering algorithm. This approach was applied to six catchments (including two subcatchments of these) in Ireland. The conceptual model for each catchment consists of four main flow pathways: overland flow, interflow, shallow groundwater and deep groundwater. The results were compared with those of the MRC analysis, a recharge coefficient approach developed in Ireland and the semi-distributed, lumped and deterministic hydrological model NAM. The new algorithm removes the ‘free variable’ aspect that is typically associated with filtering algorithms and provides a means of estimating the contribution of each pathway that is consistent with the results of hydrograph separation in catchments that are dominated by quick response pathways. These types of catchments are underlain by poorly productive aquifers that are not capable of providing large baseflows in the river. Such aquifers underlie over 73\% of Ireland, ensuring that this new algorithm is applicable in the majority of catchments in Ireland and potentially in those catchments internationally that are strongly influenced by the quick-responding hydrological pathways. This article is protected by copyright. All rights reserved.},
author = {O'Brien, Ronan J. and Misstear, Bruce D. and Gill, Laurence W. and Johnston, Paul M. and Flynn, Raymond},
doi = {10.1002/hyp.10105},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/43Z2FSW6/abstract.html:html;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/NFMHRVEG/O'Brien et al. - 2013 - Quantifying flows along hydrological pathways by a.pdf:pdf},
issn = {1099-1085},
journal = {Hydrological Processes},
keywords = {Master Recession Curve,NAM lumped hydrological model,hydrograph separation,signal analysis filtering algorithms},
language = {en},
mendeley-tags = {Master Recession Curve,NAM lumped hydrological model,hydrograph separation,signal analysis filtering algorithms},
pages = {n/a--n/a},
title = {{Quantifying flows along hydrological pathways by applying a new filtering algorithm in conjunction with master recession curve analysis}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/hyp.10105/abstract http://onlinelibrary.wiley.com/store/10.1002/hyp.10105/asset/hyp10105.pdf?v=1\&t=hof1mfh5\&s=801354227bd6b2fab63d0b535b17fb39aeb43e08},
year = {2013}
}
@article{Freyberg1986,
abstract = {The three-dimensional movement of a tracer plume containing bromide and chloride is investigated using the data base from a large-scale natural gradient field experiment on groundwater solute transport. The analysis focuses on the zeroth-, first-, and second-order spatial moments of the concentration distribution. These moments define integrated measures of the dissolved mass, mean solute velocity, and dispersion of the plume. Moments are estimated from the point observations using quadrature approximations tailored to the density of the sampling network. The estimators appear to be robust, with acceptable sampling variability. Estimates of the mass in solution for both bromide and chloride demonstrate that the tracers behaved conservatively, as expected. Analysis of the first-order moment estimates indicates that the experimental tracer plumes traveled along identical trajectories. The horizontal trajectory is linear and aligned with the hydraulic gradient. The vertical trajectory is curvilinear, concave upward. The total vertical displacement is small, however, so that the vertical component of the mean solute velocity vector is negligible. The estimated mean solute velocity is identical for both tracers (0.091 m/day) and is spatially and temporally uniform for the first 647 days of travel time. After 647 days of transport, the plume apparently encountered a relatively large-scale heterogeneity in the velocity field, leading to a distinct vertical layering, and slowing the rate of advance of the center of mass of the plume as a whole. The estimated horizontal components of the covariance tensor evolve over time in a manner consistent with the qualitative shape changes observed from plots of the concentration data. The major principal axis, initially aligned roughly perpendicular to the hydraulic gradient, rotates smoothly over time until it is nearly aligned with the mean solute velocity vector, as the plume itself elongates and orients its long axis with the direction of movement. Plots of the components of the covariance tensor as functions of time show evidence of what is commonly called “scale-dependent” dispersion: the rate of growth of the covariance over time is not linear. The theoretical results of G. Dagan (1984) calibrate well to the estimated covariance data for the first 647 days of transport. The calibrated values of the parameters of the hydrualic conductivity distribution closely match independently measured values from the site. The asymptotic longitudinal dispersivity obtained from the calibration is 0.49 m, although asymptotic conditions were apparently not reached. The estimated covariance terms for the last sampling session, 1038 days after injection, are inconsistent with the earlier data and with the Dagan model, particularly for the transverse and off-diagonal components. This behavior is probably attributable to the observed large-scale heterogeneity in the velocity field.},
author = {Freyberg, David L.},
doi = {10.1029/WR022i013p02031},
issn = {1944-7973},
journal = {Water Resources Research},
language = {en},
number = {13},
pages = {2031--2046},
shorttitle = {A natural gradient experiment on solute transport },
title = {{A natural gradient experiment on solute transport in a sand aquifer: 2. Spatial moments and the advection and dispersion of nonreactive tracers}},
url = {http://onlinelibrary.wiley.com/doi/10.1029/WR022i013p02031/abstract http://onlinelibrary.wiley.com/doi/10.1029/WR022i013p02031/full http://onlinelibrary.wiley.com/store/10.1029/WR022i013p02031/asset/wrcr4160.pdf?v=1\&t=hl1p0sht\&s=4a57e0b29315f0a7a17b4b2a3208d45063a57c8a},
volume = {22},
year = {1986}
}
@article{Robinson1995a,
author = {Robinson, Justin S. and Sivapalan, Murugesu and Snell, John D.},
journal = {Water Resources Research},
number = {12},
pages = {3089--3101},
title = {{On the relative roles of hillslope processes, channel routing, and network geomorphology in the hydrologic response}},
url = {http://cleveland2.ce.ttu.edu/documents/copyright/R-AUTHORS/WRR\_1995\_V31\_N12/wrr\_1995\_V31\_N12.pdf},
volume = {31},
year = {1995}
}
@article{Zehe2004b,
author = {Zehe, Erwin and Bl\"{o}schl, G\"{u}nter},
doi = {10.1029/2003WR002869},
issn = {00431397},
journal = {Water Resources Research},
month = oct,
number = {10},
pages = {n/a--n/a},
title = {{Predictability of hydrologic response at the plot and catchment scales: Role of initial conditions}},
url = {http://doi.wiley.com/10.1029/2003WR002869},
volume = {40},
year = {2004}
}
@article{El-Hani2000,
author = {El-Hani, Charbel Ni\~{n}o and Emmeche, Claus},
journal = {Theory in biosciences},
number = {3},
pages = {234--275},
shorttitle = {On some theoretical grounds for an organism-center},
title = {{On some theoretical grounds for an organism-centered biology: property emergence, supervenience, and downward causation}},
url = {http://www.springerlink.com/index/6115516XK5640WXN.pdf},
volume = {119},
year = {2000}
}
@article{Musner,
abstract = {Vegetation plays a major role in controlling the fate of contaminants in natural and constructed wetlands. Estimating the efficiency of contaminant removal of a wetland requires separate knowledge of the residence time statistics in the main flow channels, where the flow velocity is relatively higher, and in the more densely vegetated zones, where the velocity is smaller and most of the biochemical transformations occur. A conceptual wetland characterized by a main flow channel (MFC) and lateral vegetated zones (LVZs) is modeled here using a two-dimensional depth-averaged hydrodynamic and advection-dispersion model. The effect of vegetation is described as a flow resistance represented in the hydrodynamic model as a function of the stem density. Simulations are performed for a given flow discharge and for increasing values of the ratio between the vegetation density in the LVZs and in the MFC. Residence time distributions (RTDs) of a non-reactive tracer are derived from numerical simulations of the solute breakthrough curves (BTCs) resulting from a continuous concentration input. Results show that increasing vegetation densities produce an increasingly pronounced bimodality of the RTDs. At longer times, the RTDs decrease exponentially, with different timescales depending on the stem density ratio and other system parameters. The overall residence time distribution can be decomposed into a first component associated with the relatively fast transport in the MFC, and a second component associated with the slower transport in the LVZs. The weight of each temporal component is related to the exchange flux at the MFC-LVZ interface. A one-dimensional transport model is proposed that is capable to reproduce the RTDs predicted by the depth-averaged model, and the relationship between model and system parameters is investigated using a combination of direct and inverse modeling approaches.},
author = {Musner, T. and Bottacin-Busolin, A. and Zaramella, M. and Marion, A.},
doi = {10.1016/j.jhydrol.2014.04.043},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/WB7XAZ7Z/Musner et al. - A contaminant transport model for wetlands account.pdf:pdf},
issn = {0022-1694},
journal = {Journal of Hydrology},
keywords = {One-dimensional model,Residence time distribution,STIR-DTD,Shallow water model,Vegetation density,Wetland channelization},
mendeley-tags = {One-dimensional model,Residence time distribution,STIR-DTD,Shallow water model,Vegetation density,Wetland channelization},
title = {{A contaminant transport model for wetlands accounting for distinct residence time bimodality}},
url = {http://www.sciencedirect.com/science/article/pii/S0022169414003175 http://www.sciencedirect.com/science/article/pii/S0022169414003175/pdfft?md5=08c12f66a456f1986acf4fc46aef2a86\&pid=1-s2.0-S0022169414003175-main.pdf}
}
@article{Bathurst1992,
abstract = {Current and projected UK activities with the Syst\`{e}me Hydrologique Europ\'{e}en (SHE) hydrological modelling system are examined. Development of the SHE arose from the need for a new modelling approach for use in assessing the environmental impacts of river basin development and the system is particularly suited to predicting the impacts of land use and climatic changes and to applications to basins with sparse data sets. the basic hydrology model is now being developed into a powerful contaminant and sediment transport modelling system called SHETRAN-UK and components are also being proposed to account for landslide and gully erosion. Applications of the SHE have been made at spatial scales ranging from 30 m2 to 5000 km2 and in a variety of environments. These have demonstrated an ability to achieve calibration on the basis of short time series records and field evaluation of parameters, to provide multiple outputs on a spatially and temporally distributed basis, and to explore basin response mechanisms. They have also indicated the importance of integrating field measurements within the calibration process. the effect of the scale of model grids on parameter evaluation and on simulation results still needs to be investigated and there is a need for field process studies in areas where there is a poor understanding, to improve certain of the process representations within the SHE. However, new ideas are being explored to account for subgrid spatial variability in parameter values and to develop a validation methodology for testing the predictive capability of the SHE. Future developments will include the use of geographical information systems and data processing packages to aid data handling, expert systems to improve the efficiency of calibration, and parallel processing and other new computational techniques. an expanding range of applications will see physically based hydrological modelling systems at the core of decision support systems and integrated at the continental scale with general circulation modelling systems.},
annote = {
        From Duplicate 2 ( 
        
          Future of distributed modelling: The Systeme Hydrologique Europeen
        
         - Bathurst, J. C.; O'connell, P. E. )

        
        

        

        

      },
author = {Bathurst, J. C. and O'connell, P. E.},
doi = {10.1002/hyp.3360060304},
issn = {1099-1085},
journal = {Hydrological Processes},
keywords = {Calibration/validation,Catchment studies,Decision support systems,Impact studies,Modelling,Parameter evaluation,Spatial scale,Spatial variability},
language = {en},
mendeley-tags = {Calibration/validation,Catchment studies,Decision support systems,Impact studies,Modelling,Parameter evaluation,Spatial scale,Spatial variability},
number = {3},
pages = {265--277},
shorttitle = {Future of distributed modelling},
title = {{Future of distributed modelling: The Systeme Hydrologique Europeen}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/hyp.3360060304/abstract http://onlinelibrary.wiley.com/doi/10.1002/hyp.3360060304/full http://onlinelibrary.wiley.com/store/10.1002/hyp.3360060304/asset/3360060304\_ftp.pdf?v=1\&t=hfex148u\&s=140ee931d5aa523c024e565b38c9beac7b573bbc},
volume = {6},
year = {1992}
}
@article{Belcher1994,
abstract = {An increasingly valuable tool for modelling irregularly sampled time series data is the continuous time autoregressive model. The natural parameters in this model are the coefficients of the linear stochastic differential equation describing the process which gives rise to the data. A transformation of these parameters is introduced, based on the Cayley-Hamilton transformation. The new parameter space is identical with that of discrete time autoregressive models. The model is also modified by the introduction of prescribed moving average terms. The resulting modelling improvements include rapid and reliable convergence of parameter estimates and the ability to select the model order by testing whether the highest order coefficient is 0. A geophysical and a medical application illustrate the detection of periodicities in data by using the spectrum of the fitted model.},
author = {Belcher, J. and Hampton, J. S. and Wilson, G. Tunnicliffe},
issn = {00359246},
journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
language = {English},
number = {1},
pages = {pp. 141--155},
title = {{Parameterization of Continuous Time Autoregressive Models for Irregularly Sampled Time Series Data}},
url = {http://www.jstor.org/stable/2346034},
volume = {56},
year = {1994}
}
@article{Murray2007,
abstract = {Numerical models can be useful for explaining poorly understood phenomena or for reliable quantitative predictions. When modeling a multi-scale system, a ‘top-down’ approach—basing models on emergent variables and interactions, rather than explicitly on the much faster and smaller scale processes that give rise to them—facilitates both goals. Parameterizations representing emergent interactions range from highly simplified and abstracted to more quantitatively accurate. Empirically based large-scale parameterizations lead more reliably to accurate large-scale behavior than do parameterizations of much smaller scale processes. Conversely, purposefully simplified representations of model interactions can enhance a model's utility for explanation, clarifying the key feedbacks leading to an enigmatic behavior. For such potential insights to be relevant, the interactions in the model need to correspond to those in the ‘real’ system in some straightforward way. Such a correspondence usually holds for models constructed for predictive purposes, although this is not a requirement. The goals motivating a modeling endeavor help determine the most appropriate modeling strategies, as well as the most appropriate criteria for judging model usefulness.},
author = {Murray, A. Brad},
doi = {10.1016/j.geomorph.2006.10.020},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/GV96EGEA/Murray - 2007 - Reducing model complexity for explanation and pred.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/KGAPBD9T/Murray - 2007 - Reducing model complexity for explanation and pred.pdf:pdf},
issn = {0169-555X},
journal = {Geomorphology},
keywords = {Cellular models,Complex systems,Complexity,Emergence,Modeling,Numerical model,Reductionism},
mendeley-tags = {Cellular models,Complex systems,Complexity,Emergence,Modeling,Numerical model,Reductionism},
month = oct,
number = {3–4},
pages = {178--191},
series = {Reduced-Complexity Geomorphological Modelling for River and Catchment Management},
title = {{Reducing model complexity for explanation and prediction}},
url = {http://www.sciencedirect.com/science/article/pii/S0169555X07001286 http://www.sciencedirect.com/science/article/pii/S0169555X07001286/pdfft?md5=4eac5c159479237afbd2fa88ac7829c1\&pid=1-s2.0-S0169555X07001286-main.pdf},
volume = {90},
year = {2007}
}
@article{Koch1986,
abstract = {ABSTRACT: Hydrologic variables are related through a complex set of dynamic processes. Due to this complexity, empirical, usually statistical, models are used for the synthesis of records or extentions of short-term data. Two statistical models applied are the power function and the exponential function of a hydrologic variable expressed in terms of streamflow. Parameters are usually estimated using least squares analysis on a linear relationship between a logarithmic transformation of the variables. This procedure produces biased results when used to predict an individual value or the long-term mean. Assuming the errors of the linear model are normally distributed, the bias is derived and is shown to result from the inverse transformation process. For cases where the errors are not normal, a nonparametric approach is used to estimate the bias. Evaluation of the implications for water quality, sediment and streamflow forecasting show the magnitude of the bias to vary with the particular application and to be significant in a few cases. Use of this simple technique for sediment discharge did not provide accurate results and should be questioned in general. Since no general conclusions can be drawn from this study as to when the bias is significant, evaluation in each situation is recommended as standard practice in hydrologic regression when a transformation is applied.},
author = {Koch, Roy W. and Smillie, Gary M.},
doi = {10.1111/j.1752-1688.1986.tb00744.x},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/TWUTMSGH/Koch and Smillie - 1986 - Bias in Hydrologic Prediction Using Log-Transforme.html:html},
issn = {1752-1688},
journal = {JAWRA Journal of the American Water Resources Association},
keywords = {bias correction,regression modeling,transformation bias},
language = {en},
mendeley-tags = {bias correction,regression modeling,transformation bias},
number = {5},
pages = {717--723},
title = {{Bias in Hydrologic Prediction Using Log-Transformed Regression Models1}},
url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1752-1688.1986.tb00744.x/abstract},
volume = {22},
year = {1986}
}
@article{Loague2004,
author = {Loague, Keith and VanderKwaak, Joel E.},
journal = {Hydrological Processes},
number = {15},
pages = {2949--2956},
shorttitle = {Physics-based hydrologic response simulation},
title = {{Physics-based hydrologic response simulation: Platinum bridge, 1958 Edsel, or useful tool}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/hyp.5737/abstract http://pangea.stanford.edu/~keith/108.pdf},
volume = {18},
year = {2004}
}
@article{Beauchamp1973,
abstract = {Experience with biological data, such as dimensions of organisms, often confirms that logarithmic transformations should precede the testing of hypotheses about regression relations. However, estimates also may be needed in terms of untransformed variables. Just taking antilogarithms of values from a log-log regression line or function leads to biased estimates. This note compares corrections for this bias, and includes an example relating mass of tree parts (bole, branches, and leaves) to tree diameter of tulip poplar (Liriodendron tulipifera L.) in Oak Ridge, Tennessee, forests. An Appendix summarizes derivation of exact and approximate unbiased estimators of expected values from log-antilog regression, and of variance around the unbiased regression line.},
author = {Beauchamp, John J. and Olson, Jerry S.},
doi = {10.2307/1934208},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/CBK7RZ6R/Beauchamp and Olson - 1973 - Corrections for Bias in Regression Estimates After.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/33AR8QBX/1934208.html:html},
issn = {0012-9658},
journal = {Ecology},
month = nov,
number = {6},
pages = {1403--1407},
title = {{Corrections for Bias in Regression Estimates After Logarithmic Transformation}},
url = {http://www.jstor.org/stable/1934208 http://www.jstor.org/discover/10.2307/1934208?uid=3739560\&uid=2\&uid=4\&uid=3739256\&sid=21103119743113 http://www.jstor.org/stable/pdfplus/1934208.pdf?acceptTC=true},
volume = {54},
year = {1973}
}
@article{Beven2001c,
author = {Beven, Keith J.},
doi = {10.1002/hyp.500},
issn = {0885-6087},
journal = {Hydrological Processes},
month = oct,
number = {15},
pages = {3069--3072},
title = {{On explanatory depth and predictive power}},
url = {http://doi.wiley.com/10.1002/hyp.500},
volume = {15},
year = {2001}
}
@incollection{Osmani2011,
abstract = {The built environment consumes more natural resources than necessary and therefore generates a large amount of waste. This chapter sheds light on the idea of rethinking construction waste management by reengineering processes and practices to reduce construction waste at source. It examines the concept of waste and definitions. Rethinking waste management in construction requires adopting ‘cyclic’ rather than ‘linear’ approach to design and construction. This requires re-engineering current practice to contribute to a cleaner environment through efficient and cost effective sustainable waste minimization strategies. Following this, the chapter discusses construction waste quantification and source evaluation. It also explores current thinking on construction waste research and appraises the current construction waste management and minimization status in the United Kingdom (UK) in terms of drivers and pressures for change, design and onsite practices, and challenges and enablers. For waste minimization to be effective and self-sustaining, it is important that all stakeholders along the construction supply chain embrace a more proactive approach in dealing with waste. In recognition of the responsibility of the architectural profession, through its leading role in project management and a key player in the construction industry, architects should move beyond the concept of eco-efficiency through bolt-on environmental strategies and strive to adopt eco-effective practices by implementing a holistic approach to design out waste, which will be reinforced in tender documents and implemented during the construction stage, in addition to the capture and dissemination of lessons learnt to inform construction waste reduction baselines and benchmarking in future projects.},
address = {Boston},
author = {Osmani, Mohamed},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/2MJ45A4Z/Osmani - 2011 - Chapter 15 - Construction Waste.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {207--218},
publisher = {Academic Press},
title = {{Chapter 15 - Construction Waste}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100154 http://www.sciencedirect.com/science/article/pii/B9780123814753100154/pdfft?md5=98ff17a66a60ad7135d37f4d30d081c1\&pid=3-s2.0-B9780123814753100154-main.pdf},
year = {2011}
}
@article{Arlot2010c,
abstract = {Used to estimate the risk of an estimator or to perform model selection, cross-validation is a widespread strategy because of its simplicity and its (apparent) universality. Many results exist on model selection performances of cross-validation procedures. This survey intends to relate these results to the most recent advances of model selection theory, with a particular emphasis on distinguishing empirical statements from rigorous theoretical results. As a conclusion, guidelines are provided for choosing the best cross-validation procedure according to the particular features of the problem in hand.},
author = {Arlot, Sylvain and Celisse, Alain},
doi = {10.1214/09-SS054},
issn = {1935-7516},
journal = {Statistics Surveys},
keywords = {Model selection,cross-validation,leave-one-out},
language = {EN},
mendeley-tags = {Model selection,cross-validation,leave-one-out},
pages = {40--79},
title = {{A survey of cross-validation procedures for model selection}},
url = {http://projecteuclid.org/euclid.ssu/1268143839},
volume = {4},
year = {2010}
}
@article{Efron1997,
abstract = {A training set of data has been used to construct a rule for predicting future responses. What is the error rate of this rule? This is an important question both for comparing models and for assessing a final selected model. The traditional answer to this question is given by cross-validation. The cross-validation estimate of prediction error is nearly unbiased but can be highly variable. Here we discuss bootstrap estimates of prediction error, which can be thought of as smoothed versions of cross-validation. We show that a particular bootstrap method, the .632+ rule, substantially outperforms cross-validation in a catalog of 24 simulation experiments. Besides providing point estimates, we also consider estimating the variability of an error rate estimate. All of the results here are nonparametric and apply to any possible prediction rule; however, we study only classification problems with 0-1 loss in detail. Our simulations include "smooth" prediction rules like Fisher's linear discriminant function and unsmooth ones like nearest neighbors.},
author = {Efron, Bradley and Tibshirani, Robert},
doi = {10.2307/2965703},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/ZCM7X43R/Efron and Tibshirani - 1997 - Improvements on Cross-Validation The .632+ Bootst.pdf:pdf},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
month = jun,
number = {438},
pages = {548--560},
shorttitle = {Improvements on Cross-Validation},
title = {{Improvements on Cross-Validation: The .632+ Bootstrap Method}},
url = {http://www.jstor.org/stable/2965703 http://www.jstor.org/stable/pdfplus/2965703.pdf?acceptTC=true},
volume = {92},
year = {1997}
}
@book{Shuttleworth2012,
abstract = {Both hydrologists and meteorologists need to speak a common scientific language, and this has given rise to the new scientific discipline of hydrometeorology, which deals with the transfer of water and energy across the land/atmosphere interface. Terrestrial Hydrometeorology is the first graduate-level text with sufficient breadth and depth to be used in hydrology departments to teach relevant aspects of meteorology, and in meteorological departments to teach relevant aspects of hydrology, and to serve as an introductory text to teach the emerging discipline of hydrometeorology. The book will be essential reading for graduate students studying surface water hydrology, meteorology, and hydrometeorology. It can also be used in advanced undergraduate courses, and will be welcomed by academic and professional hydrologists and meteorologists worldwide. Additional resources for this book can be found at: http://www.wiley.com/go/shuttleworth/hydrometeorology.},
author = {Shuttleworth, W. James},
isbn = {9780470659380, 9781119951933},
month = feb,
title = {{Terrestrial Hydrometeorology}},
url = {http://onlinelibrary.wiley.com/book/10.1002/9781119951933},
year = {2012}
}
@techreport{HanfordDose1994,
author = {{The Technical Steering Panel of the Hanford Environmental Dose Reconstruction Project}},
month = apr,
pages = {63},
title = {{Summary: Radiation Dose Estimates from Hanford Radioactive Material Releases to the Air and the Columbia River}},
url = {http://www.cdc.gov/nceh/radiation/hanford/dose.pdf},
year = {1994}
}
@incollection{Cressie2005,
abstract = {Lognormality of spatial data occurs commonly enough for it to warrant continued study; contemporary statistical and computational methodologies can shed new light on the old problem of block kriging for lognormal processes. There are a number of proposals available for block kriging, many of them discussed in an unpublished, 43-page, Centre de Morphologie Mathematique “note” written by Georges Matheron in 1974. Loosely translated, the title of the note is, “The proportional effect and lognormality or: The return of the sea serpent”. Our paper is meant to rein in the sea serpent, by comparing an optimal-prediction-based predictor with a permanence-approximation-based predictor, in the context of statistics for spatial lognormal data.},
author = {Cressie, Noel and Pavlicov\'{a}, Martina},
editor = {Leuangthong, Oy and Deutsch, Clayton V.},
isbn = {978-1-4020-3515-9, 978-1-4020-3610-1},
keywords = {Computational Intelligence,Earth Sciences- general,Empirical Bayes,Geostatistics,Geotechnical Engineering \& Applied Earth Sciences,MSPE,Statistics for Engineering- Physics- Computer Scie,optimal spatial prediction},
mendeley-tags = {Computational Intelligence,Earth Sciences- general,Empirical Bayes,Geostatistics,Geotechnical Engineering \& Applied Earth Sciences,MSPE,Statistics for Engineering- Physics- Computer Scie,optimal spatial prediction},
month = jan,
pages = {1027--1036},
publisher = {Springer Netherlands},
series = {Quantitative Geology and Geostatistics},
shorttitle = {Lognormal Kriging},
title = {{Lognormal Kriging: Bias Adjustment and Kriging Variances}},
url = {http://link.springer.com/chapter/10.1007/978-1-4020-3610-1\_107 http://link.springer.com/content/pdf/10.1007\%2F978-1-4020-3610-1\_107.pdf},
year = {2005}
}
@book{UnitedNations2011,
abstract = {Exposure to ionizing radiation arises from sources such as medical diagnostic and therapeutic procedures; radon and other natural background radiation; nuclear electricity generation; accidents such as the one at Chernobyl in 1986; and occupations that increase exposure to artificial or natural sources of radiation. Since the establishment of the United Nations Scientific Committee on the Effects of Atomic Radiation by General Assembly resolution 913 (X) of 3 December 1955, the mandate of the Committee has been to undertake broad assessments of the sources of ionizing radiation and its effects on human health and the environment. In pursuit of its mandate, the Committee thoroughly reviews and evaluates global and regional exposures to radiation, and also evaluates of evidence of radiation-induced health effects in exposed groups, including surviviors of the atomic bombings in Japan. The Committee also reviews advances in the understanding of the biological mechanisms by which radiation-induced effects on health or on the environment can occur. Those assessments provide the scientific foundation used, inter alia, by the relevant agencies of the United Nations system in formulating international standards for the protection of the general public and workers against ionizing radiation: those standards, in turn, are linked to important legal and regulatory instruments.},
address = {New York},
author = {{United Nations} and {Scientific Committee on the Effects of Atomic Radiation}},
isbn = {9789216420109 9216420103},
keywords = {Folder - ch1},
language = {Text in English, French, Spanish, Russian, Chinese, and Arabic.},
mendeley-tags = {Folder - ch1},
publisher = {United Nations},
shorttitle = {Report of the United Nations Scientific Committee},
title = {{Report of the United Nations Scientific Committee on the Effects of Atomic Radiation 2010: fifty-seventh session, includes scientific report, Summary of low-dose radiation effects on health}},
url = {http://www.unscear.org/docs/reports/2010/UNSCEAR\_2010\_Report\_M.pdf},
year = {2011}
}
@techreport{Jannik1994,
author = {Jannik, G. T.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/8V97A32R/Jannik - 1994 - Savannah River Site Environmental Monitoring Plan..pdf:pdf},
institution = {Westinghouse Savannah River Co., Aiken, SC (United States)},
keywords = {and safety,compliance,contamination regulations,energy planning,environment,environmental sciences,gaseous wastes,health,liquid wastes,nuclear fuel cycle and fuel materials,planning 053002,policy and economy,radiation doses,radiation monitoring,radioactive effluents,savannah river plant,site resource and use studies},
language = {English},
mendeley-tags = {and safety,compliance,contamination regulations,energy planning,environment,environmental sciences,gaseous wastes,health,liquid wastes,nuclear fuel cycle and fuel materials,planning 053002,policy and economy,radiation doses,radiation monitoring,radioactive effluents,savannah river plant,site resource and use studies},
month = oct,
shorttitle = {Savannah River Site Environmental Monitoring Plan.},
title = {{Savannah River Site Environmental Monitoring Plan. Volume 1, Section 1000 Addendum: Revision 3}},
url = {http://www.osti.gov/scitech/biblio/10188805 http://www.osti.gov/scitech/servlets/purl/10188805},
year = {1994}
}
@article{Suk2013,
abstract = {The paper presents a semianalytical method to solve the multispecies reactive solute-transport equation coupled with a sequential first-order reaction network under spatially or temporally varying flow velocities and dispersion coefficients. This method employs the generalized integral transform technique (GITT) and general linear transformation method by Clement [2001] to transform the set of coupled multispecies reactive transport equations into a set of independent uncoupled equations and to solve these independent equations for spatially or temporally varying flow velocities and dispersion coefficients, as well for temporally varying inlet concentration. The proposed semianalytical solution is compared against previously published analytical solutions of Srinivasan and Clement [2008b] and van Genuchten [1985]. An example is used to show application of the solution to a hypothetical multilayered medium. The solution of proposed approach is compared also with a numerical solution using the 2DFATMIC. Three scenarios are illustrated to show the capabilities of the proposed semianalytical method to deal with aquifer heterogeneity and transient situations. We also show a practical implementation of the solution to an actual field, single-well push-pull test (PPT) example designed to obtain the concentration distribution of reactants consumed and products formed at the end of the injection phase.},
author = {Suk, Heejun},
doi = {10.1002/wrcr.20230},
issn = {1944-7973},
journal = {Water Resources Research},
keywords = {GITT,General linear-transformation method,Multispecies transport equation,Semianalytical solution,Sequential first-order reaction,Spatially or temporally},
language = {en},
mendeley-tags = {GITT,General linear-transformation method,Multispecies transport equation,Semianalytical solution,Sequential first-order reaction,Spatially or temporally},
pages = {n/a--n/a},
title = {{Developing semianalytical solutions for multispecies transport coupled with a sequential first-order reaction network under variable flow velocities and dispersion coefficients}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/wrcr.20230/abstract http://onlinelibrary.wiley.com/store/10.1002/wrcr.20230/asset/wrcr20230.pdf?v=1\&t=hfaf7q98\&s=7bc1dd366b580bf676208b9f427e818264cc3660},
year = {2013}
}
@article{Cherkassky2002,
abstract = {We discuss the problem of modelcomplexity control also known as modelselection. This problem frequently arises inthe context of predictive learning and adaptiveestimation of dependencies from finite data.First we review the problem of predictivelearning as it relates to model complexitycontrol. Then we discuss several issuesimportant for practical implementation ofcomplexity control, using the frameworkprovided by Statistical Learning Theory (orVapnik-Chervonenkis theory). Finally, we showpractical applications of Vapnik-Chervonenkis(VC) generalization bounds for model complexitycontrol. Empirical comparisons of differentmethods for complexity control suggestpractical advantages of using VC-based modelselection in settings where VC generalizationbounds can be rigorously applied. We also arguethat VC-theory provides methodologicalframework for complexity control even when itstechnical results can not be directly applied.},
author = {Cherkassky, Vladimir},
doi = {10.1023/A:1015007927558},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/4Z3IH25E/Cherkassky - 2002 - Model complexity control and statistical learning .pdf:pdf},
issn = {1567-7818, 1572-9796},
journal = {Natural Computing},
keywords = {Artificial Intelligence (incl. Robotics),Evolutionary Biology,Model selection,Nonlinear Dynamics- Complex Systems- Chaos- Neural,Processor Architectures,Theory of Computation,VC-generalization bounds,complexity control,prediction risk,predictive learning,signal denoising,statistical learning theory,wavelet thresholding},
language = {en},
mendeley-tags = {Artificial Intelligence (incl. Robotics),Evolutionary Biology,Model selection,Nonlinear Dynamics- Complex Systems- Chaos- Neural,Processor Architectures,Theory of Computation,VC-generalization bounds,complexity control,prediction risk,predictive learning,signal denoising,statistical learning theory,wavelet thresholding},
month = mar,
number = {1},
pages = {109--133},
title = {{Model complexity control and statistical learning theory}},
url = {http://link.springer.com/article/10.1023/A\%3A1015007927558 http://link.springer.com/content/pdf/10.1023\%2FA\%3A1015007927558.pdf},
volume = {1},
year = {2002}
}
@inproceedings{Papadimitriou2003a,
abstract = {Outlier detection is an integral part of data mining and has attracted much attention recently [M. Breunig et al., (2000)], [W. Jin et al., (2001)], [E. Knorr et al., (2000)]. We propose a new method for evaluating outlierness, which we call the local correlation integral (LOCI). As with the best previous methods, LOCI is highly effective for detecting outliers and groups of outliers (a.k.a. micro-clusters). In addition, it offers the following advantages and novelties: (a) It provides an automatic, data-dictated cutoff to determine whether a point is an outlier-in contrast, previous methods force users to pick cut-offs, without any hints as to what cut-off value is best for a given dataset. (b) It can provide a LOCI plot for each point; this plot summarizes a wealth of information about the data in the vicinity of the point, determining clusters, micro-clusters, their diameters and their inter-cluster distances. None of the existing outlier-detection methods can match this feature, because they output only a single number for each point: its outlierness score, (c) Our LOCI method can be computed as quickly as the best previous methods, (d) Moreover, LOCI leads to a practically linear approximate method, aLOCI (for approximate LOCI), which provides fast highly-accurate outlier detection. To the best of our knowledge, this is the first work to use approximate computations to speed up outlier detection. Experiments on synthetic and real world data sets show that LOCI and aLOCI can automatically detect outliers and micro-clusters, without user-required cut-offs, and that they quickly spot both expected and unexpected outliers.},
author = {Papadimitriou, S. and Kitagawa, H. and Gibbons, P.B. and Faloutsos, C.},
doi = {10.1109/ICDE.2003.1260802},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/DJN3QRS2/Papadimitriou et al. - 2003 - LOCI fast outlier detection using the local corre.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/TV7NZEJA/abs\_all.html:html},
keywords = {Data engineering,LOCI,aLOCI,approximate LOCI,approximation theory,correlation theory,data mining,inter-cluster distance,linear approximate method,local correlation integral,micro-cluster,outlier detection,real world data set,statistical analysis,synthetic data set,very large databases},
mendeley-tags = {Data engineering,LOCI,aLOCI,approximate LOCI,approximation theory,correlation theory,data mining,inter-cluster distance,linear approximate method,local correlation integral,micro-cluster,outlier detection,real world data set,statistical analysis,synthetic data set,very large databases},
month = mar,
pages = {315--326},
shorttitle = {LOCI},
title = {{LOCI: fast outlier detection using the local correlation integral}},
url = {http://ieeexplore.ieee.org/ielx5/8910/28179/01260802.pdf?tp=\&arnumber=1260802\&isnumber=28179 http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1260802\&tag=1},
year = {2003}
}
@book{NationalResearchCouncil1959,
abstract = {Considerations on the Disposal of Radioactive Wastes From Nuclear-Powered Ships Into the Marine Environment},
address = {Washington, D.C.},
author = {{National Research Council}},
publisher = {The National Academies Press},
title = {{Considerations on the Disposal of Radioactive Wastes From Nuclear-Powered Ships Into the Marine Environment}},
url = {http://www.nap.edu/catalog.php?record\_id=18744},
year = {1959}
}
@book{Letcher2011l,
address = {Burlington, MA},
annote = {Machine generated contents note: 1. A History of Waste Management 2. Green Engineering and Sustainable Design Aspects of Waste Management3. Waste Regulations with special emphasis to the USA 4. Waste Collection 5. Mine Waste: A Brief Overview of Origins, Quantities and Methods of Storage6. Metal Waste 7. Radioactive Waste Management8. Municipal Waste Management 9. Waste Water: Reuse of Oriented Wastewater - Low- and High-Tech Approaches for Urban Areas10. Recovered Paper 11. Glass Waste12. Textile Waste13. Chemicals in Waste: Household Hazardous Waste 14. Reusing Non-hazardous Industrial Waste across Business Clusters15. Construction Waste 1. 16.Thermal Waste Treatment 16. Plastic solid waste (PSW) and thermo-chemical treatment 17. Air pollution (including pollution due to Coal and Oil Burning, Cement Making and Automobile exhaust pollution 18. Ocean pollution19. Electronic Waste 20. Tyres21. Battery Waste22. Medical waste 23. Agricultural Waste and Pollution 24. Military waste25. Space waste26. Hazardous Wastes 27. Land Pollution 28. Thermal Pollution29. Landfills, Yesterday, Today and Tomorrow 30. Pollution Management and Responsible Care31. Risk Assessment, Management and Accountability Epilogue Index
----------
"Preface Waste: A Handbook of Waste Management is designed to be a resource for the designer, practitioner, researcher, teacher and student. Waste is one of those entities which is defined by everyone, but not truly and completely understood by anyone. The scientist, engineer and consumer each define waste correctly, yet differently. The overriding challenge for the authors was to provide some uniformity, yet allow for the diversity of the various aspects of waste in this handbook. After all, a handbook is often the beginning of the search for information, certainly not the end. We have borrowed from all scientific disciplines, and a few humanities, to arrive at a balanced resource. And, indeed, balance is the key to environmental science and engineering"--},
editor = {Letcher, T. M. and Vallero, Daniel A.},
isbn = {9780123814753},
keywords = {Factory and trade waste,Refuse and refuse disposal},
mendeley-tags = {Factory and trade waste,Refuse and refuse disposal},
pages = {565},
publisher = {Academic Press},
shorttitle = {Waste},
title = {{Waste: a handbook for management}},
year = {2011}
}
@article{Ruggeri,
abstract = {Adequate characterization of aquifer heterogeneity is critically important for the sustainable use, protection, and remediation of groundwater resources. The combined use of hydrological and geophysical measurements is arguably the most effective means of achieving this objective. In this regard, significant progress has been made on the quantitative integration of geophysical and hydrological data at the local scale. However, the extension of such approaches to larger, more regional scales remains a major research challenge. In this paper, we demonstrate the application of a recently developed regional-scale hydrogeophysical data integration approach, which is based on Bayesian sequential simulation, to a field database from Quebec, Canada consisting of low-resolution, surface-based geoelectrical measurements as well as high-resolution direct-push and borehole-based measurements of the electrical and hydraulic conductivities. The results of our study, which involved the integration of data along an approximately 250-m-long survey line, confirm that this novel methodology, with suitable adaptation, is fully applicable to field data and has the potential of providing realistic estimates of the spatial distribution of hydraulic target parameters at the regional-scale. Equally importantly, through the generation of multiple stochastic realizations, the methodology allows for quantitative assessment of the uncertainty associated with the inferred subsurface models, which in turn is essential for interpreting subsequent predictions of the flow and transport characteristics of the studied region.},
author = {Ruggeri, Paolo and Gloaguen, Erwan and Lefebvre, Ren\'{e} and Irving, James and Holliger, Klaus},
doi = {10.1016/j.jhydrol.2014.04.031},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/TABF39AJ/Ruggeri et al. - Integration of hydrological and geophysical data b.pdf:pdf},
issn = {0022-1694},
journal = {Journal of Hydrology},
keywords = {Downhole methods,Probabilistic forecasting,hydrogeophysics,tomography},
mendeley-tags = {Downhole methods,Probabilistic forecasting,hydrogeophysics,tomography},
shorttitle = {Integration of hydrological and geophysical data b},
title = {{Integration of hydrological and geophysical data beyond the local scale: Application of Bayesian sequential simulation to field data from the Saint-Lambert-de-Lauzon site, Qu\'{e}bec, Canada}},
url = {http://www.sciencedirect.com/science/article/pii/S0022169414003059 http://www.sciencedirect.com/science/article/pii/S0022169414003059/pdfft?md5=854f85b26fe48ad221750b020a11c830\&pid=1-s2.0-S0022169414003059-main.pdf}
}
@article{Gnanadesikan1972,
abstract = {The paper gives an overview of concepts and techniques pertaining to (i) the robust estimation of multivariate location and dispersion; (ii) the analysis of two types of multidimensional residuals-namely those that occur in the context of principal components analysis as well as the more familiar residuals associated with least squares fitting; and (iii) the detection of multiresponse outliers. The emphasis is on methods for informal exploratory analysis and the coverage is both a survey of existing techniques and an attempt to propose, tentatively, some new methodology which needs further investigation and development. Some examples of use of the methods are included.},
author = {Gnanadesikan, R. and Kettenring, J. R.},
doi = {10.2307/2528963},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/ZZZVP8ZI/Gnanadesikan and Kettenring - 1972 - Robust Estimates, Residuals, and Outlier Detection.pdf:pdf},
issn = {0006-341X},
journal = {Biometrics},
month = mar,
number = {1},
pages = {81--124},
title = {{Robust Estimates, Residuals, and Outlier Detection with Multiresponse Data}},
url = {http://www.jstor.org/stable/2528963 http://www.jstor.org/stable/pdfplus/2528963.pdf?acceptTC=true},
volume = {28},
year = {1972}
}
@article{Guerrero2010a,
abstract = {Most analytical solutions available for the equations governing the advective–dispersive transport of multiple solutes undergoing sequential first-order decay reactions have been developed for infinite or semi-infinite spatial domains and steady-state boundary conditions. In this study, we present an analytical solution for a finite domain and a time-varying boundary condition. The solution was found using the Classic Integral Transform Technique (CITT) in combination with a filter function having separable space and time dependencies, implementation of the superposition principle, and using an algebraic transformation that changes the advection–dispersion equation for each species into a diffusion equation. The analytical solution was evaluated using a test case from the literature involving a four radionuclide decay chain. Results show that convergence is slower for advection-dominated transport problems. In all cases, the converged results were identical to those obtained with the previous solution for a semi-infinite domain, except near the exit boundary where differences were expected. Among other applications, the new solution should be useful for benchmarking numerical solutions because of the adoption of a finite spatial domain.},
author = {Guerrero, Jes\'{u}s S. P\'{e}rez and Skaggs, Todd H. and van Genuchten, M. Th},
doi = {10.1007/s11242-010-9553-4},
issn = {0169-3913, 1573-1634},
journal = {Transport in Porous Media},
keywords = {Analytical solution,Civil Engineering,Classical Continuum Physics,Finite domain,Geotechnical Engineering,Hydrogeology,Industrial Chemistry/Chemical Engineering,Integral transform,Multi-species transport},
language = {en},
mendeley-tags = {Analytical solution,Civil Engineering,Classical Continuum Physics,Finite domain,Geotechnical Engineering,Hydrogeology,Industrial Chemistry/Chemical Engineering,Integral transform,Multi-species transport},
month = oct,
number = {1},
pages = {171--188},
title = {{Analytical Solution for Multi-Species Contaminant Transport in Finite Media with Time-Varying Boundary Conditions}},
url = {http://link.springer.com/article/10.1007/s11242-010-9553-4 http://link.springer.com/content/pdf/10.1007/s11242-010-9553-4},
volume = {85},
year = {2010}
}
@article{Hurvich1998,
abstract = {Many different methods have been proposed to construct nonparametric estimates of a smooth regression function, including local polynomial, (convolution) kernel and smoothing spline estimators. Each of these estimators uses a smoothing parameter to control the amount of smoothing performed on a given data set. In this paper an improved version of a criterion based on the Akaike information criterion (AIC), termed AICC, is derived and examined as a way to choose the smoothing parameter. Unlike plug-in methods, AICC can be used to choose smoothing parameters for any linear smoother, including local quadratic and smoothing spline estimators. The use of AICC avoids the large variability and tendency to undersmooth (compared with the actual minimizer of average squared error) seen when other ‘classical’ approaches (such as generalized cross-validation (GCV) or the AIC) are used to choose the smoothing parameter. Monte Carlo simulations demonstrate that the AICC-based smoothing parameter is competitive with a plug-in method (assuming that one exists) when the plug-in method works well but also performs well when the plug-in approach fails or is unavailable.},
author = {Hurvich, Clifford M. and Simonoff, Jeffrey S. and Tsai, Chih-Ling},
doi = {10.1111/1467-9868.00125},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/AEK3EZMB/Hurvich et al. - 1998 - Smoothing parameter selection in nonparametric reg.pdf:pdf},
issn = {1467-9868},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
keywords = {Convolution kernel regression estimator,Local polynomial regression estimator,Plug-in method,Smoothing spline regression estimator},
language = {en},
mendeley-tags = {Convolution kernel regression estimator,Local polynomial regression estimator,Plug-in method,Smoothing spline regression estimator},
number = {2},
pages = {271--293},
title = {{Smoothing parameter selection in nonparametric regression using an improved Akaike information criterion}},
url = {http://onlinelibrary.wiley.com/doi/10.1111/1467-9868.00125/abstract http://onlinelibrary.wiley.com/store/10.1111/1467-9868.00125/asset/1467-9868.00125.pdf?v=1\&t=hru19739\&s=af7072a8433c950538b37cfa64e36546d256af79},
volume = {60},
year = {1998}
}
@article{Sun1998a,
abstract = {Health impact studies of air pollution often require estimates of pollutant concentrations at locations where monitoring data are not available, using the concentrations observed at other monitoring stations and possibly at different time periods. Recently, a Bayesian approach for such a temporal and spatial interpolation problem has been proposed by Le, Sun and Zidek (1997). One special feature of the method is that it does not require all sites to monitor the same set of pollutants. This feature is particularly relevant in environmental health studies where pollution data are often pooled together from several monitoring networks which may or may not monitor the same set of pollutants. The methodology is applied to the data in the Province of Ontario, where monthly average concentrations for summer months of nitrogen dioxide (NO2 in $\mu$g/m3), ozone (O3 in ppb), sulphur dioxide (SO2 in $\mu$g/m3) and sulfate ion (SO4 in $\mu$g/m3) are available for the period from January 1 of 1983 to December 31 of 1988 at 31 ambient monitoring sites. Detailed descriptions of spatial interpolation for air pollutant concentrations at 37 approximate centroids of Public Health Units in Ontario using all available data are presented. The methodology is empirically assessed by a cross-validation study where each of the 31 sites is successively removed and the remaining sites are used to predict its concentration levels. The methodology seems to perform well. © 1998 John Wiley \& Sons, Ltd.},
author = {Sun, Weimin and Le, Nhu D. and Zidek, James V. and Burnett, Rick},
doi = {10.1002/(SICI)1099-095X(199809/10)9:5<565::AID-ENV324>3.0.CO;2-S},
issn = {1099-095X},
journal = {Environmetrics},
keywords = {Bayesian spatial interpolation,EM algorithm,air pollution,nitrate,ozone,sulphate,sulphur dioxide},
language = {en},
mendeley-tags = {Bayesian spatial interpolation,EM algorithm,air pollution,nitrate,ozone,sulphate,sulphur dioxide},
month = sep,
number = {5},
pages = {565--586},
title = {{Assessment of a Bayesian multivariate interpolation approach for health impact studies}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/(SICI)1099-095X(199809/10)9:5<565::AID-ENV324>3.0.CO;2-S/abstract},
volume = {9},
year = {1998}
}
@incollection{Marra2011,
abstract = {Since the advent of the modern nuclear age in the 1940’s, man has effectively managed the often hazardous waste produced by nuclear processes. Expansion of nuclear energy worldwide is likely to meet increased power demands and greenhouse gas reduction targets and will result in increased radioactive waste generation. Managing this waste effectively is a critical component of a world-wide “nuclear renaissance.” Past practice has proven the wastes generated from nuclear power generation can be effectively managed using technologies that are well demonstrated at industrial scales, with decades of safe operating practices. Emphasis is necessary to ensure that future nuclear fuel cycles remain economically and environmentally competitive (as compared to other forms of energy production) and do not produce legacy waste management issues for future generations. This chapter discusses the history of nuclear waste management and provides the current “state-of-the-art” for management of all forms of nuclear waste.
Expansion of nuclear energy worldwide is necessary to meet increased power demands and greenhouse gas reduction targets. Virtually any international energy forecast predicts large growth in nuclear power generation over the next 30–50 years. The expansion of commercial nuclear power production is likely to result in increased radioactive waste generation. Managing this waste effectively is a critical component of a worldwide nuclear renaissance and is a primary consideration for future nuclear fuel cycles. Wastes generated from nuclear power generation can be effectively managed using technologies that are well demonstrated at industrial scales, with decades of safe operating practices. As the worldwide community continues to investigate advanced nuclear fuel cycles, radioactive waste management considerations are being given increased emphasis and are, in fact, being considered at the advent of proposed fuel cycles. This emphasis is necessary to ensure that future nuclear fuel cycles remain economically and environmentally competitive (as compared with other forms of energy production) and do not produce legacy waste management issues for future generations.},
address = {Boston},
author = {Marra, John E. and Palmer, Ronald A.},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/XVIBVJMD/Marra and Palmer - 2011 - Chapter 7 - Radioactive Waste Management.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {101--108},
publisher = {Academic Press},
title = {{Chapter 7 - Radioactive Waste Management}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100075 http://www.sciencedirect.com/science/article/pii/B9780123814753100075/pdfft?md5=e15f641412c07424e6782252573cea5e\&pid=3-s2.0-B9780123814753100075-main.pdf},
year = {2011}
}
@article{Janeja2010,
abstract = {Success of anomaly detection, similar to other spatial data mining techniques, relies on neighborhood definition. In this paper, we argue that the anomalous behavior of spatial objects in a neighborhood can be truly captured when both (a) spatial autocorrelation (similar behavior of nearby objects due to proximity) and (b) spatial heterogeneity (distinct behavior of nearby objects due to difference in the underlying processes in the region) are taken into consideration for the neighborhood definition. Our approach begins by generating micro neighborhoods around spatial objects encompassing all the information about a spatial object. We selectively merge these based on spatial relationships accounting for autocorrelation and inferential relationships accounting for heterogeneity, forming macro neighborhoods. In such neighborhoods, we then identify (i) spatio-temporal outliers, where individual sensor readings are anomalous, (ii) spatial outliers, where the entire sensor is an anomaly, and (iii) spatio-temporally coalesced outliers, where a group of spatio-temporal outliers in the macro neighborhood are separated by a small time lag indicating the traversal of the anomaly. We demonstrate the effectiveness of our approach in neighborhood formation and anomaly detection with experimental results in (i) water monitoring and (ii) highway traffic monitoring sensor datasets. We also compare the results of our approach with an existing approach for spatial anomaly detection.},
author = {Janeja, Vandana P. and Adam, Nabil R. and Atluri, Vijayalakshmi and Vaidya, Jaideep},
doi = {10.1007/s10618-009-0147-0},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/TG679EHS/Janeja et al. - 2010 - Spatial neighborhood based anomaly detection in se.pdf:pdf},
issn = {1384-5810, 1573-756X},
journal = {Data Mining and Knowledge Discovery},
keywords = {Artificial Intelligence (incl. Robotics),Computing Methodologies,Data Mining and Knowledge Discovery,Information Storage and Retrieval,Sensors,Spatial neighborhood,Statistics for Engineering- Physics- Computer Scie,Statistics- general,outlier detection},
language = {en},
mendeley-tags = {Artificial Intelligence (incl. Robotics),Computing Methodologies,Data Mining and Knowledge Discovery,Information Storage and Retrieval,Sensors,Spatial neighborhood,Statistics for Engineering- Physics- Computer Scie,Statistics- general,outlier detection},
month = mar,
number = {2},
pages = {221--258},
title = {{Spatial neighborhood based anomaly detection in sensor datasets}},
url = {http://link.springer.com/article/10.1007/s10618-009-0147-0 http://link.springer.com/content/pdf/10.1007\%2Fs10618-009-0147-0.pdf},
volume = {20},
year = {2010}
}
@article{Oreskes1994,
abstract = {Verification and validation of numerical models of natural systems is impossible. This is because natural systems are never closed and because model results are always nonunique. Models can be confirmed by the demonstration of agreement between observation and prediction, but confirmation is inherently partial. Complete confirmation is logically precluded by the fallacy of affirming the consequent and by incomplete access to natural phenomena. Models can only be evaluated in relative terms, and their predictive value is always open to question. The primary value of models is heuristic.},
author = {Oreskes, N and Shrader-Frechette, K and Belitz, K},
doi = {10.1126/science.263.5147.641},
issn = {0036-8075},
journal = {Science (New York, N.Y.)},
month = mar,
number = {5147},
pages = {641--6},
pmid = {17747657},
title = {{Verification, validation, and confirmation of numerical models in the Earth sciences.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17747657},
volume = {263},
year = {1994}
}
@misc{USDepartmentofCommerce,
author = {{US Department of Commerce}, NIST},
language = {EN-US},
title = {{NIST Technical Note 1297}},
url = {http://www.nist.gov/pml/pubs/tn1297/index.cfm},
urldate = {2014-04-06 20:50:53}
}
@article{Butts2004,
author = {Butts, Michael B. and Payne, Jeffrey T. and Kristensen, Michael and Madsen, Henrik},
doi = {10.1016/j.jhydrol.2004.03.042},
issn = {00221694},
journal = {Journal of Hydrology},
keywords = {automatic calibration,distributed hydrological modelling,flow,hydrological simulation uncertainty,model structure uncertainty},
month = oct,
number = {1-4},
pages = {242--266},
title = {{An evaluation of the impact of model structure on hydrological modelling uncertainty for streamflow simulation}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0022169404002471},
volume = {298},
year = {2004}
}
@book{NationalResearchCouncil2001,
abstract = {Focused attention by world leaders is needed to address the substantial challenges posed by disposal of spent nuclear fuel from reactors and high-level radioactive waste from processing such fuel. The biggest challenges in achieving safe and secure storage and permanent waste disposal are societal, although technical challenges remain. Disposition of radioactive wastes in a deep geological repository is a sound approach as long as it progresses through a stepwise decision-making process that takes advantage of technical advances, public participation, and international cooperation. Written for concerned citizens as well as policymakers, this book was sponsored by the U.S. Department of Energy, ...},
address = {Washington, D.C.},
author = {{National Research Council}},
file = {:Users/arthur/Google Drive/References/Reports/National Academies Press docs/DispositionofHighLevelWastecontinuingchallenges2001\_10119.pdf:pdf},
publisher = {The National Academies Press},
shorttitle = {Disposition of High-Level Waste and Spent Nuclear},
title = {{Disposition of High-Level Waste and Spent Nuclear Fuel: The Continuing Societal and Technical Challenges}},
url = {http://www.nap.edu/catalog.php?record\_id=10119},
year = {2001}
}
@article{Banerjee2005,
abstract = {Statisticians analyzing spatial data often need to detect and model associations based upon distances on the Earth's surface. Accurate computation of distances are sought for exploratory and interpretation purposes, as well as for developing numerically stable estimation algorithms. When the data come from locations on the spherical Earth, application of Euclidean or planar metrics for computing distances is not straightforward. Yet, planar metrics are desirable because of their easier interpretability, easy availability in software packages, and well-established theoretical properties. While distance computations are indispensable in spatial modeling, their importance and impact upon statistical estimation and prediction have gone largely unaddressed. This article explores the different options in using planar metrics and investigates their impact upon spatial modeling.},
author = {Banerjee, Sudipto},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/M42M5H8U/Banerjee - 2005 - On Geodetic Distance Computations in Spatial Model.pdf:pdf},
issn = {0006-341X},
journal = {Biometrics},
month = jun,
number = {2},
pages = {617--625},
title = {{On Geodetic Distance Computations in Spatial Modeling}},
url = {http://www.jstor.org/stable/3695985 http://www.jstor.org/stable/pdfplus/3695985.pdf?acceptTC=true},
volume = {61},
year = {2005}
}
@article{Liu2000,
author = {Liu, Chongxuan and Szecsody, Jim E and Zachara, John M and Ball, William P},
issn = {0309-1708},
journal = {Advances in Water Resources},
month = feb,
number = {5},
pages = {483--492},
title = {{Use of the generalized integral transform method for solving equations of solute transport in porous media}},
url = {http://www.sciencedirect.com/science/article/B6VCF-3YMFH46-4/2/130ca2e462e2846193f0aeb1b4aba34c},
volume = {23},
year = {2000}
}
@article{Singha,
abstract = {Despite recent advances in the mechanistic understanding of sorption in groundwater systems, most contaminant transport models provide limited support for nonideal sorption processes such as nonlinear isotherms and/or diffusion-limited sorption. However, recent developments in the conceptualization of “dual mode” sorption for hydrophobic organic contaminants have provided more realistic and mechanistically sound alternatives to the commonly used Langmuir and Freundlich models. To support the inclusion of both nonlinear and diffusion-limited sorption processes in groundwater transport models, this paper presents two numerical algorithms based on the split operator approach. For the nonlinear equilibrium scenario, the commonly used two-step split operator algorithm has been modified to provide a more robust treatment of complex multi-parameter isotherms such as the Polanyi-partitioning model. For diffusion-limited sorption, a flexible three step split-operator procedure is presented to simulate intraparticle diffusion in multiple spherical particles with different sizes and nonlinear isotherms. Numerical experiments confirmed the accuracy of both algorithms for several candidate isotherms. However, the primary advantages of the algorithms are: (1) flexibility to accommodate any isotherm equation including “dual mode” and similar expressions, and (2) ease of adapting existing grid-based transport models of any dimensionality to include nonlinear sorption and/or intraparticle diffusion. Comparisons are developed for one-dimensional transport scenarios with different isotherms and particle configurations. Illustrative results highlight (1) the potential influence of isotherm model selection on solute transport predictions, and (2) the combined effects of intraparticle diffusion and nonlinear sorption on the plume transport and flushing for both single-particle and multi-particle scenarios.},
author = {Singh, Anshuman and Allen-King, Richelle M. and Rabideau, Alan J.},
doi = {10.1016/j.advwatres.2014.04.010},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/PXW4R4C2/Singh et al. - Groundwater transport modeling with nonlinear sorp.pdf:pdf},
issn = {0309-1708},
journal = {Advances in Water Resources},
keywords = {Contaminant transport,Groundwater,Operator splitting,Pore diffusion,Sorption},
mendeley-tags = {Contaminant transport,Groundwater,Operator splitting,Pore diffusion,Sorption},
title = {{Groundwater transport modeling with nonlinear sorption and intraparticle diffusion}},
url = {http://www.sciencedirect.com/science/article/pii/S0309170814000773 http://www.sciencedirect.com/science/article/pii/S0309170814000773/pdfft?md5=f553e96f7000b6f9726b7924be601164\&pid=1-s2.0-S0309170814000773-main.pdf}
}
@article{Malkovsky2013,
abstract = {The migration of a contaminant from a zone of injection disposal of hazardous liquid waste in a deep-seated aquifer is considered. Because of its higher density, the polluted groundwater will accumulate under the effect of gravity in aquifer dips (depressions). A 2D-model of variable-density groundwater flow is used to determine the conditions under which the gravity force will prevent polluted groundwater from leaving depressions driven by regional current. As the result, such depressions can serve as natural traps for polluted waters. The required conditions are based on simple analytical relationships, derived from the analysis of a theoretical model of variable-density groundwater flow in an inclined confined aquifer. The obtained technique is used to estimate the efficiency of such a trap at the site of injection disposal of liquid radioactive waste from Mining and Chemical Combine in Krasnoyarsk region. The analytical estimates of the trap with the use of the proposed technique are shown to be in good agreement with the results of numerical simulation of contaminant migration.},
author = {Malkovsky, V. I. and Pek, A. A.},
doi = {10.1134/S0097807813070087},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/SPA7ARCU/Malkovsky and Pek - 2013 - Effect of natural advection on stabilization of co.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/B65VSMPB/S0097807813070087.html:html},
issn = {0097-8078, 1608-344X},
journal = {Water Resources},
keywords = {Groundwater,Hydrogeology,Waste Water Technology / Water Pollution Control /,aquifer,contaminant,liquid waste,natural advection},
language = {en},
mendeley-tags = {Groundwater,Hydrogeology,Waste Water Technology / Water Pollution Control /,aquifer,contaminant,liquid waste,natural advection},
month = dec,
number = {7},
pages = {716--722},
title = {{Effect of natural advection on stabilization of contaminant plume in natural traps at underground disposal of liquid wastes}},
url = {http://link.springer.com/article/10.1134/S0097807813070087 http://link.springer.com/content/pdf/10.1134\%2FS0097807813070087.pdf},
volume = {40},
year = {2013}
}
@article{Grayson1994,
author = {Grayson, Rodger B. and Moore, Ian D. and McMahon, Thomas A.},
doi = {10.1029/93WR03157},
issn = {1944-7973},
journal = {Water Resources Research},
language = {en},
number = {3},
pages = {849--849},
shorttitle = {Reply [to “Comment on ‘Physically based hydrologic},
title = {{Reply [to “Comment on ‘Physically based hydrologic modeling: 1, A terrain-based model for investigative purposes’ by R. B. Grayson, I. D. Moore, and T. A. McMahon”]}},
url = {http://onlinelibrary.wiley.com/doi/10.1029/93WR03157/abstract http://onlinelibrary.wiley.com/store/10.1029/93WR03157/asset/wrcr6424.pdf?v=1\&t=hfeze4c9\&s=6e6fb6af2282d75d73eb998e465aa32c38196db3 http://onlinelibrary.wiley.com/store/10.1029/93WR03157/asset/wrcr6424.pdf?v=1\&t=hfezgjq1\&s=5777f7b0c4e9bc82dbd402f0ad863d93163e385b},
volume = {30},
year = {1994}
}
@article{Zidek1998,
abstract = {This paper presents the results of a reconsideration of earlier work that finds an association between daily hospital admissions for respiratory distress and daily concentrations of sulphate (lag 1) as well as daily maximum concentrations of ozone (lags 1 and 3). These associations are found even after clustering the data by hospital of admission and accounting for the effects of temperature. We use an adaptation of their generalized estimating equation technique for clustered data, that daily data being for southern Ontario summers from 1983 to 1988. Like them, we adjust for daily maximum temperatures. However, unlike the earlier work returned to ours includes daily average humidity as a potential explanatory variable in our model. Our analysis also differs from theirs in that we cluster the data by census subdivision to reduce the risk of confounding pollutant levels with population size within regions. Moreover, we log-transform the explanatory variables and then high-pass filter the resulting data. We also deviate from the earlier analysis by taking account of measurement error incurred in using surrogate measures of the explanatory variables. To do so we use new methodology designed for our study but of potential value in other applications. That methodology requires a spatial predictive distribution for the unmeasured explanatory variables. Each day about 700 missing measurements for each of these variables can then be imputed over the geographical domain of the study. With these imputations we get a measure of imputation error through the covariance of the predictive distribution. Along with the predictive distribution we require an impact model to link-up with the predictive distribution. We describe that model and show how it uses the imputed measurements of the missing values of the explanatory variables. We also show how through that model, uncertainty about these values is reflected in our analysis and in commensurate uncertainties in the inferences made. Apart from its substantive objectives, our analysis serves to test the new methods with the earlier results serving as a foil. The reassuring qualitative agreement between our findings and the earlier results seems encouraging.},
author = {Zidek, J. V. and White, R. and Sun, W. and Burnett, R. T. and Le, N. D.},
doi = {10.1023/A:1009610720709},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/QVK2IPET/Zidek et al. - 1998 - Imputing Unmeasured Explanatory Variables in Envir.pdf:pdf},
issn = {1352-8505, 1573-3009},
journal = {Environmental and Ecological Statistics},
keywords = {Ecology,Evolutionary Biology,Mathematical Biology in General,Statistics- general,air pollution,clustered data,environmental epidemiology,generalized estimating equations,longitudinal data,nonlinear mixed-effect models,ozone,respiratory morbidity,spatial prediction,structural measurement error,sulphate},
language = {en},
mendeley-tags = {Ecology,Evolutionary Biology,Mathematical Biology in General,Statistics- general,air pollution,clustered data,environmental epidemiology,generalized estimating equations,longitudinal data,nonlinear mixed-effect models,ozone,respiratory morbidity,spatial prediction,structural measurement error,sulphate},
month = jun,
number = {2},
pages = {99--105},
title = {{Imputing Unmeasured Explanatory Variables in Environmental Epidemiology With Application to Health Impact Analysis of Air Pollution}},
url = {http://link.springer.com/article/10.1023/A\%3A1009610720709 http://link.springer.com/content/pdf/10.1023\%2FA\%3A1009610720709.pdf},
volume = {5},
year = {1998}
}
@article{Molinaro2005,
abstract = {Motivation: In genomic studies, thousands of features are collected on relatively few samples. One of the goals of these studies is to build classifiers to predict the outcome of future observations. There are three inherent steps to this process: feature selection, model selection and prediction assessment. With a focus on prediction assessment, we compare several methods for estimating the ‘true’ prediction error of a prediction model in the presence of feature selection.
Results: For small studies where features are selected from thousands of candidates, the resubstitution and simple split-sample estimates are seriously biased. In these small samples, leave-one-out cross-validation (LOOCV), 10-fold cross-validation (CV) and the .632+ bootstrap have the smallest bias for diagonal discriminant analysis, nearest neighbor and classification trees. LOOCV and 10-fold CV have the smallest bias for linear discriminant analysis. Additionally, LOOCV, 5- and 10-fold CV, and the .632+ bootstrap have the lowest mean square error. The .632+ bootstrap is quite biased in small sample sizes with strong signal-to-noise ratios. Differences in performance among resampling methods are reduced as the number of specimens available increase.
Contact: annette.molinaro@yale.edu
Supplementary Information: A complete compilation of results and R code for simulations and analyses are available in Molinaro et al. (2005) (http://linus.nci.nih.gov/brb/TechReport.htm).},
author = {Molinaro, Annette M. and Simon, Richard and Pfeiffer, Ruth M.},
doi = {10.1093/bioinformatics/bti499},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/DGVV4GUS/Molinaro et al. - 2005 - Prediction error estimation a comparison of resam.pdf:pdf},
issn = {1367-4803, 1460-2059},
journal = {Bioinformatics},
language = {en},
month = aug,
number = {15},
pages = {3301--3307},
shorttitle = {Prediction error estimation},
title = {{Prediction error estimation: a comparison of resampling methods}},
url = {http://bioinformatics.oxfordjournals.org/content/21/15/3301 http://bioinformatics.oxfordjournals.org/content/21/15/3301.full.pdf http://www.ncbi.nlm.nih.gov/pubmed/15905277},
volume = {21},
year = {2005}
}
@article{Bredehoeft2012,
author = {Bredehoeft, J D and Konikow, L F},
doi = {10.1111/j.1745-6584.2012.00951.x},
issn = {1745-6584},
journal = {Ground water},
number = {4},
pages = {493--5},
pmid = {22747432},
title = {{Ground-water models: validate or invalidate.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22747432},
volume = {50},
year = {2012}
}
@article{Gaume2009,
author = {Gaume, Eric and Bain, Valerie and Bernardara, Pietro and Newinger, Olivier and Barbuc, Mihai and Bateman, Allen and Bla$\backslash$vskovi$\backslash$vcov\'{a}, Lotta and Bl\"{o}schl, G\"{u}nter and Borga, Marco and Dumitrescu, Alexandru},
journal = {Journal of Hydrology},
number = {1},
pages = {70--78},
title = {{A compilation of data on European flash floods}},
url = {http://www.sciencedirect.com/science/article/pii/S0022169409000079 http://www.hydro.tuwien.ac.at/fileadmin/mediapool-hydro/Publikationen/bloeschl/Gaumeetal2009.pdf},
volume = {367},
year = {2009}
}
@article{Grunwald2000,
abstract = {We introduce the minimum description length (MDL) principle, a general principle for inductive inference based on the idea that regularities (laws) underlying data can always be used to compress data. We introduce the fundamental concept of MDL, called the stochastic complexity, and we show how it can be used for model selection. We briefly compare MDL-based model selection to other approaches and we informally explain why we may expect MDL to give good results in practical applications. Copyright 2000 Academic Press.},
author = {Gr\"{u}nwald, P},
doi = {10.1006/jmps.1999.1280},
issn = {0022-2496},
journal = {Journal of mathematical psychology},
month = mar,
number = {1},
pages = {133--152},
pmid = {10733861},
title = {{Model Selection Based on Minimum Description Length.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10733861},
volume = {44},
year = {2000}
}
@incollection{Letcher2011k,
address = {Boston},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/CWKMABET/Letcher and Vallero - 2011 - Introduction.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {1},
publisher = {Academic Press},
title = {{Introduction}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100415 http://www.sciencedirect.com/science/article/pii/B9780123814753100415/pdfft?md5=80d0c518e60d8a65e6e1b76a303a3a7a\&pid=3-s2.0-B9780123814753100415-main.pdf},
year = {2011}
}
@article{Johnson1979,
abstract = {For any sample of size N, the absolute value of the sample skewness is bounded by (N – I), and the sample kurtosis is bounded by N. Although these bounds are easily derived, they are not widely known.},
author = {Johnson, Mark E. and Lowe, Victor W.},
doi = {10.1080/00401706.1979.10489785},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/66SHSGKF/Johnson and Lowe - 1979 - Bounds on the Sample Skewness and Kurtosis.pdf:pdf},
issn = {0040-1706},
journal = {Technometrics},
number = {3},
pages = {377--378},
title = {{Bounds on the Sample Skewness and Kurtosis}},
url = {http://www.tandfonline.com/doi/abs/10.1080/00401706.1979.10489785 http://www.tandfonline.com/doi/pdf/10.1080/00401706.1979.10489785},
volume = {21},
year = {1979}
}
@article{Angiulli2010a,
abstract = {This work proposes a method for detecting distance-based outliers in data streams under the sliding window model. The novel notion of one-time outlier query is introduced in order to detect anomalies in the current window at arbitrary points-in-time. Three algorithms are presented. The first algorithm exactly answers to outlier queries, but has larger space requirements than the other two. The second algorithm is derived from the exact one, reduces memory requirements and returns an approximate answer based on estimations with a statistical guarantee. The third algorithm is a specialization of the approximate algorithm working with strictly fixed memory requirements. Accuracy properties and memory consumption of the algorithms have been theoretically assessed. Moreover experimental results have confirmed the effectiveness of the proposed approach and the good quality of the solutions.},
author = {Angiulli, Fabrizio and Fassetti, Fabio},
doi = {10.1007/s10618-009-0159-9},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/KXUEGWIC/Angiulli and Fassetti - 2010 - Distance-based outlier queries in data streams th.pdf:pdf},
issn = {1384-5810, 1573-756X},
journal = {Data Mining and Knowledge Discovery},
keywords = {Anomaly detection,Artificial Intelligence (incl. Robotics),Computing Methodologies,Data Mining and Knowledge Discovery,Data streams,Distance-based outliers,Information Storage and Retrieval,Statistics for Engineering- Physics- Computer Scie,Statistics- general},
language = {en},
mendeley-tags = {Anomaly detection,Artificial Intelligence (incl. Robotics),Computing Methodologies,Data Mining and Knowledge Discovery,Data streams,Distance-based outliers,Information Storage and Retrieval,Statistics for Engineering- Physics- Computer Scie,Statistics- general},
month = mar,
number = {2},
pages = {290--324},
shorttitle = {Distance-based outlier queries in data streams},
title = {{Distance-based outlier queries in data streams: the novel task and algorithms}},
url = {http://link.springer.com/article/10.1007/s10618-009-0159-9 http://link.springer.com/content/pdf/10.1007\%2Fs10618-009-0159-9.pdf},
volume = {20},
year = {2010}
}
@techreport{Rodger1960,
author = {Rodger, W. A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/QE36SJ6B/Rodger - 1960 - Radioactive Waste Disposal.pdf:pdf},
institution = {Argonne National Lab., Ill.},
keywords = {efficiency,gases,liquids,radioactivity,reduction,solids,waste disposal,waste disposal and processing},
language = {English},
mendeley-tags = {efficiency,gases,liquids,radioactivity,reduction,solids,waste disposal,waste disposal and processing},
month = sep,
title = {{Radioactive Waste Disposal}},
url = {http://www.osti.gov/scitech/biblio/4119984 http://www.osti.gov/scitech/servlets/purl/4119984},
year = {1960}
}
@article{Maestroni2014,
author = {Maestroni, B.},
keywords = {APPLIED LIFE SCIENCES (S60),CHROMATOGRAPHY,CONTROL,DEVELOPING COUNTRIES,FOOD CHAINS,FOOD PROCESSING,GAS CHROMATOGRAPHY,IRRADIATION,ISOTOPE APPLICATIONS,ISOTOPES,MASS SPECTROSCOPY,MEMBER STATES,POLLUTION CONTROL,PRESERVATION,PRODUCTIVITY,RADIOPRESERVATION,RADURIZATION,RESOURCE DEVELOPMENT,SEPARATION PROCESSES,SPECTROSCOPY,STABLE ISOTOPES,STERILE MALE TECHNIQUE,SUSTAINABLE DEVELOPMENT,processing,tracer techniques},
language = {English},
mendeley-tags = {APPLIED LIFE SCIENCES (S60),CHROMATOGRAPHY,CONTROL,DEVELOPING COUNTRIES,FOOD CHAINS,FOOD PROCESSING,GAS CHROMATOGRAPHY,IRRADIATION,ISOTOPE APPLICATIONS,ISOTOPES,MASS SPECTROSCOPY,MEMBER STATES,POLLUTION CONTROL,PRESERVATION,PRODUCTIVITY,RADIOPRESERVATION,RADURIZATION,RESOURCE DEVELOPMENT,SEPARATION PROCESSES,SPECTROSCOPY,STABLE ISOTOPES,STERILE MALE TECHNIQUE,SUSTAINABLE DEVELOPMENT,processing,tracer techniques},
title = {{Sustainability of Capacity Building Activities to Improve Food Safety and Quality through Nuclear Technology and Networking}},
url = {http://inis.iaea.org/Search/search.aspx?orig\_q=RN:45020977},
year = {2014}
}
@article{Sun1999a,
abstract = {A direct method for transforming multiple solute transport equations, coupled by linear, series, and/or parallel first-order, irreversible reactions, into a series of simple transport equations having known solutions is developed. Using this method, previously published analytical solutions to single-species transport problems, in which the transported species reacts with first-order kinetics, can be used to derive analytical solutions to multispecies transport systems with parallel, serial, and combined reaction networks. This new method overcomes many of the limitations that were implicit in previously published methods. In particular, the number of species that can be described is unlimited, and the reaction stoichiometry does not have to be unimolar. To illustrate the method, an analytical solution is derived for a five-species serial-parallel reactive transport system. The analytical solution obtained for this problem is compared with a numerical solution obtained with a previously developed code. This analytical method is applicable to the verification of new numerical codes.},
author = {Sun, Y. and Petersen, J. N. and Clement, T. P. and Skeen, R. S.},
doi = {10.1029/1998WR900003},
issn = {1944-7973},
journal = {Water Resources Research},
language = {en},
number = {1},
pages = {185--190},
title = {{Development of analytical solutions for multispecies transport with serial and parallel reactions}},
url = {http://onlinelibrary.wiley.com/doi/10.1029/1998WR900003/abstract http://onlinelibrary.wiley.com/store/10.1029/1998WR900003/asset/wrcr7998.pdf?v=1\&t=hfafcx5x\&s=c57122ce5eacc8afa3ad97e9d1d032892cea9a37 http://onlinelibrary.wiley.com/store/10.1029/1998WR900003/asset/wrcr7998.pdf?v=1\&t=hfafk6tk\&s=b2d3c5fc1be1e82de7271ee6f0a43b96afcbdbaa},
volume = {35},
year = {1999}
}
@article{Rasmussen2001a,
author = {Rasmussen, Steen and Baas, Nils A. and Mayer, Bernd and Nilsson, Martin},
journal = {Artificial Life},
number = {4},
pages = {367--373},
title = {{Defense of the ansatz for dynamical hierarchies}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/106454601317297004},
volume = {7},
year = {2001}
}
@article{Oreskes1998,
abstract = {The present regulatory climate has led to increasing demands for scientists to attest to the predictive reliability of numerical simulation models used to help set public policy, a process frequently referred to as model validation. But while model validation may reveal useful information, this paper argues that it is not possible to demonstrate the predictive reliability of any model of a complex natural system in advance of its actual use. All models embed uncertainties, and these uncertainties can and frequently do undermine predictive reliability. In the case of lead in the environment, we may categorize model uncertainties as theoretical, empirical, parametrical, and temporal. Theoretical uncertainties are aspects of the system that are not fully understood, such as the biokinetic pathways of lead metabolism. Empirical uncertainties are aspects of the system that are difficult (or impossible) to measure, such as actual lead ingestion by an individual child. Parametrical uncertainties arise when complexities in the system are simplified to provide manageable model input, such as representing longitudinal lead exposure by cross-sectional measurements. Temporal uncertainties arise from the assumption that systems are stable in time. A model may also be conceptually flawed. The Ptolemaic system of astronomy is a historical example of a model that was empirically adequate but based on a wrong conceptualization. Yet had it been computerized--and had the word then existed--its users would have had every right to call it validated. Thus, rather than talking about strategies for validation, we should be talking about means of evaluation. That is not to say that language alone will solve our problems or that the problems of model evaluation are primarily linguistic. The uncertainties inherent in large, complex models will not go away simply because we change the way we talk about them. But this is precisely the point: calling a model validated does not make it valid. Modelers and policymakers must continue to work toward finding effective ways to evaluate and judge the quality of their models, and to develop appropriate terminology to communicate these judgments to the public whose health and safety may be at stake.},
author = {Oreskes, N},
issn = {0091-6765},
journal = {Environmental health perspectives},
keywords = {Models, Biological,Predictive Value of Tests,Reproducibility of Results,Toxicology},
month = dec,
number = {December},
pages = {1453--60},
pmid = {9860904},
title = {{Evaluation (not validation) of quantitative models.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1533451\&tool=pmcentrez\&rendertype=abstract},
volume = {106 Suppl },
year = {1998}
}
@article{Smith1994a,
author = {Smith, R. E. and Goodrich, D. R. and Woolhiser, D. A. and Simanton, J. R.},
doi = {10.1029/93WR03184},
issn = {1944-7973},
journal = {Water Resources Research},
language = {en},
number = {3},
pages = {851--854},
shorttitle = {Comment on “Physically based hydrologic modeling},
title = {{Comment on “Physically based hydrologic modeling: 2, Is the concept realistic?” by R. B. Grayson, I. D. Moore, and T. A. McMahon}},
url = {http://onlinelibrary.wiley.com/doi/10.1029/93WR03184/abstract http://onlinelibrary.wiley.com/store/10.1029/93WR03184/asset/wrcr6425.pdf?v=1\&t=hfezejo6\&s=10d3f76916570c1d94351a93f2fa6bab380eea0b},
volume = {30},
year = {1994}
}
@book{NationalResearchCouncil2006,
author = {{National Research Council}},
booktitle = {Management},
publisher = {National Academies Press},
title = {{Improving the Regulation and Management of Low-Activity Radioactive Wastes}},
url = {http://www.nap.edu/catalog/11595.html},
year = {2006}
}
@article{Grosse-Kunstleve2004,
author = {Grosse-Kunstleve, R. W. and Sauter, N. K. and Adams, P. D.},
doi = {10.1107/S010876730302186X},
issn = {0108-7673},
journal = {Acta Crystallographica Section A Foundations of Crystallography},
month = jan,
number = {1},
pages = {1--6},
title = {{Numerically stable algorithms for the computation of reduced unit cells}},
url = {http://kitchingroup.cheme.cmu.edu/pycse/pycse.html},
volume = {60},
year = {2004}
}
@book{AlternativesNRC2013,
abstract = {Across the United States, thousands of hazardous waste sites are contaminated with chemicals that prevent the underlying groundwater from meeting drinking water standards. These include Superfund sites and other facilities that handle and dispose of hazardous waste, active and inactive dry cleaners, and leaking underground storage tanks; many are at federal facilities such as military installations. While many sites have been closed over the past 30 years through cleanup programs run by the U.S. Department of Defense, the U.S. EPA, and other state and federal agencies, the remaining caseload is much more difficult to address because the nature of the ...},
address = {Washington, D.C.},
annote = {
        From Duplicate 2 ( 
        
        
          Alternatives for Managing the Nation's Complex Contaminated Groundwater Sites
        
        
         - National Research Council )

        
        

        From Duplicate 2 ( 
        
        
          Alternatives for Managing the Nation's Complex Contaminated Groundwater Sites
        
        
         - National Research Council; Committee on Future Options for Management in the Nation's Subsurface Remediation Effort; Water Science and Technology Board )

        
        

        

        

        

        

      },
author = {{National Research Council}},
file = {:Users/arthur/Google Drive/References/Reports/National Academies Press docs/AlternativesManagingComplexSites2013\_14668.pdf:pdf;:Users/arthur/Google Drive/References/Reports/National Academies Press docs/AlternativestoManagingtheNationsComplexContaminatedGroundwaterSites.pdf:pdf},
isbn = {9780309278744},
keywords = {Alternative,Folder - ch1,Groundwater,Groundwater contamination,Remediation},
mendeley-tags = {Folder - ch1},
publisher = {National Academies Press},
title = {{Alternatives for Managing the Nation's Complex Contaminated Groundwater Sites}},
url = {http://www.nap.edu/openbook.php?record\_id=14668 http://www.nap.edu/catalog.php?record\_id=14668},
year = {2013}
}
@article{Cerioli2010,
abstract = {In this paper we develop multivariate outlier tests based on the high-breakdown Minimum Covariance Determinant estimator. The rules that we propose have good performance under the null hypothesis of no outliers in the data and also appreciable power properties for the purpose of individual outlier detection. This achievement is made possible by two orders of improvement over the currently available methodology. First, we suggest an approximation to the exact distribution of robust distances from which cut-off values can be obtained even in small samples. Our thresholds are accurate, simple to implement and result in more powerful outlier identification rules than those obtained by calibrating the asymptotic distribution of distances. The second power improvement comes from the addition of a new iteration step after one-step reweighting of the estimator. The proposed methodology is motivated by asymptotic distributional results. Its finite sample performance is evaluated through simulations and compared to that of available multivariate outlier tests.},
author = {Cerioli, Andrea},
doi = {10.1198/jasa.2009.tm09147},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/NSE6RZZK/Cerioli - 2010 - Multivariate Outlier Detection With High-Breakdown.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/2URVPB6K/jasa.2009.html:html},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
number = {489},
pages = {147--156},
title = {{Multivariate Outlier Detection With High-Breakdown Estimators}},
url = {http://www.tandfonline.com/doi/abs/10.1198/jasa.2009.tm09147 http://www.tandfonline.com/doi/pdf/10.1198/jasa.2009.tm09147},
volume = {105},
year = {2010}
}
@article{Aelion2009,
abstract = {Bayesian kriging is a useful tool for estimating spatial distributions of metals; however, estimates are generally only verified statistically. In this study surface soil samples were collected on a uniform grid and analyzed for As, Cr, Pb, and Hg. The data were interpolated at individual locations by Bayesian kriging. Estimates were validated using a leave-one-out cross validation (LOOCV) statistical method which compared the measured and LOOCV predicted values. Validation also was carried out using additional field sampling of soil metal concentrations at points between original sampling locations, which were compared to kriging prediction distributions. LOOCV results suggest that Bayesian kriging was a good predictor of metal concentrations. When measured internode metal concentrations and estimated kriged values were compared, the measured values were located within the 5th – 95th percentile prediction distributions in over half of the internode locations. Estimated and measured internode concentrations were most similar for As and Pb. Kriged estimates did not compare as well to measured values for concentrations below the analytical minimum detection limit, or for internode samples that were very close to the original sampling node. Despite inherent variability in metal concentrations in soils, the kriged estimates were validated statistically and by in situ measurement.},
author = {Aelion, C.M. and Davis, H.T. and Liu, Y. and Lawson, A.B. and McDermott, S.},
issn = {0013-936X},
journal = {Environmental science \& technology},
month = jun,
number = {12},
pages = {4432--4438},
title = {{Validation of Bayesian kriging of arsenic, chromium, lead and mercury surface soil concentrations based on internode sampling}},
url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2755059/ http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2755059/pdf/nihms115955.pdf},
volume = {43},
year = {2009}
}
@article{Sivakumar2004,
author = {Sivakumar, Bellie},
doi = {10.1002/hyp.5606},
issn = {0885-6087},
journal = {Hydrological Processes},
month = aug,
number = {12},
pages = {2349--2353},
title = {{Dominant processes concept in hydrology: moving forward}},
url = {http://doi.wiley.com/10.1002/hyp.5606},
volume = {18},
year = {2004}
}
@article{Oostrom,
abstract = {Abstract
A series of calculations and model predictions were used to evaluate the controls on perched-water conditions and constraints on perching occurrence, persistence, and potential impact on groundwater contamination. These simulations considered perched-water conditions that have been observed in the vadose zone above a fine-grained layer located just a few meters above the water table beneath the B-Complex Tank Farms area at the Hanford Site. The perched water, containing elevated concentrations of uranium and technetium-99, is important to consider in evaluating the future flux of contaminated water into the groundwater. A study was conducted to examine the perched-water conditions and quantitatively evaluate 1) factors that control perching behavior, 2) contaminant flux toward groundwater, and, 3) associated groundwater impact. Based on the current vertical transport pathways and large areal extent of the perched system, the evaluation was conducted using a one-dimensional analysis. Steady-state analytical calculations showed that the perching-layer hydraulic conductivity is likely to be up to two orders of magnitude lower than the value obtained from Hanford site material property estimates. Numerical flow and transport simulations provided both steady-state and transient system estimates of water and contaminant behavior and were used to further refine the range of conditions consistent with current observations of perched water height and to provide estimates of future water and contaminant flux to groundwater. Near-term removal of perched water by pumping can decrease the total contaminant mass that will discharge to the groundwater, but will have only a moderate effect on the near-term discharge rate and corresponding contaminant concentration in groundwater. Combining pumping with a decrease in the recharge rate will be most effective in minimizing the impact to groundwater. These results provide a framework for constraining the behavior of perched aquifer systems especially related to impacts on contaminant transport.},
author = {Oostrom, M. and Truex, M.J. and Carroll, K.C. and Chronister, G.B.},
doi = {10.1016/j.jhydrol.2013.10.001},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/P4M8GCN9/Oostrom et al. - Perched-water Analysis Related to Deep Vadose Zone.html:html;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/ZAQ5RVCW/Oostrom et al. - Perched-water Analysis Related to Deep Vadose Zone.pdf:pdf},
issn = {0022-1694},
journal = {Journal of Hydrology},
keywords = {Contaminant transport,deep vadose zone,groundwater contaminant flux,perched water},
mendeley-tags = {Contaminant transport,deep vadose zone,groundwater contaminant flux,perched water},
title = {{Perched-water Analysis Related to Deep Vadose Zone Contaminant Transport and Impact to Groundwater}},
url = {http://www.sciencedirect.com/science/article/pii/S0022169413007087 http://www.sciencedirect.com/science/article/pii/S0022169413007087/pdfft?md5=ea5ee6c55ffd480dd79c1ae015a788f2\&pid=1-s2.0-S0022169413007087-main.pdf}
}
@article{Myung2000a,
author = {Myung, In Jae and Forster, Malcolm R. and Browne, Michael W.},
doi = {10.1006/jmps.1999.1273},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/KDRHTZEA/Myung et al. - 2000 - GUEST EDITORS' INTRODUCTION Special Issue on Mode.pdf:pdf},
issn = {0022-2496},
journal = {Journal of Mathematical Psychology},
month = mar,
number = {1},
pages = {1--2},
shorttitle = {GUEST EDITORS' INTRODUCTION},
title = {{GUEST EDITORS' INTRODUCTION: Special Issue on Model Selection}},
url = {http://www.sciencedirect.com/science/article/pii/S0022249699912737 http://www.sciencedirect.com/science/article/pii/S0022249699912737/pdfft?md5=9a38e0942bc234f32ffe0055ea405406\&pid=1-s2.0-S0022249699912737-main.pdf},
volume = {44},
year = {2000}
}
@article{Anscombe1973,
author = {Anscombe, F. J.},
doi = {10.2307/2682899},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/NQFSE474/Anscombe - 1973 - Graphs in Statistical Analysis.pdf:pdf},
issn = {0003-1305},
journal = {The American Statistician},
keywords = {graphing,graphs,statistical analysis},
mendeley-tags = {graphing,graphs,statistical analysis},
month = feb,
number = {1},
pages = {17--21},
title = {{Graphs in Statistical Analysis}},
url = {http://www.jstor.org/stable/2682899 http://www.jstor.org/stable/pdfplus/2682899.pdf?acceptTC=true},
volume = {27},
year = {1973}
}
@book{NationalResearchCouncil2006a,
abstract = {This book is the seventh in a series of titles from the National Research Council that addresses the effects of exposure to low dose LET (Linear Energy Transfer) ionizing radiation and human health. Updating information previously presented in the 1990 publication, Health Effects of Exposure to Low Levels of Ionizing Radiation: BEIR V, this book draws upon new data in both epidemiologic and experimental research. Ionizing radiation arises from both natural and man-made sources and at very high doses can produce damaging effects in human tissue that can be evident within days after exposure. However, it is the low-dose exposures ...},
author = {{National Research Council}},
keywords = {Folder - ch1},
mendeley-tags = {Folder - ch1},
publisher = {The National Academies Press},
shorttitle = {Health Risks from Exposure to Low Levels of Ionizi},
title = {{Health Risks from Exposure to Low Levels of Ionizing Radiation: BEIR VII Phase 2}},
url = {http://www.nap.edu/catalog.php?record\_id=11340},
year = {2006}
}
@article{Neupauer2000a,
abstract = {Inverse methods can be used to reconstruct the release history of a known source of groundwater contamination from concentration data describing the present-day spatial distribution of the contaminant plume. Using hypothetical release history functions and contaminant plumes, we evaluate the relative effectiveness of two proposed inverse methods, Tikhonov regularization (TR) and minimum relative entropy (MRE) inversion, in reconstructing the release history of a conservative contaminant in a one-dimensional domain [Skaggs and Kabala, 1994; Woodbury and Ulrych, 1996]. We also address issues of reproducibility of the solution and the appropriateness of models for simulating random measurement error. The results show that if error-free plume concentration data are available, both methods perform well in reconstructing a smooth source history function. With error-free data the MRE method is more robust than TR in reconstructing a nonsmooth source history function; however, the TR method is more robust if the data contain measurement error. Two error models were evaluated in this study, and we found that the particular error model does not affect the reliability of the solutions. The results for the TR method have somewhat greater reproducibility because, in some cases, its input parameters are less subjective than those of the MRE method; however, the MRE solution can identify regions where the data give little or no information about the source history function, while the TR solution cannot.},
author = {Neupauer, Roseanna M. and Borchers, Brian and Wilson, John L.},
doi = {10.1029/2000WR900176},
issn = {1944-7973},
journal = {Water Resources Research},
language = {en},
number = {9},
pages = {2469--2475},
title = {{Comparison of inverse methods for reconstructing the release history of a groundwater contamination source}},
url = {http://onlinelibrary.wiley.com/doi/10.1029/2000WR900176/abstract http://onlinelibrary.wiley.com/doi/10.1029/2000WR900176/abstract?deniedAccessCustomisedMessage=\&userIsAuthenticated=false http://onlinelibrary.wiley.com/store/10.1029/2000WR900176/asset/wrcr8716.pdf?v=1\&t=hhjwwnwr\&s=1f4108d635fadc225adf55d543ec54abc7c23e57},
volume = {36},
year = {2000}
}
@book{NationalResearchCouncil1984a,
abstract = {To complement the growing body of knowledge on the physical aspects of radioactive waste disposal, this new report identifies the ;ITsocioeconomic and institutional;IT policy issues that must be addressed in implementing the Nuclear Waste Policy Act. Site location, transportation modes, disposal schedules, regulatory systems, and the effects of these systems on the people living near the sites and along the transportation routes are addressed. ...},
address = {Washington, D.C.},
author = {{National Research Council}},
publisher = {The National Academies Press},
shorttitle = {Social and Economic Aspects of Radioactive Waste D},
title = {{Social and Economic Aspects of Radioactive Waste Disposal: Considerations for Institutional Management}},
url = {http://www.nap.edu/catalog.php?record\_id=316},
year = {1984}
}
@article{Nelson1984,
abstract = {Regression of a trendless random walk on time produces R-squared values around 44 regardless of sample length. The residuals from the regression exhibit only about 14\% as much variation as the original series even though the underlying process has no functional dependence on time. The autocorrelation structure of these "detrended" random walks is pseudo-cyclical and purely artifactual. Conventional tests for trend are strongly biased toward finding a trend when none is present, and this effect is only partially mitigated by Cochrane-Orcutt correction for autocorrelation. The results are extended to show that pairs of detrended random walks exhibit spurious correlation.},
author = {Nelson, Charles R. and Kang, Heejoon},
doi = {10.2307/1391356},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/RK54PJUB/Nelson and Kang - 1984 - Pitfalls in the Use of Time as an Explanatory Vari.pdf:pdf},
issn = {0735-0015},
journal = {Journal of Business \& Economic Statistics},
month = jan,
number = {1},
pages = {73--82},
title = {{Pitfalls in the Use of Time as an Explanatory Variable in Regression}},
url = {http://www.jstor.org/stable/1391356 http://www.jstor.org/stable/pdfplus/1391356.pdf?acceptTC=true},
volume = {2},
year = {1984}
}
@article{Ye2010,
abstract = {This study evaluates alternative groundwater models with different recharge and geologic components at the northern Yucca Flat area of the Death Valley Regional Flow System (DVRFS), USA. Recharge over the DVRFS has been estimated using five methods, and five geological interpretations are available at the northern Yucca Flat area. Combining the recharge and geological components together with additional modeling components that represent other hydrogeological conditions yields a total of 25 groundwater flow models. As all the models are plausible given available data and information, evaluating model uncertainty becomes inevitable. On the other hand, hydraulic parameters (e.g., hydraulic conductivity) are uncertain in each model, giving rise to parametric uncertainty. Propagation of the uncertainty in the models and model parameters through groundwater modeling causes predictive uncertainty in model predictions (e.g., hydraulic head and flow). Parametric uncertainty within each model is assessed using Monte Carlo simulation, and model uncertainty is evaluated using the model averaging method. Two model-averaging techniques (on the basis of information criteria and GLUE) are discussed. This study shows that contribution of model uncertainty to predictive uncertainty is significantly larger than that of parametric uncertainty. For the recharge and geological components, uncertainty in the geological interpretations has more significant effect on model predictions than uncertainty in the recharge estimates. In addition, weighted residuals vary more for the different geological models than for different recharge models. Most of the calibrated observations are not important for discriminating between the alternative models, because their weighted residuals vary only slightly from one model to another.},
author = {Ye, Ming and Pohlmann, Karl F and Chapman, Jenny B and Pohll, Greg M and Reeves, Donald M},
doi = {10.1111/j.1745-6584.2009.00633.x},
issn = {1745-6584},
journal = {Ground water},
keywords = {Models, Theoretical,Uncertainty,Water},
number = {5},
pages = {716--28},
pmid = {19788638},
title = {{A model-averaging method for assessing groundwater conceptual model uncertainty.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19788638},
volume = {48},
year = {2010}
}
@article{Emmeche1997,
author = {Emmeche, Claus and K\o ppe, Simo and Stjernfelt, Frederik},
journal = {Journal for General Philosophy of Science},
number = {1},
pages = {83--117},
shorttitle = {Explaining emergence},
title = {{Explaining emergence: towards an ontology of levels}},
url = {http://www.springerlink.com/index/rl02g77094656g16.pdf},
volume = {28},
year = {1997}
}
@article{Duddek1995,
abstract = {We demonstrate a recently developed spatial interpolation methodology in a study of the chronic effects of air pollution on respiratory morbidity. Our study uses data from the Ontario Health Study, a large survey of households in Ontario conducted for the province by Statistics Canada. The interpolation procedure imputes unobserved vectors of air pollution concentrations for individual Public Health Units, from those observed at a few fixed air pollution monitoring sites. We use logistic regression methods to assess the significance of air pollution levels based on the imputed values after modelling the relationship between binary health responses and assorted covariates such as measures of life style. Our findings prove negative; no significant relationship between chronic respiratory morbidity and air pollution is found. The imputation methodology is seen to be promising and might well be used in other such analyses.},
author = {Duddek, C. and Le, N. D. and Zidek, J. V. and Burnett, R. T.},
doi = {10.1007/BF00456664},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/MUWWIMW7/Duddek et al. - 1995 - Multivariate imputation in cross-sectional analysi.pdf:pdf},
issn = {1352-8505, 1573-3009},
journal = {Environmental and Ecological Statistics},
keywords = {Ecology,Environmental Monitoring,Evolutionary Biology,Mathematical Biology in General,Ontario Health Study,Statistics- general,air pollution,kriging,multivariate interpolation,nitrates,ozone,respiratory morbidity,sulphates},
language = {en},
mendeley-tags = {Ecology,Environmental Monitoring,Evolutionary Biology,Mathematical Biology in General,Ontario Health Study,Statistics- general,air pollution,kriging,multivariate interpolation,nitrates,ozone,respiratory morbidity,sulphates},
month = sep,
number = {3},
pages = {191--212},
title = {{Multivariate imputation in cross-sectional analysis of health effects associated with air pollution}},
url = {http://link.springer.com/article/10.1007/BF00456664 http://link.springer.com/content/pdf/10.1007\%2FBF00456664.pdf},
volume = {2},
year = {1995}
}
@incollection{Vallero2011c,
abstract = {This chapter addresses the benefits and drawbacks of various thermal destruction and removal technologies. Chemical reactions at elevated temperatures can yield products that are either good or bad from an environmental perspective. This chapter focuses on the thermal reactions that can be used to treat numerous wastes. Complete combustion may also result in the production of molecular nitrogen (N2) when nitrogen-containing organics are burned, such as in the combustion of methylamine. Incomplete combustion can produce a variety of compounds. Some are more toxic than the original compounds being oxidized, such as polycyclic aromatic hydrocarbons (PAHs), dioxins, furans, and CO. The organic portion of wastes has heat value. This means that this portion of any waste can be completely destroyed using principles based on thermodynamics, ultimately yielding carbon dioxide and water. This depends mainly on whether toxic and otherwise harmful molecules react to become less or more toxic or harmful molecules, or are transformed into molecules that are more or less mobile in the environment, which could mean greater exposures and risks. Recalcitrant waste constituents can be degraded using these techniques but caution should always be applied as improper applications of thermal technologies can lead to harm caused by products of incomplete combustion (PICs) and other pollutants.},
address = {Boston},
author = {Vallero, Daniel A.},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/5R5AWWFN/Vallero - 2011 - Chapter 16 - Thermal Waste Treatment.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {219--231},
publisher = {Academic Press},
title = {{Chapter 16 - Thermal Waste Treatment}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100166 http://www.sciencedirect.com/science/article/pii/B9780123814753100166/pdfft?md5=ddca2f3552cab5a0f510e45063607a74\&pid=3-s2.0-B9780123814753100166-main.pdf},
year = {2011}
}
@book{Pichtel2014,
author = {Pichtel, John},
edition = {2nd},
isbn = {978-1-4665-8518-8, 978-1-4665-8519-5},
language = {en},
month = mar,
publisher = {CRC Press},
shorttitle = {Waste Management Practices},
title = {{Waste Management Practices: Municipal, Hazardous, and Industrial, Second Edition}},
url = {http://www.crcnetbase.com/isbn/9781466585195},
year = {2014}
}
@article{Schubert2014a,
abstract = {Outlier detection research has been seeing many new algorithms every year that often appear to be only slightly different from existing methods along with some experiments that show them to “clearly outperform” the others. However, few approaches come along with a clear analysis of existing methods and a solid theoretical differentiation. Here, we provide a formalized method of analysis to allow for a theoretical comparison and generalization of many existing methods. Our unified view improves understanding of the shared properties and of the differences of outlier detection models. By abstracting the notion of locality from the classic distance-based notion, our framework facilitates the construction of abstract methods for many special data types that are usually handled with specialized algorithms. In particular, spatial neighborhood can be seen as a special case of locality. Here we therefore compare and generalize approaches to spatial outlier detection in a detailed manner. We also discuss temporal data like video streams, or graph data such as community networks. Since we reproduce results of specialized approaches with our general framework, and even improve upon them, our framework provides reasonable baselines to evaluate the true merits of specialized approaches. At the same time, seeing spatial outlier detection as a special case of local outlier detection, opens up new potentials for analysis and advancement of methods.},
author = {Schubert, Erich and Zimek, Arthur and Kriegel, Hans-Peter},
doi = {10.1007/s10618-012-0300-z},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/IHJW68BD/Schubert et al. - 2014 - Local outlier detection reconsidered a generalize.pdf:pdf},
issn = {1384-5810, 1573-756X},
journal = {Data Mining and Knowledge Discovery},
keywords = {Artificial Intelligence (incl. Robotics),Data Mining and Knowledge Discovery,Information Storage and Retrieval,Local outlier,Network outlier,Spatial outlier,Statistics for Engineering- Physics- Computer Scie,Video outlier},
language = {en},
mendeley-tags = {Artificial Intelligence (incl. Robotics),Data Mining and Knowledge Discovery,Information Storage and Retrieval,Local outlier,Network outlier,Spatial outlier,Statistics for Engineering- Physics- Computer Scie,Video outlier},
month = jan,
number = {1},
pages = {190--237},
shorttitle = {Local outlier detection reconsidered},
title = {{Local outlier detection reconsidered: a generalized view on locality with applications to spatial, video, and network outlier detection}},
url = {http://link.springer.com/article/10.1007/s10618-012-0300-z http://link.springer.com/content/pdf/10.1007\%2Fs10618-012-0300-z.pdf},
volume = {28},
year = {2014}
}
@article{Yuan,
abstract = {Presented in this paper is an analytical study of a pulsed volatile contaminant emission into a free-surface wetland flow. A simplified model is given for contaminant transport under the combined action of advection, mass dispersion, apparent reaction, and volatilization at the free water surface. The effect of periodic apparent reaction on contaminant transport is separated from the hydraulic effect via an extended transformation, with a limiting case covering the known transformation for constant apparent reaction rate. The analytical solutions of zeroth and first order concentration moments are rigorously derived and illustrated. It was found that the amount of contaminant decreases from the bottom bed to the free-surface under volatilization, and the total amount of contaminant decays with time. It was also found that the moving speed of the mass center of the whole contaminant cloud increases, as the ratio of volatilization coefficient to vertical effective mass dispersivity increases.},
author = {Yuan, Jue and Zeng, Li and Zhao, Yijun and Wu, Yihong and Ji, Ping and Chen, Bin},
doi = {10.1007/s11707-013-0364-0},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/E6QZGDK6/Yuan et al. - Transport of a volatile contaminant in a free-surf.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/5KNIGVRA/s11707-013-0364-0.html:html},
issn = {2095-0195, 2095-0209},
journal = {Frontiers of Earth Science},
keywords = {Contaminant transport,Earth Sciences- general,reaction,volatilization,wetland hydraulics},
language = {en},
mendeley-tags = {Contaminant transport,Earth Sciences- general,reaction,volatilization,wetland hydraulics},
pages = {1--8},
title = {{Transport of a volatile contaminant in a free-surface wetland flow}},
url = {http://link.springer.com/article/10.1007/s11707-013-0364-0 http://link.springer.com/content/pdf/10.1007\%2Fs11707-013-0364-0.pdf}
}
@article{Li2013a,
author = {Li, Y. P. and Huang, G. H. and Nie, S. L. and Chen, B. and Qin, X. S.},
doi = {10.1155/2013/674316},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/DJ56VEPU/Li et al. - 2013 - Mathematical Modeling for Resources and Environmen.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/JGMEAPZI/674316.html:html},
issn = {1024-123X},
journal = {Mathematical Problems in Engineering},
language = {en},
month = nov,
title = {{Mathematical Modeling for Resources and Environmental Systems}},
url = {http://www.hindawi.com/journals/mpe/2013/674316/abs/ http://downloads.hindawi.com/journals/mpe/2013/674316.pdf http://www.hindawi.com/journals/mpe/2013/674316/},
volume = {2013},
year = {2013}
}
@article{Kim2009a,
abstract = {We consider the accuracy estimation of a classifier constructed on a given training sample. The naive resubstitution estimate is known to have a downward bias problem. The traditional approach to tackling this bias problem is cross-validation. The bootstrap is another way to bring down the high variability of cross-validation. But a direct comparison of the two estimators, cross-validation and bootstrap, is not fair because the latter estimator requires much heavier computation. We performed an empirical study to compare the .632+ bootstrap estimator with the repeated 10-fold cross-validation and the repeated one-third holdout estimator. All the estimators were set to require about the same amount of computation. In the simulation study, the repeated 10-fold cross-validation estimator was found to have better performance than the .632+ bootstrap estimator when the classifier is highly adaptive to the training sample. We have also found that the .632+ bootstrap estimator suffers from a bias problem for large samples as well as for small samples.},
author = {Kim, Ji-Hyun},
doi = {10.1016/j.csda.2009.04.009},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/FG7REHPX/Kim - 2009 - Estimating classification error rate Repeated cro.pdf:pdf},
issn = {0167-9473},
journal = {Computational Statistics \& Data Analysis},
month = sep,
number = {11},
pages = {3735--3745},
shorttitle = {Estimating classification error rate},
title = {{Estimating classification error rate: Repeated cross-validation, repeated hold-out and bootstrap}},
url = {http://www.sciencedirect.com/science/article/pii/S0167947309001601 http://www.sciencedirect.com/science/article/pii/S0167947309001601/pdfft?md5=c4f42f7bd1f61cd0c3c977c58db9e1f5\&pid=1-s2.0-S0167947309001601-main.pdf},
volume = {53},
year = {2009}
}
@article{Wang2009,
abstract = {Summary 
Developing a hydrological forecasting model based on past records is crucial to effective hydropower reservoir management and scheduling. Traditionally, time series analysis and modeling is used for building mathematical models to generate hydrologic records in hydrology and water resources. Artificial intelligence (AI), as a branch of computer science, is capable of analyzing long-series and large-scale hydrological data. In recent years, it is one of front issues to apply AI technology to the hydrological forecasting modeling. In this paper, autoregressive moving-average (ARMA) models, artificial neural networks (ANNs) approaches, adaptive neural-based fuzzy inference system (ANFIS) techniques, genetic programming (GP) models and support vector machine (SVM) method are examined using the long-term observations of monthly river flow discharges. The four quantitative standard statistical performance evaluation measures, the coefficient of correlation (R), Nash–Sutcliffe efficiency coefficient (E), root mean squared error (RMSE), mean absolute percentage error (MAPE), are employed to evaluate the performances of various models developed. Two case study river sites are also provided to illustrate their respective performances. The results indicate that the best performance can be obtained by ANFIS, GP and SVM, in terms of different evaluation criteria during the training and validation phases.},
author = {Wang, Wen-Chuan and Chau, Kwok-Wing and Cheng, Chun-Tian and Qiu, Lin},
doi = {10.1016/j.jhydrol.2009.06.019},
issn = {0022-1694},
journal = {Journal of Hydrology},
keywords = {ANFIS,ANN,ARMA,GP,Monthly discharge time series forecasting,SVM},
mendeley-tags = {ANFIS,ANN,ARMA,GP,Monthly discharge time series forecasting,SVM},
month = aug,
number = {3–4},
pages = {294--306},
title = {{A comparison of performance of several artificial intelligence methods for forecasting monthly discharge time series}},
url = {http://www.sciencedirect.com/science/article/pii/S0022169409003527 http://pdn.sciencedirect.com/science?\_ob=MiamiImageURL\&\_cid=271842\&\_user=4420\&\_pii=S0022169409003527\&\_check=y\&\_origin=article\&\_zone=toolbar\&\_coverDate=2009--15\&view=c\&originContentFamily=serial\&wchp=dGLbVlV-zSkWb\&md5=100ac7089cf901d5790280e608e11616\&pid=1-s2.0-S0022169409003527-main.pdf},
volume = {374},
year = {2009}
}
@article{Singh2010,
abstract = {In recent years a growing understanding has emerged regarding the need to expand the modeling paradigm to include conceptual model uncertainty for groundwater models. Conceptual model uncertainty is typically addressed by formulating alternative model conceptualizations and assessing their relative likelihoods using statistical model averaging approaches. Several model averaging techniques and likelihood measures have been proposed in the recent literature for this purpose with two broad categories--Monte Carlo-based techniques such as Generalized Likelihood Uncertainty Estimation or GLUE (Beven and Binley 1992) and criterion-based techniques that use metrics such as the Bayesian and Kashyap Information Criteria (e.g., the Maximum Likelihood Bayesian Model Averaging or MLBMA approach proposed by Neuman 2003) and Akaike Information Criterion-based model averaging (AICMA) (Poeter and Anderson 2005). These different techniques can often lead to significantly different relative model weights and ranks because of differences in the underlying statistical assumptions about the nature of model uncertainty. This paper provides a comparative assessment of the four model averaging techniques (GLUE, MLBMA with KIC, MLBMA with BIC, and AIC-based model averaging) mentioned above for the purpose of quantifying the impacts of model uncertainty on groundwater model predictions. Pros and cons of each model averaging technique are examined from a practitioner's perspective using two groundwater modeling case studies. Recommendations are provided regarding the use of these techniques in groundwater modeling practice.},
author = {Singh, Abhishek and Mishra, Srikanta and Ruskauff, Greg},
doi = {10.1111/j.1745-6584.2009.00642.x},
issn = {1745-6584},
journal = {Ground water},
keywords = {Models, Theoretical,Uncertainty},
number = {5},
pages = {701--15},
pmid = {19878329},
title = {{Model averaging techniques for quantifying conceptual model uncertainty.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19878329},
volume = {48},
year = {2010}
}
@article{Marsily1977,
author = {de Marsily, G. and Ledoux, E. and Barbreau, A. and Margat, J.},
doi = {10.1126/science.197.4303.519},
issn = {0036-8075, 1095-9203},
journal = {Science},
keywords = {Folder - ch1},
language = {en},
mendeley-tags = {Folder - ch1},
month = aug,
number = {4303},
pages = {519--527},
shorttitle = {Nuclear Waste Disposal},
title = {{Nuclear Waste Disposal: Can the Geologist Guarantee Isolation?}},
url = {http://www.sciencemag.org/content/197/4303/519 http://www.ncbi.nlm.nih.gov/pubmed/17774303},
volume = {197},
year = {1977}
}
@article{Lessler1988,
abstract = {Author Institution: Department of Physiology, Ohio State University},
author = {Lessler, Milton A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/MN3PTGCN/Lessler - 1988 - Lead and Lead Poisoning from Antiquity to Modern T.pdf:pdf},
issn = {0030-0950},
journal = {Ohio Journal of Science},
keywords = {Folder - ch1},
language = {en\_US},
mendeley-tags = {Folder - ch1},
month = jun,
number = {3},
pages = {78--84},
title = {{Lead and Lead Poisoning from Antiquity to Modern Times}},
url = {http://hdl.handle.net/1811/23252 http://kb.osu.edu/dspace/bitstream/1811/23252/1/V088N3\_078.pdf},
volume = {88},
year = {1988}
}
@article{Srivastava2014,
abstract = {Contamination of groundwater constrains its uses and poses a serious threat to the environment. Once groundwater is contaminated, the cleanup may be difficult and expensive. Identification of unknown pollution sources is the first step toward adopting any remediation strategy. The proposed methodology exploits the capability of a universal function approximation by a feed-forward multilayer artificial neural network (ANN) to identify the sources in terms of its location, magnitudes, and duration of activity. The back-propagation algorithm is utilized for training the ANN to identify the source characteristics based on simulated concentration data at specified observation locations in the aquifer. Uniform random generation and the Latin hypercube sampling method of random generation are used to generate temporal varying source fluxes. These source fluxes are used in groundwater flow and the transport simulation model to generate necessary data for the ANN model-building processes. Breakthrough curves obtained for the specified pollution scenario are characterized by different methods. The characterized breakthrough curves parameters serve as inputs to ANN model. Unknown pollution source characteristics are outputs for ANN model. Experimentation is also performed with different number of training and testing patterns. In addition, the effects of measurement errors in concentration measurements values are used to show the robustness of ANN based methodology for source identification in case of erroneous data.},
author = {Srivastava, Divya and Singh, Raj Mohan},
doi = {10.1080/15275922.2014.890142},
issn = {1527-5922},
journal = {Environmental Forensics},
number = {2},
pages = {175--189},
title = {{Breakthrough Curves Characterization and Identification of an Unknown Pollution Source in Groundwater System Using an Artificial Neural Network (ANN)}},
url = {http://www.tandfonline.com/doi/abs/10.1080/15275922.2014.890142},
volume = {15},
year = {2014}
}
@article{Hido2011,
abstract = {We propose a new statistical approach to the problem of inlier-based outlier detection, i.e., finding outliers in the test set based on the training set consisting only of inliers. Our key idea is to use the ratio of training and test data densities as an outlier score. This approach is expected to have better performance even in high-dimensional problems since methods for directly estimating the density ratio without going through density estimation are available. Among various density ratio estimation methods, we employ the method called unconstrained least-squares importance fitting (uLSIF) since it is equipped with natural cross-validation procedures, allowing us to objectively optimize the value of tuning parameters such as the regularization parameter and the kernel width. Furthermore, uLSIF offers a closed-form solution as well as a closed-form formula for the leave-one-out error, so it is computationally very efficient and is scalable to massive datasets. Simulations with benchmark and real-world datasets illustrate the usefulness of the proposed approach.},
author = {Hido, Shohei and Tsuboi, Yuta and Kashima, Hisashi and Sugiyama, Masashi and Kanamori, Takafumi},
doi = {10.1007/s10115-010-0283-2},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/FF9BXV97/s10115-010-0283-2.html:html},
issn = {0219-1377, 0219-3116},
journal = {Knowledge and Information Systems},
keywords = {Business Information Systems,Density ratio,Importance,Information Systems and Communication Service,Unconstrained least-squares importance fitting (uL,outlier detection},
language = {en},
mendeley-tags = {Business Information Systems,Density ratio,Importance,Information Systems and Communication Service,Unconstrained least-squares importance fitting (uL,outlier detection},
month = feb,
number = {2},
pages = {309--336},
title = {{Statistical outlier detection using direct density ratio estimation}},
url = {http://link.springer.com/article/10.1007/s10115-010-0283-2},
volume = {26},
year = {2011}
}
@article{Lindenschmidt2006,
abstract = {Snowling and Kramer [2001. Evaluating modelling uncertainty for model selection. Ecol. Modell. 138(1), 17–30] proposed a hypothesis stating that as a model becomes more complex in terms of increased number of parameters and variable, the error between simulations and measurements decreases and the overall model sensitivity increases. In this paper, the hypothesis is tested using a river water quality model of the lower course of the Saale river, Germany. The eutrophication module of WASP5 (5th version of Water quality Analysis Simulation Program), which was developed by the U.S. EPA, was implemented. The model allows the complexity of the dissolved oxygen balance and dynamics in a water body to be easily varied from a simple Streeter–Phelps approach of dissolved oxygen–biological oxygen demand (DO–BOD) interaction to more complex phytoplankton–nutrient dynamics. Five complexities were modelled and plotted against a normalized root-mean-squared error and a normalized global sensitivity. The results verify the hypothesis. A utility function, which minimizes both error and sensitivity, shows that the most complex model is not necessarily the most “useful”. In the case of the lower Saale river, modelling only the phytoplankton–nutrient cycle has almost as much descriptive power as when the complexity is increased by adding the DO–BOD cycle. The low sensitivity of the parameters linking the two cycles also indicates their weak coupling in the Saale river system. This verifies the observations that the source of the organic loading in the Saale has shifted from primary (point load) to secondary (phytoplankton) origin.},
author = {Lindenschmidt, Karl-Erich},
doi = {10.1016/j.ecolmodel.2005.04.016},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/S23PC4JD/Lindenschmidt - 2006 - The effect of complexity on parameter sensitivity .pdf:pdf},
issn = {0304-3800},
journal = {Ecological Modelling},
keywords = {Biological oxygen demand,Phytoplankton–nutrient dynamics,Saale,WASP5,dissolved oxygen,model complexity},
mendeley-tags = {Biological oxygen demand,Phytoplankton–nutrient dynamics,Saale,WASP5,dissolved oxygen,model complexity},
month = jan,
number = {1–2},
pages = {72--86},
title = {{The effect of complexity on parameter sensitivity and model uncertainty in river water quality modelling}},
url = {http://www.sciencedirect.com/science/article/pii/S0304380005002218 http://www.sciencedirect.com/science/article/pii/S0304380005002218/pdfft?md5=c188188532a8f14f7014cca4cce609af\&pid=1-s2.0-S0304380005002218-main.pdf},
volume = {190},
year = {2006}
}
@article{Bea2013,
author = {Bea, Sergio a. and Wainwright, Haruko and Spycher, Nicolas and Faybishenko, Boris and Hubbard, Susan S. and Denham, Miles E.},
doi = {10.1016/j.jconhyd.2013.04.005},
isbn = {5104865266},
issn = {01697722},
journal = {Journal of Contaminant Hydrology},
month = may,
number = {Vi},
publisher = {Elsevier B.V.},
title = {{Identifying key controls on the behaviour of an acidic-U(VI) plume in the Savannah River Site using reactive transport modeling}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0169772213000612},
year = {2013}
}
@article{Ye1997,
author = {Ye, W. and Bates, B. C. and Viney, Neil R. and Sivapalan, M. and Jakeman, A. J.},
journal = {Water Resources Research},
number = {1},
pages = {153--166},
title = {{Performance of conceptual rainfall-runoff models in low-yielding ephemeral catchments}},
volume = {33},
year = {1997}
}
@techreport{CommitteeonIntrinsicRemediation2000,
address = {Washington, D.C.},
author = {{National Research Council}},
file = {:Users/arthur/Google Drive/References/Reports/National Academies Press docs/NaturalAttenforGWremediation.pdf:pdf},
institution = {National Research Council},
isbn = {0309516455},
title = {{Natural Attenuation for Groundwater Remediation}},
year = {2000}
}
@article{Gupta2009,
author = {Gupta, Hoshin V. and Kling, Harald and Yilmaz, Koray K. and Martinez, Guillermo F.},
doi = {10.1016/j.jhydrol.2009.08.003},
issn = {00221694},
journal = {Journal of Hydrology},
keywords = {Criteria decomposition,Mean squared error,Model performance evaluation,Multiple criteria,Nash–Sutcliffe efficiency,calibration},
mendeley-tags = {Criteria decomposition,Mean squared error,Model performance evaluation,Multiple criteria,Nash–Sutcliffe efficiency,calibration},
month = oct,
number = {1-2},
pages = {80--91},
shorttitle = {Decomposition of the mean squared error and NSE pe},
title = {{Decomposition of the mean squared error and NSE performance criteria: Implications for improving hydrological modelling}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0022169409004843 http://pdn.sciencedirect.com/science?\_ob=MiamiImageURL\&\_cid=271842\&\_user=4420\&\_pii=S0022169409004843\&\_check=y\&\_origin=article\&\_zone=toolbar\&\_coverDate=2009--20\&view=c\&originContentFamily=serial\&wchp=dGLbVlS-zSkWb\&md5=b1684394c7b9a5ce557858e14e9b796c\&pid=1-s2.0-S0022169409004843-main.pdf http://www.sciencedirect.com/science/article/pii/S0022169409004843},
volume = {377},
year = {2009}
}
@article{Sawyer2004,
author = {Sawyer, R. Keith},
journal = {Philosophy of the Social Sciences},
number = {2},
pages = {260--282},
title = {{The mechanisms of emergence}},
url = {http://pos.sagepub.com/content/34/2/260.short http://www.artsci.wustl.edu/~ksawyer/PDFs/mechanisms.pdf},
volume = {34},
year = {2004}
}
@incollection{Pretz2011,
abstract = {The recovery and processing of metals is one of the oldest recycling measures of mankind and the reasons for this are due to energy saving considerations and to the conservation of primary raw materials. Processes for the treatment of obsolete scrap metal have to be adapted to the most frequently used metals and metal mixtures. Size reduction as well as screen classification and separating procedures are the most common stages in scrap metal processing plants. In this chapter an overview is given showing the typical equipment for the handling of scrap metals. In this context the design and functioning principle of scrap shears as well as shredder and post-shredder plants are discussed. Finally, a new and highly sophisticated method for the segregation of waste metals - the so-called sensor based sorting - is discussed and explained.
This chapter describes the fundamentals of metal recycling. It considers the process of mechanical processing of scrap. These processes are all that is required to produce metals that can be used without any difficulties and without further treatment in metallurgical plants. These metallurgical processes include the machinery that is actually a part of the downstream equipment involved in smelting and refining and thus these processes complete the recycling loop for metals. Mechanical treatment of different waste streams containing metals involves the use of well-established methods, which, as a rule, is profitable because of the high market value of the recovered metals and also because metals do not change their properties with use and hence can be recycled an unlimited number of times. The main aim of the processing methods is to achieve high recovery values as well as the best possible grades of the final metallic products. Newly developed systems such as sensor-based sorters are increasingly being implemented to improve separation efficiencies. Finally, re-smelting of the reclaimed products constitutes the closing of the complete recycling loop for metals.},
address = {Boston},
author = {Pretz, Thomas and Julius, J\"{o}rg},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/INE7AFZ4/Pretz and Julius - 2011 - Chapter 6 - Metal Waste.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {89--99},
publisher = {Academic Press},
title = {{Chapter 6 - Metal Waste}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100063 http://www.sciencedirect.com/science/article/pii/B9780123814753100063/pdfft?md5=ba1b5ec7efabbdbdba5baf3e969a7efc\&pid=3-s2.0-B9780123814753100063-main.pdf},
year = {2011}
}
@incollection{Calo2008,
abstract = {Forward search (FS) methods have been shown to be usefully employed for detecting multiple outliers in continuous multivariate data (Hadi, (1994); Atkinson et al., (2004)). Starting from an outlier-free subset of observations, they iteratively enlarge this good subset using Mahalanobis distances based only on the good observations. In this paper, an alternative formulation of the FS paradigm is presented, that takes a mixture of K > 1 normal components as a null model. The proposal is developed according to both the graphical and the inferential approach to FS-based outlier detection. The performance of the method is shown on an illustrative example and evaluated on a simulation experiment in the multiple cluster setting.},
author = {Cal\`{o}, Daniela G.},
editor = {Preisach, Christine and Burkhardt, Professor Dr Hans and Schmidt-Thieme, Professor Dr Lars and Decker, Professor Dr Reinhold},
isbn = {978-3-540-78239-1, 978-3-540-78246-9},
keywords = {Artificial Intelligence (incl. Robotics),Business Information Systems,Data Mining and Knowledge Discovery,Statistics- general},
mendeley-tags = {Artificial Intelligence (incl. Robotics),Business Information Systems,Data Mining and Knowledge Discovery,Statistics- general},
month = jan,
pages = {103--110},
publisher = {Springer Berlin Heidelberg},
series = {Studies in Classification, Data Analysis, and Knowledge Organization},
title = {{Mixture Models in Forward Search Methods for Outlier Detection}},
url = {http://link.springer.com/chapter/10.1007/978-3-540-78246-9\_13 http://link.springer.com/content/pdf/10.1007\%2F978-3-540-78246-9\_13.pdf},
year = {2008}
}
@incollection{MichaelGertz2009,
annote = {doi:10.1201/9781420069815-c10},
author = {{Michael Gertz} and {Carlos Rueda} and {Jianting Zhang}},
booktitle = {Scien},
isbn = {978-1-4200-6980-8},
month = dec,
publisher = {Chapman and Hall/CRC},
series = {Chapman \& Hall/CRC Computational Science},
title = {{Interoperability and Data Integration in the Geosciences}},
url = {http://dx.doi.org/10.1201/9781420069815-c10},
year = {2009}
}
@article{Le1997,
abstract = {In a network of sg sites, responses like levels of airborne pollutant concentrations may be monitored over time. The sites need not all measure the same set of response items and unmeasured items are considered as data missing by design. We propose a hierarchical Bayesian approach to interpolate the levels of, say, k responses at su other locations called ungauged sites and also the unmeasured levels of the k responses at the gauged sites. Our method involves two steps. First, when all hyperparameters are assumed to be known, a predictive distribution is derived. In turn, an interpolator, its variance and a simultaneous interpolation region are obtained. In step two, we propose the use of an empirical Bayesian approach to estimate the hyperparameters through an EM algorithm. We base our theory on a linear Gaussian model and the relationship between a multivariate normal and matrix T-distribution. Our theory allows us to pool data from several existing networks that measure different subsets of response items for interpolation.},
author = {Le, Nhu D. and Sun, Weimin and Zidek, James V.},
doi = {10.1111/1467-9868.00081},
issn = {1467-9868},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
keywords = {Bayesian Interpolation,Co-Kriging,Matrix T-Distribution,Predictive Distribution,Spatial Interpolation},
language = {en},
mendeley-tags = {Bayesian Interpolation,Co-Kriging,Matrix T-Distribution,Predictive Distribution,Spatial Interpolation},
month = jan,
number = {2},
pages = {501--510},
title = {{Bayesian Multivariate Spatial Interpolation with Data Missing by Design}},
url = {http://onlinelibrary.wiley.com/doi/10.1111/1467-9868.00081/abstract},
volume = {59},
year = {1997}
}
@article{Wood1988,
author = {Wood, Eric F. and Sivapalan, Murugesu and Beven, Keith J. and Band, Larry},
doi = {10.1016/0022-1694(88)90090-X},
issn = {00221694},
journal = {Journal of Hydrology},
month = sep,
number = {1-4},
pages = {29--47},
title = {{Effects of spatial variability and scale with implications to hydrologic modeling}},
url = {http://linkinghub.elsevier.com/retrieve/pii/002216948890090X},
volume = {102},
year = {1988}
}
@article{Beven1993109,
annote = {XVI General Assembly of the European Geophysical Society },
author = {Beven, Keith J.},
doi = {10.1016/0022-1694(93)90091-M},
issn = {0022-1694},
journal = {Journal of Hydrology},
number = {1–2},
pages = {109--123},
title = {{Estimating transport parameters at the grid scale: on the value of a single measurement}},
url = {http://www.sciencedirect.com/science/article/pii/002216949390091M},
volume = {143},
year = {1993}
}
@article{Chatterjee2007,
abstract = {The Anscombe dataset is popular for teaching the importance of graphics in data analysis. It consists of four datasets that have identical summary statistics (e.g., mean, standard deviation, and correlation) but dissimilar data graphics (scatterplots). In this article, we provide a general procedure to generate datasets with identical summary statistics but dissimilar graphics by using a genetic algorithm based approach.},
author = {Chatterjee, Sangit and Firat, Aykut},
doi = {10.1198/000313007X220057},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/A24ZHTXS/Chatterjee and Firat - 2007 - Generating Data with Identical Statistics but Diss.pdf:pdf},
issn = {0003-1305},
journal = {The American Statistician},
number = {3},
pages = {248--254},
title = {{Generating Data with Identical Statistics but Dissimilar Graphics}},
url = {http://www.tandfonline.com/doi/abs/10.1198/000313007X220057 http://www.tandfonline.com/doi/pdf/10.1198/000313007X220057},
volume = {61},
year = {2007}
}
@article{Smith1994,
author = {Smith, R. E. and Goodrich, D. R. and Woolhiser, David A. and Simanton, J. R.},
doi = {10.1029/93WR03184},
issn = {1944-7973},
journal = {Water Resources Research},
language = {en},
number = {3},
pages = {851--854},
shorttitle = {Comment on “Physically based hydrologic modeling},
title = {{Comment on “Physically based hydrologic modeling: 2, Is the concept realistic?” by R. B. Grayson, I. D. Moore, and T. A. McMahon}},
url = {http://onlinelibrary.wiley.com/doi/10.1029/93WR03184/abstract http://onlinelibrary.wiley.com/store/10.1029/93WR03184/asset/wrcr6425.pdf?v=1\&t=hfezejo6\&s=10d3f76916570c1d94351a93f2fa6bab380eea0b},
volume = {30},
year = {1994}
}
@book{Nriagu1983,
author = {Nriagu, Jerome O.},
isbn = {9780471087670},
keywords = {Antiquities,Folder - ch1,Lead,Lead - History,Lead poisoning,Lead-poisoning,Medical / Toxicology,Science / Chemistry / General,Technology \& Engineering / Metallurgy},
language = {en},
mendeley-tags = {Antiquities,Folder - ch1,Lead,Lead - History,Lead poisoning,Lead-poisoning,Medical / Toxicology,Science / Chemistry / General,Technology \& Engineering / Metallurgy},
pages = {464},
publisher = {Wiley},
title = {{Lead and Lead Poisoning in Antiquity}},
url = {http://books.google.com/books?id=O6RTAAAAMAAJ},
year = {1983}
}
@article{PinderIII2014,
abstract = {Data from published studies and World Wide Web sources were combined to produce and test a regression model to predict Cs concentration ratios for freshwater fish species. The accuracies of predicted concentration ratios, which were computed using 1) species trophic levels obtained from random resampling of known food items and 2) K concentrations in the water for 207 fish from 44 species and 43 locations, were tested against independent observations of ratios for 57 fish from 17 species from 25 locations. Accuracy was assessed as the percent of observed to predicted ratios within factors of 2 or 3. Conservatism, expressed as the lack of under prediction, was assessed as the percent of observed to predicted ratios that were less than 2 or less than 3. The model's median observed to predicted ratio was 1.26, which was not significantly different from 1, and 50\% of the ratios were between 0.73 and 1.85. The percentages of ratios within factors of 2 or 3 were 67 and 82\%, respectively. The percentages of ratios that were <2 or <3 were 79 and 88\%, respectively. An example for Perca fluviatilis demonstrated that increased prediction accuracy could be obtained when more detailed knowledge of diet was available to estimate trophic level.},
author = {{Pinder III}, John E. and Rowan, David J. and Rasmussen, Joseph B. and Smith, Jim T. and Hinton, Thomas G. and Whicker, F. W.},
doi = {10.1016/j.jenvrad.2014.03.003},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/EEHMQ33Z/Pinder III et al. - 2014 - Development and evaluation of a regression-based m.pdf:pdf},
issn = {0265-931X},
journal = {Journal of Environmental Radioactivity},
keywords = {Cs concentration ratios,Freshwater fish,K concentrations,Predictive model,Trophic levels,regression},
mendeley-tags = {Cs concentration ratios,Freshwater fish,K concentrations,Predictive model,Trophic levels,regression},
month = aug,
pages = {89--98},
title = {{Development and evaluation of a regression-based model to predict cesium concentration ratios for freshwater fish}},
url = {http://www.sciencedirect.com/science/article/pii/S0265931X14000812 http://www.sciencedirect.com/science/article/pii/S0265931X14000812/pdfft?md5=cc6272bcb50d317e8f5387d870717c79\&pid=1-s2.0-S0265931X14000812-main.pdf},
volume = {134},
year = {2014}
}
@article{Bozdogan2000a,
abstract = {In this paper we briefly study the basic idea of Akaike's (1973) information criterion (AIC). Then, we present some recent developments on a new entropic or information complexity (ICOMP) criterion of Bozdogan (1988a, 1988b, 1990, 1994d, 1996, 1998a, 1998b) for model selection. A rationale for ICOMP as a model selection criterion is that it combines a badness-of-fit term (such as minus twice the maximum log likelihood) with a measure of complexity of a model differently than AIC, or its variants, by taking into account the interdependencies of the parameter estimates as well as the dependencies of the model residuals. We operationalize the general form of ICOMP based on the quantification of the concept of overall model complexity in terms of the estimated inverse-Fisher information matrix. This approach results in an approximation to the sum of two Kullback-Leibler distances. Using the correlational form of the complexity, we further provide yet another form of ICOMP to take into account the interdependencies (i.e., correlations) among the parameter estimates of the model. Later, we illustrate the practical utility and the importance of this new model selection criterion by providing several real as well as Monte Carlo simulation examples and compare its performance against AIC, or its variants. Copyright 2000 Academic Press.},
author = {Bozdogan, H},
doi = {10.1006/jmps.1999.1277},
issn = {0022-2496},
journal = {Journal of mathematical psychology},
month = mar,
number = {1},
pages = {62--91},
pmid = {10733858},
title = {{Akaike's Information Criterion and Recent Developments in Information Complexity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10733858},
volume = {44},
year = {2000}
}
@article{Grayson1994c,
author = {Grayson, Rodger B. and Moore, Ian D. and McMahon, Thomas A.},
doi = {10.1029/93WR03185},
issn = {1944-7973},
journal = {Water Resources Research},
language = {en},
number = {3},
pages = {855--856},
shorttitle = {Reply [to “Comment on ‘Physically based hydrologic},
title = {{Reply [to “Comment on ‘Physically based hydrologic modeling: 2, Is the concept realistic?’ by R. B. Grayson, I. D. Moore, and T. A. McMahon”]}},
url = {http://onlinelibrary.wiley.com/doi/10.1029/93WR03185/abstract http://onlinelibrary.wiley.com/store/10.1029/93WR03185/asset/wrcr6426.pdf?v=1\&t=hfezamo6\&s=38815934f4de662002fd5f006beb158af4059234},
volume = {30},
year = {1994}
}
@article{Arlot2010a,
abstract = {Used to estimate the risk of an estimator or to perform model selection, cross-validation is a widespread strategy because of its simplicity and its (apparent) universality. Many results exist on model selection performances of cross-validation procedures. This survey intends to relate these results to the most recent advances of model selection theory, with a particular emphasis on distinguishing empirical statements from rigorous theoretical results. As a conclusion, guidelines are provided for choosing the best cross-validation procedure according to the particular features of the problem in hand.},
author = {Arlot, Sylvain and Celisse, Alain},
doi = {10.1214/09-SS054},
issn = {1935-7516},
journal = {Statistics Surveys},
keywords = {Model selection,cross-validation,leave-one-out},
language = {EN},
mendeley-tags = {Model selection,cross-validation,leave-one-out},
pages = {40--79},
title = {{A survey of cross-validation procedures for model selection}},
url = {http://projecteuclid.org/euclid.ssu/1268143839},
volume = {4},
year = {2010}
}
@article{Bell2009,
author = {Bell, Gordon and Hey, Tony and Szalay, Alex},
doi = {10.1126/science.1170411},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/KWG8ZA6C/Bell et al. - 2009 - Beyond the Data Deluge.pdf:pdf},
issn = {0036-8075, 1095-9203},
journal = {Science},
language = {en},
month = mar,
number = {5919},
pages = {1297--1298},
title = {{Beyond the Data Deluge}},
url = {http://www.sciencemag.org/content/323/5919/1297 http://www.ncbi.nlm.nih.gov/pubmed/19265007 http://www.sciencemag.org/content/323/5919/1297.full.pdf},
volume = {323},
year = {2009}
}
@article{Sharma,
abstract = {Inverse modeling technique based on nonlinear least square regression method (LSRM) is developed for the identification of aquatic source and transport parameters. Instantaneous line source release model in two-dimensional domain and continuous point source release model in three-dimensional domain are used for the purpose. Case studies have been carried out for both types of releases to illustrate their application. Error analysis has been carried out to identify the maximum error that can be tolerated in the input concentration data used in the inverse model and to specify the minimum number of sampling points to generate such input data. The LSRM is compared with the well-established correlation coefficient optimization method for instantaneous line source release model, and good comparison is observed between them. The LSRM is used to quantitatively estimate the releases of different radionuclides into the Pacific Ocean which has resulted due to the discharge of highly radioactive liquid effluent from the affected Daiichi Nuclear Power Station at Fukushima in Japan. The measured concentrations of these radionuclides in seawater samples collected from two sampling points near Fukushima are used for the estimation. The average release works out to be 1.09 × 1016 for 131I, 3.4 × 1015 Bq for 134Cs, and 3.57 × 1015 Bq for 137Cs. Very good agreement is observed between the releases estimated in this study and those estimated by other different agencies.},
author = {Sharma, L. K. and Ghosh, A. K. and Nair, R. N. and Chopra, Manish and Sunny, Faby and Puranik, V. D.},
doi = {10.1007/s10666-013-9391-1},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/TT42HG44/Sharma et al. - Inverse Modeling for Aquatic Source and Transport .pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/65IS88C9/s10666-013-9391-1.html:html},
issn = {1420-2026, 1573-2967},
journal = {Environmental Modeling \& Assessment},
keywords = {Applications of Mathematics,Fukushima DNPS,LSRM,Math. Appl. in Environmental Science,Mathematical Modeling and Industrial Mathematics,Operations Research/Decision Theory,Radionuclide,Surface water},
language = {en},
mendeley-tags = {Applications of Mathematics,Fukushima DNPS,LSRM,Math. Appl. in Environmental Science,Mathematical Modeling and Industrial Mathematics,Operations Research/Decision Theory,Radionuclide,Surface water},
pages = {1--14},
title = {{Inverse Modeling for Aquatic Source and Transport Parameters Identification and its Application to Fukushima Nuclear Accident}},
url = {http://link.springer.com/article/10.1007/s10666-013-9391-1 http://link.springer.com/content/pdf/10.1007\%2Fs10666-013-9391-1.pdf}
}
@article{Beven2002,
author = {Beven, Keith J.},
doi = {10.1098/rspa.2002.0986},
issn = {1364-5021},
journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
month = oct,
number = {2026},
pages = {2465--2484},
title = {{Towards a coherent philosophy for modelling the environment}},
url = {http://rspa.royalsocietypublishing.org/cgi/doi/10.1098/rspa.2002.0986},
volume = {458},
year = {2002}
}
@article{Mishali2007a,
abstract = {We address the problem of reconstructing a multi-band signal from its sub-Nyquist point-wise samples. To date, all reconstruction methods proposed for this class of signals assumed knowledge of the band locations. In this paper, we develop a non-linear blind perfect reconstruction scheme for multi-band signals which does not require the band locations. Our approach assumes an existing blind multi-coset sampling method. The sparse structure of multi-band signals in the continuous frequency domain is used to replace the continuous reconstruction with a single finite dimensional problem without the need for discretization. The resulting problem can be formulated within the framework of compressed sensing, and thus can be solved efficiently using known tractable algorithms from this emerging area. We also develop a theoretical lower bound on the average sampling rate required for blind signal reconstruction, which is twice the minimal rate of known-spectrum recovery. Our method ensures perfect reconstruction for a wide class of signals sampled at the minimal rate. Numerical experiments are presented demonstrating blind sampling and reconstruction with minimal sampling rate.},
author = {Mishali, Moshe and Eldar, Yonina C.},
journal = {arXiv:0709.1563},
keywords = {Nonlinear Sciences - Cellular Automata and Lattice,Nonlinear Sciences - Exactly Solvable and Integrab},
mendeley-tags = {Nonlinear Sciences - Cellular Automata and Lattice,Nonlinear Sciences - Exactly Solvable and Integrab},
month = sep,
shorttitle = {Blind Multi-Band Signal Reconstruction},
title = {{Blind Multi-Band Signal Reconstruction: Compressed Sensing for Analog Signals}},
url = {http://arxiv.org/abs/0709.1563 http://www.arxiv.org/pdf/0709.1563.pdf},
year = {2007}
}
@article{Gell-Mann1995,
author = {Gell-Mann, Murray},
doi = {10.1002/cplx.6130010105},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/TNXUX7D9/Gell-Mann - 1995 - What is complexity Remarks on simplicity and comp.pdf:pdf},
issn = {1099-0526},
journal = {Complexity},
language = {en},
month = sep,
number = {1},
pages = {16--19},
shorttitle = {What is complexity?},
title = {{What is complexity? Remarks on simplicity and complexity by the Nobel Prize-winning author of The Quark and the Jaguar}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/cplx.6130010105/abstract http://onlinelibrary.wiley.com/store/10.1002/cplx.6130010105/asset/6130010105\_ftp.pdf?v=1\&t=hv1cd2ja\&s=6530228c1b5eea0432a6e085c045b49e2f2d806e},
volume = {1},
year = {1995}
}
@incollection{Pichtel2014p3,
author = {Pichtel, John},
booktitle = {Waste Management Practices: Municipal, Hazardous, and Industrial, Second Edition},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/WRU3PGF6/2014 - Hazardous Waste Management.pdf:pdf},
isbn = {978-1-4665-8518-8},
month = jan,
pages = {353--354},
publisher = {CRC Press},
title = {{Hazardous Waste Management}},
url = {http://www.crcnetbase.com/doi/abs/10.1201/b16576-14 http://www.crcnetbase.com/doi/pdf/10.1201/b16576-14},
year = {2014}
}
@article{Koufakou2010,
abstract = {Outlier detection has attracted substantial attention in many applications and research areas; some of the most prominent applications are network intrusion detection or credit card fraud detection. Many of the existing approaches are based on calculating distances among the points in the dataset. These approaches cannot easily adapt to current datasets that usually contain a mix of categorical and continuous attributes, and may be distributed among different geographical locations. In addition, current datasets usually have a large number of dimensions. These datasets tend to be sparse, and traditional concepts such as Euclidean distance or nearest neighbor become unsuitable. We propose a fast distributed outlier detection strategy intended for datasets containing mixed attributes. The proposed method takes into consideration the sparseness of the dataset, and is experimentally shown to be highly scalable with the number of points and the number of attributes in the dataset. Experimental results show that the proposed outlier detection method compares very favorably with other state-of-the art outlier detection strategies proposed in the literature and that the speedup achieved by its distributed version is very close to linear.},
author = {Koufakou, Anna and Georgiopoulos, Michael},
doi = {10.1007/s10618-009-0148-z},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/2C7UKQ3M/Koufakou and Georgiopoulos - 2010 - A fast outlier detection strategy for distributed .pdf:pdf},
issn = {1384-5810, 1573-756X},
journal = {Data Mining and Knowledge Discovery},
keywords = {Anomaly detection,Artificial Intelligence (incl. Robotics),Computing Methodologies,Data Mining and Knowledge Discovery,Distributed data sets,High-dimensional data sets,Information Storage and Retrieval,Mixed attribute data sets,Statistics for Engineering- Physics- Computer Scie,Statistics- general,data mining,outlier detection},
language = {en},
mendeley-tags = {Anomaly detection,Artificial Intelligence (incl. Robotics),Computing Methodologies,Data Mining and Knowledge Discovery,Distributed data sets,High-dimensional data sets,Information Storage and Retrieval,Mixed attribute data sets,Statistics for Engineering- Physics- Computer Scie,Statistics- general,data mining,outlier detection},
month = mar,
number = {2},
pages = {259--289},
title = {{A fast outlier detection strategy for distributed high-dimensional data sets with mixed attributes}},
url = {http://link.springer.com/article/10.1007/s10618-009-0148-z http://link.springer.com/content/pdf/10.1007\%2Fs10618-009-0148-z.pdf},
volume = {20},
year = {2010}
}
@article{Branch2013,
abstract = {To address the problem of unsupervised outlier detection in wireless sensor networks, we develop an approach that (1) is flexible with respect to the outlier definition, (2) computes the result in-network to reduce both bandwidth and energy consumption, (3) uses only single-hop communication, thus permitting very simple node failure detection and message reliability assurance mechanisms (e.g., carrier-sense), and (4) seamlessly accommodates dynamic updates to data. We examine performance by simulation, using real sensor data streams. Our results demonstrate that our approach is accurate and imposes reasonable communication and power consumption demands.},
author = {Branch, Joel W. and Giannella, Chris and Szymanski, Boleslaw and Wolff, Ran and Kargupta, Hillol},
doi = {10.1007/s10115-011-0474-5},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/VAQ4K99T/s10115-011-0474-5.html:html},
issn = {0219-1377, 0219-3116},
journal = {Knowledge and Information Systems},
keywords = {Business Information Systems,In-network computation,Information Systems and Communication Service,outlier detection,wireless sensor networks},
language = {en},
mendeley-tags = {Business Information Systems,In-network computation,Information Systems and Communication Service,outlier detection,wireless sensor networks},
month = jan,
number = {1},
pages = {23--54},
title = {{In-network outlier detection in wireless sensor networks}},
url = {http://link.springer.com/article/10.1007/s10115-011-0474-5},
volume = {34},
year = {2013}
}
@article{Newell1951,
author = {Newell, John F. and Christenson, C. W.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/X23TXFVV/Newell and Christenson - 1951 - Radioactive Waste Disposal.pdf:pdf},
issn = {0096-364X},
journal = {Sewage and Industrial Wastes},
month = jul,
number = {7},
pages = {861--868},
title = {{Radioactive Waste Disposal}},
url = {http://www.jstor.org/stable/25031633 http://www.jstor.org/stable/pdfplus/25031633.pdf?acceptTC=true},
volume = {23},
year = {1951}
}
@book{Carson1962a,
abstract = {Silent Spring-Rachel Carson-1962},
author = {Carson, Rachel},
keywords = {Folder - ch1,chemicals},
language = {eng},
mendeley-tags = {Folder - ch1,chemicals},
title = {{Silent Spring}},
url = {http://archive.org/details/fp\_Silent\_Spring-Rachel\_Carson-1962},
year = {1962}
}
@incollection{TevfikKosar2009,
annote = {doi:10.1201/9781420069815-c4},
author = {{Tevfik Kosar} and {Andrei Hutanu} and {Jon McLaren} and {Douglas Thain}},
booktitle = {Scien},
isbn = {978-1-4200-6980-8},
month = dec,
publisher = {Chapman and Hall/CRC},
series = {Chapman \& Hall/CRC Computational Science},
title = {{Coordination of Access to Large-Scale Datasets in Distributed Environments}},
url = {http://dx.doi.org/10.1201/9781420069815-c4},
year = {2009}
}
@article{Grayson1994b,
author = {Grayson, Rodger B. and Moore, Ian D. and McMahon, Thomas A.},
doi = {10.1029/93WR03185},
issn = {1944-7973},
journal = {Water Resources Research},
language = {en},
number = {3},
pages = {855--856},
shorttitle = {Reply [to “Comment on ‘Physically based hydrologic},
title = {{Reply [to “Comment on ‘Physically based hydrologic modeling: 2, Is the concept realistic?’ by R. B. Grayson, I. D. Moore, and T. A. McMahon”]}},
url = {http://onlinelibrary.wiley.com/doi/10.1029/93WR03185/abstract http://onlinelibrary.wiley.com/store/10.1029/93WR03185/asset/wrcr6426.pdf?v=1\&t=hfezamo6\&s=38815934f4de662002fd5f006beb158af4059234},
volume = {30},
year = {1994}
}
@article{Bagtzoglou2014,
abstract = {This work applies optimization and an Eulerian inversion approach presented by Bagtzoglou and Baun in 2005 in order to reconstruct contaminant plume time histories and to identify the likely source of atmospheric contamination using data from a real test site for the first time. Present-day distribution of an atmospheric contaminant plume as well as data points reflecting the plume history allow the reconstruction and provide the plume velocity, distribution, and probable source. The method was tested to a hypothetical case and with data from the Forest Atmosphere Transfer and Storage (FACTS) experiment in the Duke experimental forest site. In the scenarios presented herein, as well as in numerous cases tested for verification purposes, the model conserved mass, successfully located the peak of the plume, and managed to capture the motion of the plume well but underestimated the contaminant peak.},
author = {Bagtzoglou, Amvrossios C. and Kenney, Eric D. and Hiscox, April and Miller, David R.},
doi = {10.1080/15275922.2014.890146},
issn = {1527-5922},
journal = {Environmental Forensics},
number = {2},
pages = {147--158},
title = {{Optimization-Based Atmospheric Plume Source Identification}},
url = {http://www.tandfonline.com/doi/abs/10.1080/15275922.2014.890146},
volume = {15},
year = {2014}
}
@inproceedings{Tianhong2013,
abstract = {Outliers are the observations which do not follow the regular pattern of system, and usually generated by the mechanical faults, measurement error, changes in system behavior. For the precise demand with the dynamic modeling, it is necessary to remove outliers from the measured raw data before constructing the model. Traditional statistical parameter estimation often fail to detect outliers in the functional profile. In this paper we propose a practical approach to outlier detection, which are based on the characteristics of time-dependent signal. The proposed algorithm included the change rate of signal calculation, statistical parameters estimation, signal recovering. A bioinformatic application demonstrates powerfulness of the proposed algorithm. The most advantage of the propose method is that it only clean (i.e., detects and recovers) outliers and preserves all other information in the observations.},
author = {Tianhong, Pan and Biao, Huang and Khare, S.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/UW3WBJD6/Tianhong et al. - 2013 - A practical algorithm to outlier detection and dat.pdf:pdf;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/MJZANDJ3/abs\_all.html:html},
keywords = {Compounds,Data models,Educational institutions,Indexes,Monitoring,Real Time Cell Analyzer (RTCA),Time-dependent Cellular Response Curve (TCRC),bioinformatic application,bioinformatics,data cleaning,dynamic modeling,noise,outlier detection,parameter estimation,signal calculation change rate,signal processing,signal recovering,statistical analysis,statistical parameter estimation,time-dependent signal characteristics},
mendeley-tags = {Compounds,Data models,Educational institutions,Indexes,Monitoring,Real Time Cell Analyzer (RTCA),Time-dependent Cellular Response Curve (TCRC),bioinformatic application,bioinformatics,data cleaning,dynamic modeling,noise,outlier detection,parameter estimation,signal calculation change rate,signal processing,signal recovering,statistical analysis,statistical parameter estimation,time-dependent signal characteristics},
month = jul,
pages = {1676--1679},
title = {{A practical algorithm to outlier detection and data cleaning for the time-dependent signal}},
url = {http://ieeexplore.ieee.org/ielx7/6621666/6639389/06639696.pdf?tp=\&arnumber=6639696\&isnumber=6639389 http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6639696},
year = {2013}
}
@article{Skoien2003,
author = {Sk\o ien, Jon Olav},
doi = {10.1029/2002WR001736},
issn = {0043-1397},
journal = {Water Resources Research},
number = {10},
pages = {1304},
title = {{Characteristic space scales and timescales in hydrology}},
url = {http://www.agu.org/pubs/crossref/2003/2002WR001736.shtml},
volume = {39},
year = {2003}
}
@article{Haddad,
abstract = {The complexity of mass transfer processes between the mobile and immobile zones in geohydrologic settings and the limitations that currently exist in the characterization of contaminated sites demand the development of improved models. In this work, we present a model that describes the mass transfer in structured porous media. This model considers divergent radial advective-dispersive transport in fractures and diffusive mass transfer inside rock matrix blocks. The heterogeneous nature of fractured formations is included with the integration of various distributions of rock matrix block sizes into the transport model. Breakthrough curves generated based on the developed model are analyzed to investigate the effects of the rate of injection, dispersivity and the immobile to mobile porosity ratio on mass transfer between mobile and immobile zones. It is shown that the developed model, in conjunction with tracer data collected from a monitoring well, can be used to estimate the dispersivity and fracture intensity. Results reveal that the dispersivity is independent of the rock matrix block size distribution for dispersion-dominant transport in fractures. These findings are used to develop a methodology to characterize rock matrix block size distribution in fractured aquifers and to estimate dispersivity based on a tracer test, which will improve our decisions concerning the remediation of contaminated sites.},
author = {Haddad, Amin Sharifi and Hassanzadeh, Hassan and Abedi, Jalal and Chen, Zhangxin},
doi = {10.1016/j.jhydrol.2014.01.008},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/F74PN6V4/S0022169414000134.html:html;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/VA5D5AHI/Haddad et al. - Application of tracer injection tests to character.pdf:pdf},
issn = {0022-1694},
journal = {Journal of Hydrology},
keywords = {Advection,Aquifer characterization,Breakthrough curve,Dispersion,Dispersivity,Fractured rock,Solute transport,ground water},
mendeley-tags = {Advection,Aquifer characterization,Breakthrough curve,Dispersion,Dispersivity,Fractured rock,Solute transport,ground water},
title = {{Application of tracer injection tests to characterize rock matrix block size distribution and dispersivity in fractured aquifers}},
url = {http://www.sciencedirect.com/science/article/pii/S0022169414000134 http://www.sciencedirect.com/science/article/pii/S0022169414000134/pdfft?md5=2632bef3921cd13bcd1098a44f008368\&pid=1-s2.0-S0022169414000134-main.pdf}
}
@article{Zidek2000,
abstract = {Networks of ambient monitoring stations are used to monitor environmental pollution fields such as those for acid rain and air pollution. Such stations provide regular measurements of pollutant concentrations. The networks are established for a variety of purposes at various times so often several stations measuring different subsets of pollutant concentrations can be found in compact geographical regions. The problem of statistically combining these disparate information sources into a single ‘network’ then arises. Capitalizing on the efficiencies so achieved can then lead to the secondary problem of extending this network. The subject of this paper is a set of 31 air pollution monitoring stations in southern Ontario. Each of these regularly measures a particular subset of ionic sulphate, sulphite, nitrite and ozone. However, this subset varies from station to station. For example only two stations measure all four. Some measure just one. We describe a Bayesian framework for integrating the measurements of these stations to yield a spatial predictive distribution for unmonitored sites and unmeasured concentrations at existing stations. Furthermore we show how this network can be extended by using an entropy maximization criterion. The methods assume that the multivariate response field being measured has a joint Gaussian distribution conditional on its mean and covariance function. A conjugate prior is used for these parameters, some of its hyperparameters being fitted empirically.},
author = {Zidek, J. V. and Sun, W. and Le, N. D.},
doi = {10.1111/1467-9876.00179},
issn = {1467-9876},
journal = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
keywords = {Data missing by design,Hierarchical Bayes method,Inverted Wishart distribution,Monitoring network,Nonparametric covariance estimation,Optimal design,air pollution,entropy,kriging,ozone,spatial prediction,sulphate},
language = {en},
mendeley-tags = {Data missing by design,Hierarchical Bayes method,Inverted Wishart distribution,Monitoring network,Nonparametric covariance estimation,Optimal design,air pollution,entropy,kriging,ozone,spatial prediction,sulphate},
month = jan,
number = {1},
pages = {63--79},
title = {{Designing and integrating composite networks for monitoring multivariate gaussian pollution fields}},
url = {http://onlinelibrary.wiley.com/doi/10.1111/1467-9876.00179/abstract},
volume = {49},
year = {2000}
}
@incollection{Stansbery2011,
abstract = {Earth-orbiting spacecraft have become an integral part of everyone's lives. People depend on them for communications, weather forecasts, scientific research, and national security. A real and growing concern for the safety and reliability of these satellites is the threat from collision with other orbiting objects, including space debris. Even small particles can damage, degrade, or destroy spacecraft due to the very high velocities involved in a collision. The three principal counter measures to this threat that are being used are shielding, collision avoidance, and curtailment of the creation of new debris through design and operational practices. In addition to the obvious due diligence aspect of protecting operational spacecraft, one long-term benefit of collision avoidance is the prevention of collisions between two large objects, which in turn could further degrade near-Earth space with large numbers of new debris, as was the case with the collision of Iridium 33 and Cosmos 2251. On the other hand, over 99\% of the risk to operational spacecraft from collisions with orbital debris comes from objects too small to track on a routine basis, that is, smaller than 10 cm. Hence, only an improvement in the orbital debris environment itself can dramatically reduce the risks to operational spacecraft.},
address = {Boston},
author = {Stansbery, Gene},
booktitle = {Waste: a handbook for management},
editor = {Letcher, Trevor M. and Vallero, Daniel A.},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/GX65WMIG/Stansbery - 2011 - Chapter 26 - Space Waste.pdf:pdf},
isbn = {978-0-12-381475-3},
pages = {377--391},
publisher = {Academic Press},
title = {{Chapter 26 - Space Waste}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123814753100269 http://www.sciencedirect.com/science/article/pii/B9780123814753100269/pdfft?md5=08f4a15b96f7fc7b75258e87af2381bf\&pid=3-s2.0-B9780123814753100269-main.pdf},
year = {2011}
}
@article{Sakaguchi2012,
abstract = {Concentrations of the radionuclides, U, Pu, and Cs were measured in water samples (10-20 L) to study analyte dispersion and migration following the Fukushima Daiichi Nuclear Power Plant (FDNPP) accident. A total of 8 water samples including oceanic water and paddy-field water were collected in the vicinity of the plant. Determinations of U, Pu and Cs isotopes were performed by accelerator mass spectrometry (AMS), inductively coupled plasma mass spectrometry (ICP-MS), and $\gamma$-ray spectrometry. The 236U/ 238U atom ratio was in the range 1.83-8.20 × 10-9 for fresh water and around 0.57 × 10-9 for seawater while the concentration of 236U was about 104-105 and 106 atoms/kg, respectively. Plutonium (239-240Pu) was detected in one riverine sample and the marine samples at very low levels and with large uncertainty. The concentrations of 137Cs in fresh riverine samples were 0.02-0.46 Bq/kg which are more than three orders of magnitude larger than the global fallout level. As for seawater samples within 80 km offshore of the FDNPP, the concentrations of 137Cs were 10-20 times higher than that of the Japan Sea water. Also 134Cs and 137Cs were of similar concentrations in all samples. The results show that volatile and refractory nuclides such as Cs, U and Pu exist in the dissolved phase, which can be readily assimilated by plants/humans. However the environmental impact of Pu and U in the vicinity of the FDNPP is considered to be low in comparison to that of the volatile radionuclide Cs. © 2012 by The Geochemical Society of Japan.},
annote = {Cited By (since 1996):11},
author = {Sakaguchi, A. and Kadokura, A. and Steier, P. and Tanaka, K. and Takahashi, Y. and Chiga, H. and Matsushima, A. and Nakashima, S. and Onda, Y.},
issn = {0016-7002},
journal = {Geochemical Journal},
keywords = {Caesium,Fukushima,Plutonium,Riverine water,Seawater,Uranium},
language = {English},
mendeley-tags = {Caesium,Fukushima,Plutonium,Riverine water,Seawater,Uranium},
number = {4},
pages = {355--360},
title = {{Isotopic Determination of U, Pu and Cs in environmental waters following the Fukushima Daiichi Nuclear Power Plant accident}},
volume = {46},
year = {2012}
}
@techreport{DuPontdeNemoursE.I.andCo.AikenS.C.USA.AtomicEnergyDiv.1962,
author = {{Du Pont de Nemours (E.I.) and Co., Aiken, S.C. (USA). Atomic Energy Div.}},
month = feb,
title = {{Health physics regional monitoring semiannual report, January--June 1961}},
url = {http://www.osti.gov/servlets/purl/4297950/},
year = {1962}
}
@article{Western2002,
author = {Western, Andrew W. and Grayson, Rodger B. and Bl\"{o}schl, G\"{u}nter},
journal = {Annual Review of Earth and Planetary Sciences},
number = {1},
pages = {149--180},
shorttitle = {Scaling of soil moisture},
title = {{Scaling of soil moisture: a hydrologic perspective}},
url = {http://www.annualreviews.org/doi/abs/10.1146/annurev.earth.30.091201.140434},
volume = {30},
year = {2002}
}
@article{Sun1999,
abstract = {Many numerical computer codes used to simulate multi-species reactive transport and biodegradation have been developed in recent years. Such numerical codes must be validated by comparison of the numerical solutions with an analytical solution. In this paper, a method for deriving analytical solutions of the partial differential equations describing multiple species multi-dimensional transport with first-order sequential reactions is presented. Although others have developed specific solutions of multi-species transport equations, here a more general analytical approach, capable of describing any number of reactive species in multiple dimensions is derived. A substitution method is used to transform the multi-species reactive transport problem to one that can be solved using previously published single-species solutions for various initial and boundary conditions. One- and three-dimensional examples are presented to illustrate the steps involved in extending single-species solutions to a four-species system with sequential first-order reactions.},
author = {Sun, Y. and Petersen, J.N. and Clement, T.P.},
doi = {10.1016/S0169-7722(98)00105-3},
issn = {0169-7722},
journal = {Journal of Contaminant Hydrology},
keywords = {Analytical solution,Biodegradation,First-order reaction,Multi-species,Transport},
mendeley-tags = {Analytical solution,Biodegradation,First-order reaction,Multi-species,Transport},
month = jan,
number = {4},
pages = {429--440},
title = {{Analytical solutions for multiple species reactive transport in multiple dimensions}},
url = {http://www.sciencedirect.com/science/article/pii/S0169772298001053 http://pdn.sciencedirect.com/science?\_ob=MiamiImageURL\&\_cid=271864\&\_user=4420\&\_pii=S0169772298001053\&\_check=y\&\_origin=article\&\_zone=toolbar\&\_coverDate=1999--15\&view=c\&originContentFamily=serial\&wchp=dGLbVlB-zSkzS\&md5=f0f89763b44f379666f52a6504c9c0f1\&pid=1-s2.0-S0169772298001053-main.pdf http://pdn.sciencedirect.com/science?\_ob=MiamiImageURL\&\_cid=271864\&\_user=4420\&\_pii=S0169772298001053\&\_check=y\&\_origin=article\&\_zone=toolbar\&\_cove},
volume = {35},
year = {1999}
}
@article{Brown1991a,
abstract = {K.F. Cheung and R.J. Marks (ibid., vol.CAS-32, no.5 p.481-4, 1985) have shown that if at least one of the interpolation functions used in the generalized sampling expansion of A. Papoulis (1977) is not square-integrable, then the problem is ill-posed in the sense that the variance of the reconstruction error is unbounded when noisy samples are used. It is shown that if all the interpolation functions are square-integrable, then the generalized sampling problem is well posed, essentially a converse of the Cheung-Marks result. A useful alternative sufficient condition for well-posedness that depends only on the transfer characteristics of the channels and does not require explicit calculation of the interpolation functions is developed. Several examples illustrating the results are given; in particular, the important nonuniform sampling strategy of J.L. Yen (IRE Trans. Circuits Theory, vol. CT-3, p.251-7, Dec. 1956) using bunched samples is shown to be well posed},
author = {Brown, J.L. and Cabrera, S.D.},
doi = {10.1109/31.76494},
issn = {0098-4094},
journal = {IEEE Transactions on Circuits and Systems},
keywords = {Circuit stability,Circuits and systems,Differential equations,Filters,Polynomials,Robustness,Sampling methods,Scattering,Stability criteria,filtering and prediction theory,generalized sampling expansion,interpolation,interpolation functions,noisy samples,random noise,reconstruction error,signal processing,square-integrable functions,transfer characteristics},
mendeley-tags = {Circuit stability,Circuits and systems,Differential equations,Filters,Polynomials,Robustness,Sampling methods,Scattering,Stability criteria,filtering and prediction theory,generalized sampling expansion,interpolation,interpolation functions,noisy samples,random noise,reconstruction error,signal processing,square-integrable functions,transfer characteristics},
number = {5},
pages = {554--556},
title = {{On well-posedness of the Papoulis generalized sampling expansion}},
url = {http://ieeexplore.ieee.org/ielx1/31/2550/00076494.pdf?tp=\&arnumber=76494\&isnumber=2550 http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=76494\&sortType=asc\_p\_Sequence\&filter=AND(p\_IS\_Number:2550)},
volume = {38},
year = {1991}
}
@article{Klemes1988,
abstract = {In practice, hydrology is regarded mostly as a technological discipline rather than a science; this attitude is responsible for much bad science in hydrology which, in turn, has led to much bad technology in applied disciplines. It is argued that the present offers a unique opportunity to fill the vacant niche of the science of hydrology and some suggestions for action are offered. The paper was written in the author's capacity as the current President of the International Association of Hydrological Sciences.},
author = {Kleme\v{s}, V.},
doi = {10.1016/0022-1694(88)90179-5},
issn = {0022-1694},
journal = {Journal of Hydrology},
month = jul,
number = {1–3},
pages = {3--28},
title = {{A hydrological perspective}},
url = {http://www.sciencedirect.com/science/article/pii/0022169488901795 http://www.sciencedirect.com/science?\_ob=MiamiImageURL\&\_cid=271842\&\_user=4420\&\_pii=0022169488901795\&\_check=y\&\_origin=article\&\_zone=toolbar\&\_coverDate=30-Jul-1988\&view=c\&originContentFamily=serial\&wchp=dGLbVlk-zSkzk\&md5=715b29bea7f33cec34299436903222fb\&pid=1-s2.0-0022169488901795-main.pdf},
volume = {100},
year = {1988}
}
@article{Mieles2012,
abstract = {The permeable reactive barrier (PRB) remediation technology has proven to be more cost-effective than conventional pump-and-treat systems, and has demonstrated the ability to rapidly reduce the concentrations of specific chemicals of concern (COCs) by up to several orders of magnitude in some scenarios. This study derives new steady-state analytical solutions to multispecies reactive transport in a PRB–aquifer (dual domain) system. The advantage of the dual domain model is that it can account for the potential existence of natural degradation in the aquifer, when designing the required PRB thickness. The study focuses primarily on the steady-state analytical solutions of the tetrachloroethene (PCE) serial degradation pathway and secondly on the analytical solutions of the parallel degradation pathway. The solutions in this study can also be applied to other types of dual domain systems with distinct flow and transport properties. The steady-state analytical solutions are shown to be accurate and the numerical program RT3D is selected for comparison. The results of this study are novel in that the solutions provide improved modeling flexibility including: 1) every species can have unique first-order reaction rates and unique retardation factors, and 2) daughter species can be modeled with their individual input concentrations or solely as byproducts of the parent species. The steady-state analytical solutions exhibit a limitation that occurs when interspecies reaction rate factors equal each other, which result in undefined solutions. Excel spreadsheet programs were created to facilitate prompt application of the steady-state analytical solutions, for both the serial and parallel degradation pathways.},
author = {Mieles, John and Zhan, Hongbin},
doi = {10.1016/j.jconhyd.2012.04.002},
issn = {0169-7722},
journal = {Journal of Contaminant Hydrology},
keywords = {In situ remediation,Modeling,Multispecies reactive transport,PRB design equations},
mendeley-tags = {In situ remediation,Modeling,Multispecies reactive transport,PRB design equations},
month = jun,
pages = {54--68},
title = {{Analytical solutions of one-dimensional multispecies reactive transport in a permeable reactive barrier-aquifer system}},
url = {http://www.sciencedirect.com/science/article/pii/S0169772212000538 http://pdn.sciencedirect.com/science?\_ob=MiamiImageURL\&\_cid=271864\&\_user=4420\&\_pii=S0169772212000538\&\_check=y\&\_origin=article\&\_zone=toolbar\&\_coverDate=30-Jun-2012\&view=c\&originContentFamily=serial\&wchp=dGLbVBA-zSkzk\&md5=03cea8db5b62491768257f0b97908861\&pid=1-s2.0-S0169772212000538-main.pdf http://www.sciencedirect.com/science/article/pii/S0169772212000538\#},
volume = {134–135},
year = {2012}
}
@article{Jothityangkoon2001,
author = {Jothityangkoon, Chatchai and Sivapalan, M. and Farmer, D. L.},
journal = {Journal of Hydrology},
number = {1},
pages = {174--198},
shorttitle = {Process controls of water balance variability in a},
title = {{Process controls of water balance variability in a large semi-arid catchment: downward approach to hydrological model development}},
url = {http://www.sciencedirect.com/science/article/pii/S0022169401004966 http://sutir.sut.ac.th:8080/sutir/bitstream/123456789/884/1/Process+controls+of+water+balance+variability+in+a+large+semi-arid+catchment+downward+approach+to+hydrological+model+development\_full.pdf},
volume = {254},
year = {2001}
}
@article{Chitsazan2014,
abstract = {Groundwater prediction models are subjected to various sources of uncertainty. This study introduces a hierarchical Bayesian model averaging (HBMA) method to segregate and prioritize sources of uncertainty in a hierarchical structure and conduct BMA for concentration prediction. A BMA tree of models is developed to understand the impact of individual sources of uncertainty and uncertainty propagation to model predictions. HBMA evaluates the relative importance of different modeling propositions at each level in the BMA tree of model weights. The HBMA method is applied to chloride concentration prediction for the “1,500-foot” sand of the Baton Rouge area, Louisiana from 2005 to 2029. The groundwater head data from 1990 to 2004 is used for model calibration. Four sources of uncertainty are considered and resulted in 180 flow and transport models for concentration prediction. The results show that prediction variances of concentration from uncertain model elements are much higher than the prediction variance from uncertain model parameters. The HBMA method is able to quantify the contributions of individual sources of uncertainty to the total uncertainty.},
author = {Chitsazan, Nima and Tsai, Frank T.-C.},
doi = {10.1111/gwat.12207},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/FUA4DF9A/Chitsazan and Tsai - 2014 - A Hierarchical Bayesian Model Averaging Framework .pdf:pdf},
issn = {1745-6584},
journal = {Groundwater},
language = {en},
month = may,
pages = {n/a--n/a},
title = {{A Hierarchical Bayesian Model Averaging Framework for Groundwater Prediction under Uncertainty}},
url = {http://onlinelibrary.wiley.com/doi/10.1111/gwat.12207/abstract http://onlinelibrary.wiley.com/store/10.1111/gwat.12207/asset/gwat12207.pdf?v=1\&t=hvyzbbyf\&s=8f938f8b71cf6be901df302c98ab6015d00bafe8},
year = {2014}
}
@book{Landes2003,
abstract = {For over thirty years David S. Landes's The Unbound Prometheus has offered an unrivalled history of industrial revolution and economic development in Europe. Now, in this new edition, the author reframes and reasserts his original arguments in the light of current debates about globalisation and comparative economic growth. The book begins with a classic account of the characteristics, progress, and political, economic and social implications of the Industrial Revolution in Britain, France and Germany. Professor Landes here raises the much-debated question: why was Europe the first to industrialise? He then charts the economic history of the twentieth-century: the effect of the First World War in accelerating the dissolution of the old international economy; the economic crisis of 1929-32; Europe's recovery and unprecedented economic growth following the Second World War. He concludes that only by continuous industrial revolution can Europe and the world sustain itself in the years ahead.},
author = {Landes, David S.},
isbn = {9780521534024},
keywords = {Business \& Economics / Corporate \& Business Histor,Business \& Economics / Economic History,Business \& Economics / Industries / General,Folder - ch1,History / Europe / General,History / Modern / 20th Century,History / Modern / General,History / Renaissance},
language = {en},
mendeley-tags = {Business \& Economics / Corporate \& Business Histor,Business \& Economics / Economic History,Business \& Economics / Industries / General,Folder - ch1,History / Europe / General,History / Modern / 20th Century,History / Modern / General,History / Renaissance},
month = jun,
pages = {590},
publisher = {Cambridge University Press},
shorttitle = {The Unbound Prometheus},
title = {{The Unbound Prometheus: Technological Change and Industrial Development in Western Europe from 1750 to the Present}},
url = {http://books.google.com/books?id=qqDWGXjhZIYC},
year = {2003}
}
@book{Hey2009,
address = {Redmond (Wash.)},
author = {Hey, Anthony J. G. and Tansley, Stewart and Tolle, Kristin},
isbn = {9780982544204  0982544200},
language = {English},
publisher = {Microsoft Research},
title = {{The Fourth Paradigm Data-Intensive Scientific Discovery}},
url = {http://research.microsoft.com/en-us/collaboration/fourthparadigm/},
year = {2009}
}
@article{Avinur1960,
author = {Avinur, P. and Nir, A.},
doi = {10.1038/188652a0},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/WUC5ITBZ/Avinur and Nir - 1960 - Separation Factor of Tritiated Water Fractional in.pdf:pdf},
journal = {Nature},
language = {en},
month = nov,
number = {4751},
pages = {652--652},
title = {{Separation Factor of Tritiated Water Fractional in Distillation}},
url = {http://www.nature.com/nature/journal/v188/n4751/abs/188652a0.html http://www.nature.com/nature/journal/v188/n4751/pdf/188652a0.pdf},
volume = {188},
year = {1960}
}
@article{Wang2013,
author = {Wang, Yue Ying and Li, Xiang and Xi, Bei Dou and Bai, Shun Guo and Li, Ming Xiao and Li, Juan},
doi = {10.4028/www.scientific.net/AMR.838-841.995},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/C3NII6X4/AMR.838-841.html:html},
issn = {1662-8985},
journal = {Advanced Materials Research},
month = nov,
pages = {995--1002},
title = {{Effect of Spatial Uncertainty of Unsaturated Zone Permeability Coefficient on Cl\&lt;sup\&gt;-\&lt;/sup\&gt; Migration}},
url = {http://www.scientific.net/AMR.838-841.995},
volume = {838-841},
year = {2013}
}
@article{Brown1991,
abstract = {K.F. Cheung and R.J. Marks (ibid., vol.CAS-32, no.5 p.481-4, 1985) have shown that if at least one of the interpolation functions used in the generalized sampling expansion of A. Papoulis (1977) is not square-integrable, then the problem is ill-posed in the sense that the variance of the reconstruction error is unbounded when noisy samples are used. It is shown that if all the interpolation functions are square-integrable, then the generalized sampling problem is well posed, essentially a converse of the Cheung-Marks result. A useful alternative sufficient condition for well-posedness that depends only on the transfer characteristics of the channels and does not require explicit calculation of the interpolation functions is developed. Several examples illustrating the results are given; in particular, the important nonuniform sampling strategy of J.L. Yen (IRE Trans. Circuits Theory, vol. CT-3, p.251-7, Dec. 1956) using bunched samples is shown to be well posed},
author = {Brown, J.L. and Cabrera, S.D.},
doi = {10.1109/31.76494},
issn = {0098-4094},
journal = {IEEE Transactions on Circuits and Systems},
keywords = {Circuit stability,Circuits and systems,Differential equations,Filters,Polynomials,Robustness,Sampling methods,Scattering,Stability criteria,filtering and prediction theory,generalized sampling expansion,interpolation,interpolation functions,noisy samples,random noise,reconstruction error,signal processing,square-integrable functions,transfer characteristics},
mendeley-tags = {Circuit stability,Circuits and systems,Differential equations,Filters,Polynomials,Robustness,Sampling methods,Scattering,Stability criteria,filtering and prediction theory,generalized sampling expansion,interpolation,interpolation functions,noisy samples,random noise,reconstruction error,signal processing,square-integrable functions,transfer characteristics},
number = {5},
pages = {554--556},
title = {{On well-posedness of the Papoulis generalized sampling expansion}},
url = {http://ieeexplore.ieee.org/ielx1/31/2550/00076494.pdf?tp=\&arnumber=76494\&isnumber=2550 http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=76494\&sortType=asc\_p\_Sequence\&filter=AND(p\_IS\_Number:2550)},
volume = {38},
year = {1991}
}
@article{Sudicky1990,
abstract = {A new and efficient technique is presented for numerical solution of solute transport problems in multi-dimensional double-porosity media. The method is based on the Laplace Transform Galerkin (LTG) technique (Sudicky, 1989) and employs a convolution integral in the governing advection-dispersion equation to express the diffusive exchange of solute between the mobile and immobile regions. Because the Laplace transformation is applied to the advection-dispersion equation describing transport in the mobile region, the convolution integral, in addition to the temporal derivative, is effectively removed. After the transformed equation is solved using the Galerkin finite element method, nodal concentrations in the time-domain are obtained using a robust and efficient algorithm for inversion of the Laplace-domain nodal concentrations. The method permits the solution to be evaluated at any future point in time without any need for time steps and permits the use of grids having a relatively coarse spatial discretization while avoiding significant numerical dispersion. Further computational efficiency is achieved for large-grid problems by employing an ORTHOMIN-accelerated iterative solver (Vinsome, 1976) to solve the system of Laplace-domain finite element equations. Influence functions describing the mobile-immobile region solute transfer are presented for the case of slab and sphere geometries for the immobile-fluid zone and for the case of first-order exchange theory, along with expressions which unify the three approaches. The utility of the model is demonstrated by applying it to the problem of solute transport in a sandy-type aquifer having a random, spatially-correlated hydraulic conductivity field and comprised of slightly porous grains that admit intragranular diffusion but do not conduct fluid.},
author = {Sudicky, E.A.},
doi = {10.1016/0016-7061(90)90016-3},
issn = {0016-7061},
journal = {Geoderma},
month = mar,
number = {1–3},
pages = {209--232},
title = {{The Laplace Transform Galerkin technique for efficient time-continuous solution of solute transport in double-porosity media}},
url = {http://www.sciencedirect.com/science/article/pii/0016706190900163 http://pdn.sciencedirect.com/science?\_ob=MiamiImageURL\&\_cid=271789\&\_user=4420\&\_pii=0016706190900163\&\_check=y\&\_origin=article\&\_zone=toolbar\&\_coverDate=31-Mar-1990\&view=c\&originContentFamily=serial\&wchp=dGLbVlS-zSkWA\&md5=db45dda0faef843c796f906d8b926c05\&pid=1-s2.0-0016706190900163-main.pdf},
volume = {46},
year = {1990}
}
@incollection{Pichtel2014ch17,
author = {Pichtel, John},
booktitle = {Waste Management Practices: Municipal, Hazardous, and Industrial, Second Edition},
chapter = {17},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/788A6RJZ/2014 - Land Disposal of Hazardous Waste.pdf:pdf},
isbn = {978-1-4665-8518-8},
month = jan,
pages = {495--514},
publisher = {CRC Press},
title = {{Land Disposal of Hazardous Waste}},
url = {http://www.crcnetbase.com/doi/abs/10.1201/b16576-21 http://www.crcnetbase.com/doi/pdf/10.1201/b16576-21},
year = {2014}
}
@article{Hadley2013,
abstract = {The groundwater remediation field has been changing constantly since it first emerged in the 1970s. The remediation field has evolved from a dissolved-phase centric conceptual model to a DNAPL-dominated one, which is now being questioned due to a renewed appreciation of matrix diffusion effects on remediation. Detailed observations about contaminant transport have emerged from the remediation field, and challenge the validity of one of the mainstays of the groundwater solute transport modeling world: the concept of mechanical dispersion (Payne et al. 2008). We review and discuss how a new conceptual model of contaminant transport based on diffusion (the usurper) may topple the well-established position of mechanical dispersion (the status quo) that is commonly used in almost every groundwater contaminant transport model, and evaluate the status of existing models and modeling studies that were conducted using advection-dispersion models.},
author = {Hadley, Paul W. and Newell, Charles},
doi = {10.1111/gwat.12135},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/CWQSIS4R/abstract.html:html;:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/UK37WTN9/Hadley and Newell - 2013 - The New Potential for Understanding Groundwater Co.pdf:pdf},
issn = {1745-6584},
journal = {Groundwater},
language = {en},
pages = {n/a--n/a},
title = {{The New Potential for Understanding Groundwater Contaminant Transport}},
url = {http://onlinelibrary.wiley.com/doi/10.1111/gwat.12135/abstract http://onlinelibrary.wiley.com/store/10.1111/gwat.12135/asset/gwat12135.pdf?v=1\&t=hof1od2q\&s=5e71a848ddf1d75c68cf00185cf66c565e95f857},
year = {2013}
}
@article{Hynds,
abstract = {An integrated domestic well sampling and “susceptibility assessment” programme was undertaken in the Republic of Ireland from April 2008 to November 2010. Overall, 211 domestic wells were sampled, assessed and collated with local climate data. Based upon groundwater physicochemical profile, three clusters have been identified and characterized by source type (borehole or hand-dug well) and local geological setting. Statistical analysis indicates that cluster membership is significantly associated with the prevalence of bacteria (p = 0.001), with mean E. coli presence within clusters ranging from 15.4\% (Cluster-1) to 47.6\% (Cluster-3). Bivariate risk factor analysis shows that on-site septic tank presence was the only risk factor significantly associated (p < 0.05) with bacterial presence within all clusters. Point agriculture adjacency was significantly associated with both borehole-related clusters. Well design criteria were associated with hand-dug wells and boreholes in areas characterized by high permeability subsoils, while local geological setting was significant for hand-dug wells and boreholes in areas dominated by low/moderate permeability subsoils. Multivariate susceptibility models were developed for all clusters, with predictive accuracies of 84\% (Cluster-1) to 91\% (Cluster-2) achieved. Septic tank setback was a common variable within all multivariate models, while agricultural sources were also significant, albeit to a lesser degree. Furthermore, well liner clearance was a significant factor in all models, indicating that direct surface ingress is a significant well contamination mechanism. Identification and elucidation of cluster-specific contamination mechanisms may be used to develop improved overall risk management and wellhead protection strategies, while also informing future remediation and maintenance efforts.},
author = {Hynds, Paul and Misstear, Bruce D. and Gill, Laurence W. and Murphy, Heather M.},
doi = {10.1016/j.jconhyd.2014.02.001},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/4Q5AJ754/Hynds et al. - Groundwater source contamination mechanisms Physi.pdf:pdf},
issn = {0169-7722},
journal = {Journal of Contaminant Hydrology},
keywords = {Cluster Analysis,E. coli,Groundwater,Physicochemical Profile,Risk Factor Analysis},
mendeley-tags = {Cluster Analysis,E. coli,Groundwater,Physicochemical Profile,Risk Factor Analysis},
shorttitle = {Groundwater source contamination mechanisms},
title = {{Groundwater source contamination mechanisms: Physicochemical profile clustering, risk factor analysis and multivariate modelling}},
url = {http://www.sciencedirect.com/science/article/pii/S0169772214000254 http://www.sciencedirect.com/science/article/pii/S0169772214000254/pdfft?md5=8cd4eff28f4cb7b6614a11a77bd4f925\&pid=1-s2.0-S0169772214000254-main.pdf}
}
@article{Yen1956,
abstract = {The purpose of this investigation is to examine four special nonuniform sampling processes in detail, and to deduce some interesting properties of bandwidth-limited signals. The main results are contained in four generalized sampling theorems. These theorems not only contain the nature of determination (unique-specification, over-specification, and underspecification) of signals but also include explicit reconstruction formulas. From the reconstruction formulas, the complexity and accuracy of the nonuniform sampling processes discussed can be estimated. In addition, these theorems lead to observations regarding the allowable shapes, the "prediction," and the "energy" of bandwidth-limited signals in general. A "minimum-energy" signal is introduced which has certain advantages as compared to the ordinary "time-limited" signals when a finite number of sample values are given. Finally, a statement due to Cauchy on the sampling of bandwidth-limited signals is generalized to include a wider class of nonuniform sample point distributions and modified to give more exact information regarding the nature of determination of signals.},
author = {Yen, J.},
doi = {10.1109/TCT.1956.1086325},
issn = {0096-2007},
journal = {IRE Transactions on Circuit Theory},
keywords = {Bridges,Frequency conversion,Mathematics,Nonuniform sampling,Physics,Sampling methods,Signal sampling,Telegraphy,interpolation,signal processing},
mendeley-tags = {Bridges,Frequency conversion,Mathematics,Nonuniform sampling,Physics,Sampling methods,Signal sampling,Telegraphy,interpolation,signal processing},
number = {4},
pages = {251--257},
title = {{On Nonuniform Sampling of Bandwidth-Limited Signals}},
url = {http://ieeexplore.ieee.org/ielx5/8148/23600/01086325.pdf?tp=\&arnumber=1086325\&isnumber=23600 http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=1086325\&sortType=asc\_p\_Sequence\&filter=AND(p\_IS\_Number:23600)},
volume = {3},
year = {1956}
}
@article{Stephens2002,
abstract = {* 1During the past 15 years, models have been used increasingly in predictive population ecology. Matrix models used for predicting the fates of populations are often extremely basic, ignoring density dependence, spatial scale and behaviour, and often based on one sex only. We tested the importance of some of these omissions for model realism, by comparing the performance of a variety of population models of varying levels of complexity.
* 2Detailed data from more than 13 years of behavioural and demographic research on a population of alpine marmots Marmota marmota in Berchtesgaden National Park, southern Germany, were used to parameterize four different population models. The models ranged from a simple population-based matrix model, to a spatially explicit behaviour-based model.
* 3The performance of the models was judged by their ability to predict basic population dynamics under equilibrium conditions. Only a spatially explicit individual-based model ignoring optimal behaviour predicted dynamics significantly different to those observed in the field, highlighting the importance of considering realistic patterns of behaviour in spatially explicit models.
* 4Using realistic levels of environmental and demographic stochasticity, variance in population growth rates predicted by all models was high, even within the range of population densities experienced in the field. This emphasizes the difficulty of using population-level field data to determine overall patterns of density dependence for use in population models.
* 5All models were also used to predict potential density-dependent effects on alpine marmot population growth. In this regard, the models differed greatly. It was concluded that the simplest matrix model was adequate for making predictions regarding population sizes or densities under equilibrium conditions, but that for predictions requiring an understanding of transient dynamics only the behavioural model would be adequate.
* 6An emergent feature of this study of alpine marmot population dynamics was the prediction of a demographic Allee effect with a profound influence on population dynamics across a very broad range of population sizes. Three mechanisms were identified as underlying this Allee effect: stochastic skews in sex ratio and demographic composition at low population sizes; less efficient social thermoregulation during hibernation in small groups; and difficulties with mate finding during dispersal, even at relatively high population sizes.},
author = {Stephens, Philip A. and Frey-roos, Fredy and Arnold, Walter and Sutherland, Wlliam J.},
doi = {10.1046/j.1365-2656.2002.00605.x},
file = {:Users/arthur/Library/Application Support/Mendeley Desktop/Downloaded/5M4DVW63/Stephens et al. - 2002 - Model complexity and population predictions. The a.pdf:pdf},
issn = {1365-2656},
journal = {Journal of Animal Ecology},
keywords = {Allee effects,behaviour-based models,density dependence,individual-based models,matrix models},
language = {en},
mendeley-tags = {Allee effects,behaviour-based models,density dependence,individual-based models,matrix models},
month = mar,
number = {2},
pages = {343--361},
title = {{Model complexity and population predictions. The alpine marmot as a case study}},
url = {http://onlinelibrary.wiley.com/doi/10.1046/j.1365-2656.2002.00605.x/abstract http://onlinelibrary.wiley.com/store/10.1046/j.1365-2656.2002.00605.x/asset/j.1365-2656.2002.00605.x.pdf?v=1\&t=hv1chfp8\&s=e3124757254d80fe4e0f3d113b3ebc23a2000e7d},
volume = {71},
year = {2002}
}
@article{Jury1982,
abstract = {A transfer function model is proposed for simulating solute transport under natural field conditions where substantial variability exists in water transport properties. This approach makes no attempt to describe the variability through a deterministic model but merely measures the distribution of solute travel times from the soil surface to a reference depth. Using this distribution function, it is possible to simulate the average solute concentrations at any depth and time for arbitrary solute inputs or water application variability. Equivalently, the model may be used to predict the probability of extremely long or short travel times for a mobile chemical. In this paper several illustrative calculations are performed for which analytic solutions are possible. In a companion paper (Jury et al., this issue) a field test of the model is reported.},
author = {Jury, William A.},
doi = {10.1029/WR018i002p00363},
issn = {1944-7973},
journal = {Water Resources Research},
language = {en},
number = {2},
pages = {363--368},
title = {{Simulation of solute transport using a transfer function model}},
url = {http://onlinelibrary.wiley.com/doi/10.1029/WR018i002p00363/abstract http://onlinelibrary.wiley.com/doi/10.1029/WR018i002p00363/full http://onlinelibrary.wiley.com/store/10.1029/WR018i002p00363/asset/wrcr3107.pdf?v=1\&t=hl1p13vx\&s=205d3770d2d317731806adbf00fb6dc61e175849},
volume = {18},
year = {1982}
}
@book{Pichtel2005b,
author = {Pichtel, John},
edition = {1st},
isbn = {978-0-8493-3525-9},
month = mar,
publisher = {CRC Press},
title = {{Waste Management Practices}},
url = {http://www.crcnetbase.com/doi/book/10.1201/9781420037517},
year = {2005}
}
@article{Srzic2013a,
abstract = {In this paper we study the influence of high log-conductivity variance ($\sigma$Y2) and local scale dispersion on the first two concentration moments as well as on higher order moments, skewness and kurtosis, in a two-dimensional heterogeneous aquifer. Three different heterogeneity structures are considered, defined with one and the same global isotropic Gaussian variogram. The three structures differ in terms of spatial connectivity patterns at extreme log-conductivity values. Our numerical approach to simulate contaminant transport through heterogeneous porous media is based on the Lagrangian framework with a reverse tracking formulation. Advection and local scale dispersion are two competing and controlling mechanisms, with a relative ratio defined by the Peclet number (Pe); hydraulic log-conductivity variance $\sigma$Y2 in the simulations is assumed to be 1 or 8. The term local scale dispersion is used as a combined effect of molecular diffusion and mechanical dispersion. Uncertainty of the concentration field is quantified by the second order moment, or the coefficient of variation (CVC) as a function of the sampling position along a centerline, Peclet number and $\sigma$Y2, as well as by higher order moments, i.e., skewness and kurtosis. $\sigma$Y2 shows a strong influence on the concentration statistics while the three different structures have a minor impact in the case of low heterogeneity. The results also indicate that for $\sigma$Y2 equal to eight, the influence of local scale dispersion is significant after five integral scales (IY) from the source for the CN field, while in case of a DN field, the local scale dispersion effect is observed after 20 IY from the source. In the case of unit $\sigma$Y2, local scale dispersion acts very slowly affecting concentration uncertainty at distances higher than 20 IY from the source. Our inspection of Monte-Carlo (MC) concentration skewness and kurtosis with ones obtained from the Beta distribution show the discrepancies for high $\sigma$Y2 and CN log-conductivity structure.},
author = {Srzic, Veljko and Cvetkovic, Vladimir and Andricevic, Roko and Gotovac, Hrvoje},
doi = {10.1002/wrcr.20314},
issn = {1944-7973},
journal = {Water Resources Research},
keywords = {Advection,Concentration uncertainty,Heterogeneity structure,Kurtosis,Local scale dispersion,Skewness},
language = {en},
mendeley-tags = {Advection,Concentration uncertainty,Heterogeneity structure,Kurtosis,Local scale dispersion,Skewness},
pages = {n/a--n/a},
title = {{Impact of aquifer heterogeneity structure and local scale dispersion on solute concentration uncertainty}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/wrcr.20314/abstract http://onlinelibrary.wiley.com/store/10.1002/wrcr.20314/asset/wrcr20314.pdf?v=1\&t=hh8dtl54\&s=59950d9d73b86ac7cf08818c394b4ee5e26f0f50},
year = {2013}
}
@article{Dausman2010,
abstract = {The present study demonstrates a methodology for optimization of environmental data acquisition. Based on the premise that the worth of data increases in proportion to its ability to reduce the uncertainty of key model predictions, the methodology can be used to compare the worth of different data types, gathered at different locations within study areas of arbitrary complexity. The method is applied to a hypothetical nonlinear, variable density numerical model of salt and heat transport. The relative utilities of temperature and concentration measurements at different locations within the model domain are assessed in terms of their ability to reduce the uncertainty associated with predictions of movement of the salt water interface in response to a decrease in fresh water recharge. In order to test the sensitivity of the method to nonlinear model behavior, analyses were repeated for multiple realizations of system properties. Rankings of observation worth were similar for all realizations, indicating robust performance of the methodology when employed in conjunction with a highly nonlinear model. The analysis showed that while concentration and temperature measurements can both aid in the prediction of interface movement, concentration measurements, especially when taken in proximity to the interface at locations where the interface is expected to move, are of greater worth than temperature measurements. Nevertheless, it was also demonstrated that pairs of temperature measurements, taken in strategic locations with respect to the interface, can also lead to more precise predictions of interface movement.},
author = {Dausman, Alyssa M and Doherty, John and Langevin, Christian D and Sukop, Michael C},
doi = {10.1111/j.1745-6584.2010.00679.x},
issn = {1745-6584},
journal = {Ground water},
keywords = {Data Interpretation, Statistical,Seawater,Uncertainty,Water Movements},
number = {5},
pages = {729--40},
pmid = {20132327},
title = {{Quantifying data worth toward reducing predictive uncertainty.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20132327},
volume = {48},
year = {2010}
}
@incollection{Pichtel2005a,
author = {Pichtel, John},
booktitle = {Waste Management Practices},
chapter = {2},
doi = {10.1201/9781420037517.ch2},
isbn = {978-0-8493-3525-9, 978-1-4200-3751-7},
month = mar,
pages = {21--46},
publisher = {CRC Press},
title = {{A Brief History of Waste Management}},
url = {http://www.crcnetbase.com/doi/abs/10.1201/9781420037517.ch2},
year = {2005}
}
@article{Fang2009,
author = {Fang, Yilin and Yabusaki, Steven B. and Morrison, Stan J. and Amonette, James P. and Long, Philip E.},
doi = {10.1016/j.gca.2009.07.019},
issn = {00167037},
journal = {Geochimica et Cosmochimica Acta},
month = oct,
number = {20},
pages = {6029--6051},
publisher = {Elsevier Ltd},
title = {{Multicomponent reactive transport modeling of uranium bioremediation field experiments}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S001670370900458X},
volume = {73},
year = {2009}
}
@book{Mokyr1990,
abstract = {In a world of supercomputers, genetic engineering, and fiber optics, technological creativity is ever more the key to economic success. But why are some nations more creative than others, and why do some highly innovative societies--such as ancient China, or Britain in the industrial revolution--pass into stagnation? Beginning with a fascinating, concise history of technological progress, Mokyr sets the background for his analysis by tracing the major inventions and innovations that have transformed society since ancient Greece and Rome. What emerges from this survey is often surprising: the classical world, for instance, was largely barren of new technology, the relatively backward society of medieval Europe bristled with inventions, and the period between the Reformation and the Industrial Revolution was one of slow and unspectacular progress in technology, despite the tumultuous developments associated with the Voyages of Discovery and the Scientific Revolution. What were the causes of technological creativity? Mokyr distinguishes between the relationship of inventors and their physical environment--which determined their willingness to challenge nature--and the social environment, which determined the openness to new ideas. He discusses a long list of such factors, showing how they interact to help or hinder a nation's creativity, and then illustrates them by a number of detailed studies taken from the history of Europe and China. He examines such aspects as the role of the state (the Chinese gave up a millenium-wide lead in shipping to the Europeans, for example, when an Emperor banned large ocean-going vessels), the impact of science, as well as religion, politics, and even nutrition. He questions the importance of such commonly-cited factors as the spill-over benefits of war, the abundance of of natural resources, life expectancy, and labor costs. And he presents startlingly novel explanations of why China lost its dramatic lead in technology to Europe, why medieval Europe was technologically more creative than Classical Antiquity, and why Britain left the rest of the world behind during the Industrial Revolution only to lose its leadership a century later. Today, an ever greater number of industrial economies are competing in the global market, locked in a struggle that revolves around technological ingenuity. Lever of Riches, with its keen analysis derived from a sweeping survey of creativity throughout history, offers telling insight into the question of how Western economies can maintain, and developing nations can unlock, their creative potential.},
author = {Mokyr, Joel},
isbn = {9780195061130},
keywords = {Fiction / General,Folder - ch1},
language = {en},
mendeley-tags = {Fiction / General,Folder - ch1},
pages = {366},
publisher = {Oxford University Press},
shorttitle = {The Lever of Riches},
title = {{The Lever of Riches: Technological Creativity and Economic Progress}},
url = {http://books.google.com/books?id=zo\_8L4lT1z0C},
year = {1990}
}
@incollection{ToreRisch2009,
annote = {doi:10.1201/9781420069815-c11},
author = {{Tore Risch} and {Samuel Madden} and {Hari Balakrishan} and {Lewis Girod} and {Ryan Newton} and {Milena Ivanova} and {Erik Zeitler} and {Johannes Gehrke} and {Biswanath Panda} and {Mirek Riedewald}},
booktitle = {Scien},
isbn = {978-1-4200-6980-8},
month = dec,
publisher = {Chapman and Hall/CRC},
series = {Chapman \& Hall/CRC Computational Science},
title = {{Analyzing Data Streams in Scientific Applications*}},
url = {http://dx.doi.org/10.1201/9781420069815-c11},
year = {2009}
}
@techreport{Drake1996,
author = {Drake, Robert H.},
month = jun,
pages = {12 p.},
title = {{Recovery of tritium from tritiated waste water cost-effectiveness analysis}},
url = {http://lib-www.lanl.gov/cgi-bin/getfile?00326809.pdf http://www.fas.org/sgp/othergov/doe/lanl/lib-www/la-pubs/00326809.html},
year = {1996}
}
@article{Dausman2010,
abstract = {The present study demonstrates a methodology for optimization of environmental data acquisition. Based on the premise that the worth of data increases in proportion to its ability to reduce the uncertainty of key model predictions, the methodology can be used to compare the worth of different data types, gathered at different locations within study areas of arbitrary complexity. The method is applied to a hypothetical nonlinear, variable density numerical model of salt and heat transport. The relative utilities of temperature and concentration measurements at different locations within the model domain are assessed in terms of their ability to reduce the uncertainty associated with predictions of movement of the salt water interface in response to a decrease in fresh water recharge. In order to test the sensitivity of the method to nonlinear model behavior, analyses were repeated for multiple realizations of system properties. Rankings of observation worth were similar for all realizations, indicating robust performance of the methodology when employed in conjunction with a highly nonlinear model. The analysis showed that while concentration and temperature measurements can both aid in the prediction of interface movement, concentration measurements, especially when taken in proximity to the interface at locations where the interface is expected to move, are of greater worth than temperature measurements. Nevertheless, it was also demonstrated that pairs of temperature measurements, taken in strategic locations with respect to the interface, can also lead to more precise predictions of interface movement.},
author = {Dausman, Alyssa M. and Doherty, John and Langevin, Christian D. and Sukop, Michael C.},
doi = {10.1111/j.1745-6584.2010.00679.x},
issn = {1745-6584},
journal = {Ground water},
keywords = {Data Interpretation,Seawater,Statistical,Uncertainty,Water Movements},
language = {en},
number = {5},
pages = {729--40},
pmid = {20132327},
title = {{Quantifying Data Worth Toward Reducing Predictive Uncertainty}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20132327 http://onlinelibrary.wiley.com/doi/10.1111/j.1745-6584.2010.00679.x/abstract http://onlinelibrary.wiley.com/store/10.1111/j.1745-6584.2010.00679.x/asset/j.1745-6584.2010.00679.x.pdf?v=1\&t=hf3ncnvh\&s=d219cf9754ceab1672a615613d8e82fb4aaf4d4e},
volume = {48},
year = {2010}
}

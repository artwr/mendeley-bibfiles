Automatically generated by Mendeley Desktop 1.11
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{King1986,
abstract = {This article identifies a set of serious theoretical mistakes appearing with troublingly high frequency throughout the quantitative political science literature. These mistakes are all based on faulty statistical theory or on erroneous statistical analysis. Through algebraic and interpretive proofs, some of the most commonly made mistakes are explicated and illus- trated. The theoretical problem underlying each is highlighted, and suggested solutions are provided throughout. It is argued that closer attention to these problems and solutions will result in more reliable quantitative analyses and more useful theoretical contributions.},
author = {King, Gary (New York University)},
file = {::},
journal = {American Journal of Political Science},
month = aug,
number = {3},
pages = {666 -- 687},
title = {{How Not to Lie with Statistics: Avoiding Common Mistakes in Quantitative Political Science}},
url = {http://www.jstor.org/stable/2111095?origin=crossref},
volume = {30},
year = {1986}
}
@article{King2000,
abstract = {Social scientists rarely take full advantage of the information available in their statistical results. As a consequence, they miss opportunities to present quantities that are of greatest substantive interest for their research and express the appropriate degree of certainty about these quantities. In this article, we offer an approach, built on the technique of statistical simulation, to extract the currently overlooked information from any statistical method and to interpret and present it in a reader-friendly manner. Using this technique requires some expertise, which we try to provide herein, but its application should make the results of quantitative articles more informative and transparent. To illustrate our recommendations, we replicate the results of several published works, showing in each case how the authorsâ€™ own conclusions can be expressed more sharply and informatively, and, without changing any data or statistical assumptions, how our approach reveals important new information about the research questions at hand. We also offer very easy-to-use software that implements our suggestions.},
author = {King, Gary (Harvard University) and Tomz, Michael (Harvard University) and Wittenberg, Jason (Harvard University)},
file = {::},
journal = {American Journal of Political Science},
number = {2},
pages = {341--355},
title = {{Making the Most of Statistical Analyses: Improving Interpretation and Presentation}},
volume = {44},
year = {2000}
}
@incollection{Studenmund2005k,
address = {London},
author = {Studenmund, A.H.},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {16},
edition = {Fifth},
editor = {Clinton, Denise},
file = {::},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {616},
publisher = {Pearson Education, Inc.},
title = {{16. Statistical Principles}},
year = {2005}
}
@unpublished{Imai2009,
abstract = {In a highly influential paper, Baron and Kenny (1986) proposed a statistical procedure to con- duct a causal mediation analysis and identify possible causal mechanisms. This procedure has been widely used across many branches of the social and medical sciences and especially in psychology and epidemiology. However, one major limitation of this approach is that it is based on a set of linear regressions and cannot be easily extended to more complex situations that are frequently encoun- tered in applied research. In this paper, we propose an approach that generalizes the Baron-Kenny procedure. Our method can accommodate linear and nonlinear relationships, parametric and non- parametric models, continuous and discrete mediators, and various types of outcome variables. We also provide a formal statistical justification for the proposed generalization of the Baron-Kenny pro- cedure by placing causal mediation analysis within the widely-accepted counterfactual framework of causal inference. Finally, we develop a set of sensitivity analyses that allow applied researchers to quantify the robustness of their empirical conclusions. Such sensitivity analysis is important because as we showthe Baron-Kenny procedure and our generalization of it rest on a strong and untestable as- sumption even in randomized experiments. We illustrate the proposed methods by applying them to a randomized field experiment, the Job Search Intervention Study (JOBS II).We also offer easy-to-use software that implements all of our proposed methods.},
address = {Princeton},
author = {Imai, Kosuke (Princenton University) and Keele, Luke (Princenton University) and Tingley, Dustin (Princenton University)},
file = {::},
institution = {Princeton University},
keywords = {Mediation,Statistics,Structural Equation Modeling,causal inference,causal mechanisms,sensitivity analysis,sequential ignorability,struc- tural equation modeling,unobserved confounder},
mendeley-tags = {Mediation,Statistics,Structural Equation Modeling},
title = {{A General Approach to Causal Mediation Analysis}},
year = {2009}
}
@article{Arlot2010,
abstract = {Used to estimate the risk of an estimator or to perform model selection, cross-validation is a widespread strategy because of its simplicity and its apparent universality. Many results exist on the model selection performances of cross-validation procedures. This survey intends to relate these results to the most recent advances of model selection theory, with a particular emphasis on distinguishing empirical statements from rigorous theoretical results. As a conclusion, guidelines are provided for choosing the best cross-validation procedure according to the particular features of the problem in hand.},
author = {Arlot, Sylvain and Celisse, Alain},
journal = {Statistics Surveys},
keywords = {cross validation,leave one out,model selection,phrases},
number = {0},
pages = {40--79},
publisher = {The author, under a Creative Commons Attribution License},
title = {{A survey of cross-validation procedures for model selection}},
url = {http://arxiv.org/abs/0907.4728},
volume = {4},
year = {2010}
}
@incollection{Studenmund2005d,
address = {London},
author = {Studenmund, A.H.},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {5},
edition = {Fifth},
editor = {Clinton, Denise},
file = {::},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {616},
publisher = {Pearson Education, Inc.},
title = {{5. Hypothesis Testing}},
year = {2005}
}
@incollection{Studenmund2005f,
address = {London},
author = {Studenmund, A.H.},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {7},
edition = {Fifth},
editor = {Clinton, Denise},
file = {::},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {616},
publisher = {Pearson Education, Inc.},
title = {{7. Specification: Choosing a Functional Form}},
year = {2005}
}
@misc{Preacher2004,
abstract = {This web page calculates simple intercepts and simple slopes, the region of significance, and computes specific values to facilitate the plotting of significant three-way interactions in ordinary least squares (OLS) regression. The interaction can be between any combination of dichotomous and continuous variables. We assume that the user is sufficiently knowledgeable in the testing, probing, and interpretation of interactions in multiple regression (e.g., Aiken \& West, 1991; Bauer \& Curran, 2004; Cohen, Cohen, West \& Aiken, 2003). A more extensive treatment of interaction effects can be found here. We further assume that the user has read the descriptions provided in support of the web page for probing a two-way interaction.},
author = {Preacher, Kristopher J. (University Of North Carolina At Chapel Hill) and Curran, Patrick J. (University Of North Carolina At Chapel Hill) and Bauer, Daniel J. (University Of North Carolina At Chapel Hill)},
file = {::},
keywords = {3-Way Interactions,Interactions,Statistics},
mendeley-tags = {3-Way Interactions,Interactions,Statistics},
pages = {1--5},
title = {{Simple Intercepts, Simple Slopes, and Regions of Significance in MLR 3-Way Interactions}},
urldate = {1 January 2010},
year = {2004}
}
@incollection{Studenmund2005h,
address = {London},
author = {Studenmund, A.H.},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {9},
edition = {Fifth},
editor = {Clinton, Denise},
file = {::},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {616},
publisher = {Pearson Education, Inc.},
title = {{9. Serial Correlation}},
year = {2005}
}
@article{Liu2005,
abstract = {This article reviews methodologies used for analyzing ordered categorical (ordinal) response variables. We begin by surveying models for data with a single ordinal response variable. We also survey recently proposed strategies for modeling ordinal response variables when the data have some type of clustering or when repeated measurement occurs at various occasions for each subject, such as in longitudinal studies. Primary models in that case include marginal models and cluster-specific (conditional) models for which effects apply conditionally at the cluster level. Re- lated discussion refers to multi-level and transitional models. The main empha- sis is on maximum likelihood inference, although we indicate certain models (e.g., marginal models,multi-level models) for which this can be computationally difficult. The Bayesian approach has also received considerable attention for categorical data in the past decade, and we survey recent Bayesian approaches to modeling ordinal response variables. Alternative, non-model-based, approaches are also available for certain types of inference.},
author = {Liu, Ivy and Agresti, A.},
file = {::},
journal = {Test},
keywords = {contingency tables,ordinal,statistics},
mendeley-tags = {contingency tables,ordinal,statistics},
number = {1},
pages = {1--73},
publisher = {Springer},
title = {{The Analysis of Ordered Categorical Data: An Overview and a Survey of Recent Developments}},
url = {http://www.springerlink.com/index/vj250ju52484xj03.pdf},
volume = {14},
year = {2005}
}
@incollection{Studenmund2005,
address = {London},
author = {Studenmund, A.H.},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {1},
edition = {Fifth},
editor = {Clinton, Denise},
file = {::},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {616},
publisher = {Pearson Education, Inc.},
title = {{1. The Basic Regression Model.}},
year = {2005}
}
@unpublished{Keele2008,
abstract = {Experiments have become an increasingly common tool for political science researchers over the last decade, particularly laboratory experiments performed on small convenience samples. The standard statistical paradigm used in political science is designed to connect samples to populations, while the inferential goal in an experiment is often about understand- ing whether an observed treatment effect occurred due to chance. In this paper, we outline an alternative derivation for statistical inference based on randomization of the treatment. While some standard tests approximate this form of inference, many do not and can produce incorrect inferences. These tests also have robust forms that are insensitive to the distribu- tion of the data. We outline common randomization tests, such as Wilcoxon rank tests and the Kruskal-Wallis test, and also develop a randomization test for two-way factorial designs as an alternative to the commonly used two-way ANOVA model. Finally, we reanalyze data from two political science experiments using randomization tests to illustrate the inferential errors that can be made when classical tests are used with data from the lab.},
author = {Keele, Luke (Ohio State University) and Mcconnaughy, Corrine (Ohio State University) and White, Ismail (Ohio State University)},
file = {::},
pages = {1--41},
title = {{Statistical Inference For Experiments}},
year = {2008}
}
@incollection{Studenmund2005e,
address = {London},
author = {Studenmund, A.H.},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {6},
edition = {Fifth},
editor = {Clinton, Denise},
file = {::},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {616},
publisher = {Pearson Education, Inc.},
title = {{6. Specification: Choosing the Independent Variables.}},
year = {2005}
}
@article{Elfenbein2007,
author = {Elfenbein, Hillary Anger and Foo, Maw Der and White, Judith and Tan, Hwee Hoon and Aik, Voon Chuan},
doi = {10.1007/s10919-007-0033-7},
file = {::},
issn = {0191-5886},
journal = {Journal of Nonverbal Behavior},
keywords = {IM,emotion recognition \'{a} accuracy,emotional intelligence,workplace \'{a} performance \'{a},\'{a},\'{a} decoding \'{a} negotiation},
mendeley-tags = {IM},
month = aug,
number = {4},
pages = {205--223},
title = {{Reading your Counterpart: The Benefit of Emotion Recognition Accuracy for Effectiveness in Negotiation}},
url = {http://www.springerlink.com/index/10.1007/s10919-007-0033-7},
volume = {31},
year = {2007}
}
@incollection{Studenmund2005c,
address = {London},
author = {Studenmund, A.H.},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {4},
edition = {Fifth},
editor = {Clinton, Denise},
file = {::},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {616},
publisher = {Pearson Education, Inc.},
title = {{4. The Classical Model}},
year = {2005}
}
@incollection{Studenmund2005b,
address = {London},
author = {Studenmund, A.H.},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {3},
edition = {Fifth},
editor = {Clinton, Denise},
file = {::},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {63--83},
publisher = {Pearson Education, Inc.},
title = {{3. Learning to Use Regression Analysis.}},
year = {2005}
}
@book{Gujarati2004,
abstract = {This book covers some essential topics of econometrics. It covers from single regression to multiple regression. The second part of the book talks about how to detect a violation of assumptions (multicollinearity, heteroscedasticity, autocorrelation, model specification) made for running multiple regression and what the remedies are. The third part deals with three topics, including (a) regression on dummy variables, (b) regression on dummy dependent variables, (c) autoregressive and distributed lag models. The last part deals with simultaneous-equation model.},
author = {Gujarati, Damodar N. (West Point Military Academy)},
edition = {Forth},
file = {::},
isbn = {9780071276252},
keywords = {Econometrics,Statistics},
mendeley-tags = {Econometrics,Statistics},
pages = {1--1003},
publisher = {The McGrawâˆ’Hill Companies},
title = {{Basic Econometrics}},
year = {2004}
}
@incollection{Studenmund2005i,
address = {London},
author = {Studenmund, A.H.},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {10-12},
edition = {Fifth},
editor = {Clinton, Denise},
file = {::},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {345--433},
publisher = {Pearson Education, Inc.},
title = {{10-12. Heteroskedasticity.}},
year = {2005}
}
@incollection{Studenmund2005a,
address = {London},
author = {Studenmund, A.H.},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {2},
edition = {Fifth},
editor = {Clinton, Denise},
file = {::},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {34--62},
publisher = {Pearson Education, Inc.},
title = {{2. Ordinary Least Squares.}},
year = {2005}
}
@article{Szalkai2013,
abstract = {The original k-means clustering method works only if the exact vectors representing the data points are known. Therefore calculating the distances from the centroids needs vector operations, since the average of abstract data points is undefined. Existing algorithms can be extended for those cases when the sole input is the distance matrix, and the exact representing vectors are unknown. This extension may be named relational k-means after a notation for a similar algorithm invented for fuzzy clustering. A method is then proposed for generalizing k-means for scenarios when the data points have absolutely no connection with a Euclidean space.},
author = {Szalkai, Bal\'{a}zs},
keywords = {kmeans},
mendeley-tags = {kmeans},
month = mar,
pages = {3},
title = {{Generalizing k-means for an arbitrary distance matrix}},
url = {http://arxiv.org/abs/1303.6001},
year = {2013}
}
@book{Rumsey2009,
address = {Indianapolis},
author = {Rumsey, Deborah},
booktitle = {Director},
file = {::},
keywords = {Statistics},
mendeley-tags = {Statistics},
pages = {1--413},
publisher = {For Dummies},
title = {{Statistics II for Dummies}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=\_UzkbN\_QRuUC\&amp;oi=fnd\&amp;pg=PA1\&amp;dq=Statistics+II+for+Dummies\&amp;ots=0CFwi7vheg\&amp;sig=a1ee7gEns9jmxZ\_Mg5qfkDyZ6mM},
year = {2009}
}
@article{Braumoeller2004,
abstract = {When a statistical equation incorporates a multiplicative term in an attempt to model interaction effects, the statistical significance of the lower-order coefficients is largely useless for the typical purposes of hypothesis testing. This fact remains largely unappreciated in political science, however. This brief article explains this point, provides examples, and offers some suggestions for more meaningful interpretation},
author = {Braumoeller, Bear F.},
file = {::},
journal = {International Organization},
keywords = {Interaction effects,Multiplicative Models,Statistics},
mendeley-tags = {Interaction effects,Multiplicative Models,Statistics},
month = oct,
number = {04},
pages = {807--820},
publisher = {Cambridge Univ Press},
title = {{Hypothesis Testing and Multiplicative Interaction Terms}},
url = {http://www.journals.cambridge.org/abstract\_S0020818304040251},
volume = {58},
year = {2004}
}
@article{Cook2008,
author = {Cook, Alex},
file = {::},
number = {August},
title = {{Kaplan â€“ Meier estimate of S ( t ) in R}},
year = {2008}
}
@unpublished{Franzese2001,
abstract = {Despite occasional constructive pedagogical treatises on the topic in the past (e.g., Friedrich 1982), a common methodology for employing and interpreting interaction terms in regression analysis continues to elude the field; and, partly as a consequence, their misinterpretation remains sadly rampant. This paper aims to redress these problems. We first document the widespread and expanding use of interaction terms in political science. We then elaborate and support our claim that, despite the increased use of interaction terms in regression analyses, many inherently interactive arguments are not being modeled as such. Finally, we note and review several inconsistencies and much confusion in the literature regarding the substantive interpretation of interaction terms and the statistical inferences from the coefficient and standard-error estimates surrounding them. After this review, we discuss three pedagogical themes. First, we offer a generic consideration of the process of writing empirical models that embody interactive hypotheses. Our second theme focuses more specifically on a set of statistical practices and rules of thumb when utilizing interaction models suggested by previous methodological treatments of the topic and frequently employed in current political science literature. We demonstrate that many of these can be misleading. Finally, we discuss the presentation of interaction effects. We show that, while the existing practice of reporting standard errors for individual coefficients remains useful, that practice is decidedly insufficient regarding coefficients on interactive terms. Assessment of interaction effects virtually requires graphical or tabular presentation of results, neither of which is currently commonly published. In this context, we strongly suggest the use of effect-line graphs or conditional-coefficient tables, complete with standard errors, hypothesis tests, and/or confidence intervals of those effects or conditional coefficients. We show how to construct these graphs and tables, giving detailed spreadsheet formulae for doing so in addition to the standard mathematical formulae for their elements.},
address = {Ann Arbor},
author = {Franzese, Robert Jr. (The University Of Michigan) and Kam, Cindy D. (The University Of Michigan) and Jamal, Amaney A. (The University Of Michigan)},
file = {::},
institution = {The University of Michigan},
keywords = {Interaction effects,Regression,Statistics},
mendeley-tags = {Interaction effects,Regression,Statistics},
number = {September},
pages = {1--13},
publisher = {Univ of Michigan Pr},
title = {{Modeling and Interpreting Interactive Hypotheses in Regression Analysis}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=DO2joSlFdBMC\&amp;oi=fnd\&amp;pg=PA1\&amp;dq=Modeling+and+Interreting+Interactive+Hypotheses+in+Regression+Analysis\&amp;ots=k\_szg9guZB\&amp;sig=KdNSnQPPD2xXtafwF3Hz-UQQNSU},
year = {2001}
}
@incollection{Studenmund2005g,
address = {London},
author = {Studenmund, A.H.},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {8},
edition = {Fifth},
editor = {Clinton, Denise},
file = {::},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {616},
publisher = {Pearson Education, Inc.},
title = {{8. Multicollinearity}},
year = {2005}
}
@article{Cai2010,
author = {Cai, TT and Zhang, CH and Zhou, HH},
doi = {10.1214/09-AOS752},
file = {::},
issn = {0090-5364},
journal = {The Annals of Statistics},
keywords = {Covariance matrix,Frobenius norm,minimax lower bound,operator norm,optimal rate of convergence,tapering},
month = aug,
number = {4},
pages = {2118--2144},
title = {{Optimal rates of convergence for covariance matrix estimation}},
url = {http://projecteuclid.org/euclid.aos/1278861244},
volume = {38},
year = {2010}
}
@book{Huff1954,
address = {New York},
author = {Huff, Darrell},
file = {::},
isbn = {0393052648},
keywords = {Statistics,Statistics as Topic},
pages = {1--141},
publisher = {W.W. Norton \& Company, Inc.},
title = {{How to Lie with Statistics}},
year = {1954}
}
@article{Reilly2012,
author = {Reilly, Barry and Rickman, Neil and Witt, Robert},
issn = {17409705},
journal = {Significance},
month = jun,
number = {3},
pages = {17--21},
title = {{Robbing banks: Crime does pay - but not very much}},
url = {http://doi.wiley.com/10.1111/j.1740-9713.2012.00570.x},
volume = {9},
year = {2012}
}
@article{Brambor2006,
abstract = {Multiplicative interaction models are common in the quantitative political science literature. This is so for good reason. Institutional arguments frequently imply that the relationship between political inputs and outcomes varies depending on the institutional context. Models of strategic interaction typically produce conditional hypotheses as well. Although con- ditional hypotheses are ubiquitous in political science and multiplicative interaction models have been found to capture their intuition quite well, a survey of the top three political science journals from 1998 to 2002 suggests that the execution of these models is often flawed and inferential errors are common. We believe that considerable progress in our understanding of the political world can occur if scholars follow the simple checklist of dos and donâ€™ts for using multiplicative interaction models presented in this article. Only 10\% of the articles in our survey followed the checklist.},
author = {Brambor, Thomas (New York University) and Clark, William Roberts (University Of Michigan) and Golder, Matt (Florida State University)},
file = {::},
journal = {Political Analysis},
keywords = {Interaction effects,Multiplicative Models,STATA,Statistics},
mendeley-tags = {Interaction effects,Multiplicative Models,STATA,Statistics},
month = may,
number = {1},
pages = {63--82},
title = {{Understanding Interaction Models: Improving Empirical Analyses}},
url = {http://pan.oxfordjournals.org/cgi/doi/10.1093/pan/mpi014},
volume = {14},
year = {2006}
}
@article{Aguilar-Barojas2005,
abstract = {En la investigaci\'{o}n en salud, es muy dif\'{\i}cil estudiar a toda la poblaci\'{o}n que presenta la variable de inter\'{e}s, por lo que es necesario realizar un muestreo que resulte representativo de la poblaci\'{o}n objetivo. El c\'{a}lculo de la muestra permite responder a la pregunta del investigador de Â¿cu\'{a}ntos individuos se deben considerar para estudiar un par\'{a}metro con un grado de confianza determinado? o Â¿cu\'{a}ntos individuos se deben estudiar para detectar en los resultados de los dos grupos, una diferencia que sea estad\'{\i}sticamente significativa? El art\'{\i}culo realiza las consideraciones previas sobre la profundidad del estudio y las variables. Presenta las f\'{o}rmulas para calcular muestras con variables cualitativas y cuantitativas para estudios descriptivos y explicativos. En estos \'{u}ltimos, cuando se utilizan las pruebas de contrastaci\'{o}n de hip\'{o}tesis m\'{a}s comunes, como son la Chi cuadrada, la t de student y el coeficiente de correlaci\'{o}n de Pearson.},
archivePrefix = {arXiv},
arxivId = {1405-2091},
author = {Aguilar-Barojas, S},
eprint = {1405-2091},
file = {::},
journal = {Salud en Tabasco},
keywords = {SRA,c\'{a}lculo de muestra,f\'{o}rmulas,investigaci\'{o}n en salud,muestra,representativa,s},
mendeley-tags = {SRA},
number = {1-2},
pages = {333--338},
title = {{F\'{o}rmulas para el c\'{a}lculo de la muestra en investigaciones de salud}},
url = {http://www.redalyc.org/articulo.oa?id=48711206},
volume = {11},
year = {2005}
}
@article{Schwartz2011,
abstract = {Patterns of interaction in any social system are accompanied by counter-patterns of withdrawal, one highly institutionalized (but unexplored) mode of which is privacy. There exists a threshold beyond which social contact becomes irritating for all parties; therefore, some provision for removing oneself from interaction and observation must be built into every establishment. Such provisions subserve the action patterns for which they provide intermission. Privacy, which is bought and sold in social establishments, reflects and affirms status divisions, and permits "localized" deviation which is invisible to the group as a whole. Privacy thereby unsulates against dysfunctional knowledge. Rules governing entrance into and exit from privacy are most clearly articulated on the level of the establishment and are reflected in its physical structure and in proprieties concerning the uses of space, doors, windows, drawers, etc. The report ends with a discussion of identity and its relation to the freedoms of engagement and disengagement.},
author = {Schwartz, Barry},
file = {::},
journal = {The American Journal of Sociology},
keywords = {Privacy},
mendeley-tags = {Privacy},
number = {6},
pages = {741--752},
title = {{The Social Psychology of Privacy}},
url = {http://www.jstor.org/stable/2775779},
volume = {73},
year = {2011}
}
@incollection{Studenmund2005j,
address = {London},
author = {Studenmund, A.H.},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {13-15},
edition = {Fifth},
editor = {Clinton, Denise},
file = {::},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {434--519},
publisher = {Pearson Education, Inc.},
title = {{13-15. Dummy Dependent Variable Techniques}},
year = {2005}
}
@techreport{Deloitte2012,
author = {Deloitte},
file = {::},
institution = {Deloitte},
number = {November},
title = {{Measuring the Economic Benefits of Mathematical Science Research in the UK}},
year = {2012}
}
